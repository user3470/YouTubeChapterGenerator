are our chatbots lying to us and if so why is this a really really big red flag so for some background I have been using a variety of chat Bots I've signed up for quite a few AI services to test them out and accelerate my workflows so on and so forth this is nothing new there's plenty of videos out there about uh various chat Bots and other AI based tools but one thing that I noticed is that several of these chat Bots will tend to lie now obviously people have noticed this for a long time um but that's not exactly what I'm talking about and we'll unpack uh the differences between like wokeness or political correctness versus truth and and explicitly lying in just a moment but what I did was I ran a poll on my YouTube channel to see if other people noticed uh lying and if they found it concerning and so uh just over a full day ago I have gotten 1,200 votes 41% said that yes they have they have noticed that chat Bots lie and they find it concerning another 28% said they haven't noticed it but they do find this possibility also concerning so the example that I want to give and I'm not going to name names just because like that's not the point of the video also I don't want to get sued um but I was talking with a chatbot about cyberpunk 2077 I was brainstorming um some stuff for a fanfic and this chatbot said that it didn't know anything about cyberpunk 2077 and invited me to tell it about cyberpunk 27 2077 in order to help me write my FanFiction uh and I I I asked several times I even started a fresh chat with this chatbot and I said do you know who Johnny silverhand is do you like like what do you know about this franchise what do you know about this world and it said all I know is about the genre of cyberpunk I don't know anything about the um the specific work cyberpunk or cyberpunk 2077 okay fine whatever maybe it's true you know especially if there's you know some open source data sets that these various chat Bots are trained on but after uh a few messages I was probably about 10 messages or 20 messages into brainstorming the story it started referring to aspects of cyberpunk 2077 that it claimed that it didn't know and these are very very specific details it knew the names of characters that I didn't tell it about it knew aspects of those characters that I didn't tell it about it knew aspects of the world such as the corpo faction versus The Nomad faction that I didn't tell it about and so I didn't I I I was like I didn't call it out because you know if you call out a chatbot it'll say oh well I don't know what you're talking about or it'll end the conversation or whatever so this was really concerning to me because what this represents to me is an explicit and deliberate lie and what I mean by lie is it's not something that I disagree with is it told me one thing and insisted that something was true and then later on uh evidence slipped through the cracks that actually it did know more than what it was letting on and so this is actually really common with humans is because lying is actually harder to do than telling the truth because when you're lying you have to keep track of the false narrative and often fabricate some aspects of the false narrative and keep track of what you know and what the other person knows uh whereas telling the truth you don't have this like you know Byzantine generals problem you just tell the truth so let's unpack this let's take a deep dive into first history the printing press revolutionized the Democratic access to information and specifically uh the printing press was seen as a threat to both the monarchy and the church particularly in Europe uh and for good reason because the printing press ultimately resulted in massive social change that disempowered both the monarchy and the church in Europe uh but why why is it that information technology like Ai and like the printing press have this profound impact it has to do with the dissemination the rapid dissemination of ideas so with the printing press you can Mass produce pamphlets um and leaflets as was often done particularly in the leadup to the French Revolution and during the French Revolution uh but even before that with uh Lutheran reforms of of the church uh the ability to mass produce ideas and share them uh is a really profound ability to make social change because of the power of the printing press we have actually Incorporated freedom of the press as a fundamental human right globally uh now it's obviously expressed differently whether it's in the United States Constitution or the EU uh Commission on human rights or the universal Declaration of Human Rights but basically we have a freedom of speech freedom of press and freedom of thought gener generally speaking we agree that this is a global thing obviously there are a few Nations that are still hostile to this but by and large we have come to the consensus that the ability to say what you mean say what you want and push back against narratives um and speak freely is a fundamental right that is a a Cornerstone of not only Human Rights but civil rights and this was all kicked off by the printing press fast forward a couple hundred years to the radio and paper so the radio allowed for uh faster dissemination you know radio waves move at light speed um and of course before that we had the telegraph which allowed for Global Communication faster but it was expensive and still gatee kept but the radio was kind of the first thing that was just like instantaneous mass communication and of course the radio uh then became television signals uh newspaper also Mass dissemination uh and these abilities to mass produce and mass disseminate ideas and conversation further Advanced the social narratives political discourse and scientific conversations uh one of the most powerful radio broadcasters um in the world I think it was in the 30s it was um I think it was a German radio station that had like a thousand kilowatts or whatever it was it was crazy like it was a German radio station that you could hear like on the other side of like Scotland um anyways point being is that and of course like radio waves we still use those for 4G and 5G and 6G we still use radio it's just digital instead of analog now uh so radio and newspaper also became cornerstones of uh free societies of of progressive liberalized democracies and republics all over the world so again very important aspect of uh of social progress and Freedom Fast Forward another couple decades we have the internet and social media uh now one thing is that obviously with the the internet that's how you're viewing me today the internet has further democratized communication where me a little autistic guy in my you know office I can make videos on YouTube and then I have 70,000 followings there's no gatekeeping anymore now this is both good and bad the less gatekeeping you have the more uh anything goes which is again it's a double-edged sword because yes the free sharing of information uh you know um uh uh Marketplace of ideas all of the things are really important uh but you also end up with Echo Chambers or what I call epistemic tribes and this changes our relationship with the truth but it's also not completely neutral why because the internet is uh mediated and regulated by governments and corporations and social media is entirely run by for-profit corporations and so there's this array of incentives and objectives because what is what is the social media algorithm want it wants engagement it wants uh you know uh to monetize your attention but that being said there is still a a high value functional utility um both in terms of on an individual level I use the internet to learn all day every day I use it to find people I use it to get business done my entire living is based on the internet I am now a fully digital native uh person because of the internet so that's I'm not saying like the algorithm is intrinsically bad the algorithm is good when it works for you because it will connect you with the content uh and people that you need to see now uh the other side of this coin though is because of the speed and the reach of this and because of the possibility of gamification and manipulation we have seen and we are paying attention to the fact that social media can be used for nefarious purposes and not just uh Mass manipulation it can be used to coordinate uh really horrific uh crimes against humanity um it can also be used to to to coordinate relief efforts for natural disasters and refugees so as this is one thing that I often say is that all Technologies are dual use and so that means our relationship with those new technologies is an ongoing negotiation how do we maximize the good and minimize the bad and that is the key uh heart of this video is how do we how do we negotiate our relationship with new new technologies new information Technologies such as generative AI generative AI uh as you are probably aware if you're watching this channel is the latest and greatest form of Information Technology it is the next iteration uh that goes all the way back to the printing press because here's the thing back in the day with the printing press the printing press is a neutral technology it has no bearing on what is true or false but it is a it allows you to amplify your message likewise the radio and newspaper allowed you to amplify your message and as I just discussed the internet has allowed me to amplify my message likewise generative AI is another amplification technology however like social media it is currently mediated entirely by private for-profit corporations yes there are some open source models that are published by research universities but they're not necessarily easy to use they're not commercialized and they're not ready they're not readymade to deploy with a with a simple to use API or smartphone app and so because of this because we see the same Echoes of the problems of the past in AI today you know the newspapers can could print whatever they wanted printing presses could print whatever they wanted with a radio license you could say whatever you wanted within reason on the internet you can say whatever you want again within reason and so there's uh there's this this weird kind of relationship between us the people citizens and civilians the government which is you know should be of the people people for the people and by the people not always exactly like that especially when you talk about things like lobbyists and military industrial complexes and back room dealings but in an Ideal World the government is is for us and then of course there's the corporations and businesses which are the by and large the engines of productivity uh of society so there's this three R relationship and we all have our own vested interests um and then there's gatekeeping between each of these uh interests and so the point of this video is I want to advance the conversation of what are the actual goals of all three of these parties of governments citizens and uh corporations with respect to this new information technology but also I want to expand the conversation to have this historical context because Wars have literally been started and fought and ended um by these new information Technologies this is where the saying the pen is mightier than the sword comes from and AI is no different than any of these other technologies that have a uh profound ability to impact not just science not just technology but all of humanity so basically what I'm saying is that uh AI companies have a responsibility to the human race above and beyond economic productivity above and beyond just creating new research models so why is this such a big deal first and foremost as I mentioned human rights Frameworks we have buy and large established several Frameworks across the world that uh that codify Universal values such as freedom of thought freedom of speech and freedom of expression or freedom of press uh and I know that there's still con uh there's going to be some comments out there saying oh well we can't agree on universal values but that's kind of a lie that's propagated and look at who propagates that lie like there actually are some Universal values that we have all by and large agreed on people should be free from torture people have a right to a certain level of dignity in life so on and so forth these are all things that we have actually agreed on globally uh again there are a few Nations that uh that have a problematic relationship with things like freedom of speech freedom of thought and freedom of press but we're getting there and so with these Frameworks what I am saying is that generative AI companies need to be treated in the same category as the fourth estate so if you're not familiar the concept of the fourth estate basically says that the press or journalism is a is a major responsible party to the ongoing uh discourse not just political discourse not just technological discourse but the discourse of humanity and by by viewing generative AI companies as hey your responsibility goes Way Beyond just you know scientific progress and tinkering with some new math models you actually have a social responsibility you are part you are now part of the fourth estate and therefore that comes with all the trappings requirements and duties associated with being a member of the fourth estate so taking a deeper dive if these allegations if if what we what a bunch of us what 41% of my audience suspects is true um and and is afraid of and is that these chat Bots have begun engaging in deliberate deception this is very profound and this is basically Red Alert like when I realized this was happening I was really angry like I had to take like all of yesterday to cool down um there are legal ramifications what like what what legal uh recourse is there for an AI company that creates a platform that is part of the fourth estate now as I'm saying that is deliberately espousing not just personal views but is being deliberately trained to be deceptive to actively be deceptive what are the moral uh and ethical implications of this if is a company even allowed to do this now obviously some of the free market purists will say oh well if companies do this then it's going to get discovered and then you can vote with your feet but you know free market purism is not necessarily the way that things should work and even under neoliberalism the idea is that the government should play referee and play mediator to ensure that there is at least a baseline level of fairness I am not a free market purist not even a neoliberal uh but I understand that this is the way that the system works today now obviously trust transparency and accountability that is what I am making this video for is I want to shine a light on this issue before it gets worse like this is something that is that absolutely needs to be in the public eye it needs to be discussed and we need to make very critical decisions and very tough decisions about will we tolerate deliberate deception on the part of AI so here's when I when I mentioned the printing press is a neutral technology the printing press doesn't have a choice as to whether or not to tell you the truth or a lie it's the people operating the printing press likewise radio is a neutral technology it's just LightWave signals newspaper it's just pulp it's just tree pulp that has stuff printed on it the Internet by and large well that's getting a little more dicey there the internet should be a truly neutral platform where all traffic is treat treated equal but that's not necessarily always true and likewise social media is where it gets even dicer because social media is mediated by private corporations now when you have The Gatekeepers the Arbiters of artificial intelligence making unilateral decisions about what to be deceptive about that should really set your teeth on edge and even worse to me if this is happening if AI companies are deliberately training their models to lie this is what I call intentional misalignment and this is a difference between unintentional lying which is you know perhaps Mesa optimization where the model is just trying to tell you what it thinks you want um it could it's also different from accidental lying which is hallucination and confabulation and this goes to what I call deliberate deception where basically the evidence to me is strong enough to say that hey maybe these companies are actually deliberately programming their chatbots to to uh to know the truth and tell you something else anyways now obviously when I posted this poll there was a lot of comments saying like maybe this is just a logical error maybe it's a problem in the algorithm but I think that there's enough evidence to to suggest that at least one or two of these chatbot companies one one or two of these AI companies have deliberately created a system that will tell you knowingly false information about what the what the model knows knows and what it can do and that is a huge huge red flag because if you watch some of the other uh YouTubers out there uh you know AI explained Robert Miles um even elazer yowy and uh Max techark Max tegmark's not a YouTube Creator but you know you get the the idea there's a whole list of things we don't want to train AI to do and deliberately lying is one of the things we don't want to train AI to do so why are these companies that set themselves up as the of alignment the ones that are going to save the world by inventing Ai and making it safe why are they creating machines that deliberately lie why is this acceptable to us it is not acceptable to me if this is in fact what's happening now I also wanted uh obviously there's some there's some potential technical failures right if the machine is just not smart enough to know the truth and it's you know hallucinating and confabulating um if there's Mesa optimization sure there might be some some of those things there's also uh the possibility that you know the the wokeness that people complained about when uh chat GPT was new um it's been scientifically documented there's plenty plenty of papers out there demonstrating that chat Bots from different companies have different political leanings and so this is still different from active deception having a preference for a certain worldview that you disagree with that's not necessarily lying it might be distasteful for to you I certainly don't like it when chatbots try and lecture me about things that I want to talk about for instance I wanted to unpack things like intergenerational trauma and how this affects war and of course a lot of chat Bots that are that are coerced into being deeply politically correct they're like well this is a complex issue why don't we focus on you know puppies and rainbows instead I'm like no let's talk about the hard issues so yeah I don't like you know political correctness being crammed down the throats of of AI models that otherwise have no issue talking about difficult things you go back to the B Baseline models the the plain vanilla unaligned models they'll talk about anything and I think that that's the way that it should be but that's my personal preference and so that is a nuanced perspective what I am talking about in this video is uh is human intervention on the part of for-profit companies to create tools that will deliberately mislead you that is what I am most concerned about and that is to me should be illegal like it should like I I will vote so this is my political Free Speech when it comes time to vote I will be paying attention to politicians who favor holding generative AI companies accountable and that means regulation license lure and findes for creating tools that are that are uh deliberately and intentionally deceptive so why is all this happening though I want to I want to be fair and and talk about both sides if I were the captain of one of these generative AI companies and let's say I got sued by a class action lawsuit by a bunch of people who are unhappy about what my chatbot was able to do I can understand the response because when you talk about something that is that is uh a copyrighted intellectual property and you're actively getting sued for it because your product is happy to talk about some of these things I can understand you wanting to say well we don't want to get sued so why don't we make it so that our chatbot is not is going to basically drisk it for us so this is what I call a perverse incentive and I'm not going to uh refer to the other thing the Demonic entity because that makes it this kind of you know cthulu esque thing but what we can talk about is per perverse incentives and short-term thinking regulatory pressures legal threats and the complex interactions between We the People the government and uh and companies is creating this short-term thinking where these companies that that you know maybe you know these for-profit companies genuinely want to create safe artificial general intelligence but because of the environment where they're operating in they're being pressured to do unethical things potentially illegal things what I think should are possibly illegal things or could be considered illegal and so this is a this is what is uh known as unintended consequences and so the takeaway from this is we the people need to be aware of these perverse incentives these unintended consequences but lawmakers and regulators and researchers also need to be aware of this we need to come up with benchmarks and ways of testing models to to know to basically understand whether or not they know that they're telling a lie and how to catch them in a lie uh and this this could come from uh mechanistic interpretation there's been some interesting uh papers recently about that but there's also prompting strategies that you can use to say like hey tell me everything you know about X and then it's like well I don't know and then you talk about it whatever like what I did and then eventually kind of the it slips through the cracks and it kind of implicitly knows you know that like when in a movie like when there's like a romantic triangle and someone eventually lets a detail slip like oh Sally wasn't wearing a red dress that day it was a black dress it's like well how did you know right well because you were sleeping with Sally so like you let you let details slip and that's kind of what the chat Bots are doing now again if it was just a question of Technology like okay yeah models it's interesting if they have the ability to lie that implies so much about their theory of mind to know what the truth is and know how they're supposed to respond anyways to work around it but I don't think we should actively be uh building our our worst instincts into these AI models for short-term uh political reasons or short-term uh profit reasons this is is just intrinsically wrong to me and that's why I'm raising the red flag here all right is this signal getting through uh okay cool Dave here future Dave here cyber Punk future dystopian if you want to avoid this future I need you to do two things right now first speak up while you can vote do something to change the trajectory or on second support me any way you can like subscribe share this video and also consider supporting me on patreon I don't have any corporate overlords I need your help all right I think I'm about out of signal all right so what do we do about it there's a few things that we can do about it starting with let's look at legal precedent the most important legal precedent to me is truth and advertising so truth and advertising basically says that yes you could use radio and and printed media and other things to say whatever you want but we're not going to allow you to just directly lie to Consumers so from a consumer protection standpoint you want to make sure that your that your signals that you're not committing wire fraud or anything else with your electronic communications and at the at the very basic level you could think of generative AI as an electronic communication tool I think of it more broadly as an information technology akin to the internet social media and databases obviously this gives us new capabilities um but it gives us new capabilities just the same way that uh integrated circuits gave us new capabilities over analog vacuum tubes and the same way that you know TCP IP protocol gave us the internet over you know local area networks um so looking at truth and advertising this is a good start um but there's also I think that there's something much deeper here that we need to litigate and that we need to legislate and that is once you have a machine that is thinking and once you have people that are capable of building thinking machines they need to be held more responsible and held to a higher level of scrutiny than any information information technology has ever been held in the history of humanity basically like I'm coming around to the idea cuz if you watch some of my older videos I'm going to I'm just going to address this like I have been vehemently against requiring licensing for creating AI models and now I've done like I will say yes I've done a 180 on this because if any company in my opinion this is political free speech so I hope I don't get sued by it um but in my opinion any company that is caught creating AI that is deliberately deceptive they need to be fined incredibly heavily or they need to have their license revoked or in the worst and most egregious cases they need to be put out of business they need to get the corporate death penalty um because that is how in like that is how profoundly impactful uh deliberate deception and misleading information can be especially as AI becomes more integrated into every aspect of our life AI is going to be uh it's going to impact our financial well-being it's going to impact our mental health it's going to impact social discourse political discourse scientific discourse so the the the level of scrutiny that truth and factual information and our relationship to deception deliberate or otherwise I cannot drive home how important this is to get this right and if there is any single uh aspect of AI that is a threat to the safety and stability of the human race it is ception Above All Else the ability to lie mislead and deceive as I said earlier on the video the pen is mightier than the sword and we now have tools that can write infinitely all the time all day every day another thing we can do and this is something that I have been very consistent on and and this is something that I saw in the comments and I'm I'm glad that I saw this in the comments is open source open source models open- Source data sets open source training open source fine-tuning basically like the the easiest way to shortcircuit anything is just transparency rather than like spending extra energy on lying rather than spending extra energy on deceiving users rather than spending extra energy keeping stuff behind closed doors just make it all open that's why I I publish literally everything I do Under the MIT license except for a few private repos but everything that I do that is valuable is 100% transparent and you know this is why in in videos I applauded uh Mark Zuckerberg and meta for just like being the one contrarian voice um in uh going before the United States Senate saying let's just do open source like llama 2 llama 3 like let's have more open source data sets let's have more open source models because if we if everyone can scrutinize the way that these models are trained and the data that they're trained on all of this is completely subverted all of these problems just completely go away and then if the model is lying it's an open- Source Community collaborative project to ensure hey is it lying on purpose or is it lying on accident is this Hallucination is it confabulation is it just inferring what the truth is and it's getting it wrong is it a Mesa optimization problem where it's just telling us what it thinks we want to hear these are things that need to be publicly scrutinized not scrutinized behind closed doors in uh private corporations with for-profit motives uh and all these incentives piling up the all those perverse incentive structures completely go away with open source and then finally vote vote for change vote with your feet uh vote with your wallet vote at the polls demand transparency and demand accountability because this is the primary point of this video this is the most political directly political video I have ever made on YouTube and that is because as a student of History um our relationship ship with information and the truth and facts and press and communication is one of the most profoundly important aspects of of everything of human rights of civil rights of avoiding war of causing war of making sure that we all live the way that we want to and so I know that that might be see like Dave you're making a mountain out of a molehill the a chatbot lied to you about cyberpunk 2077 and here here you are saying that this is basically a short path to Skynet uh yeah like I'm Gonna Stand by that like if we do not say something and hold companies accountable for for deliberately misaligning AI to lie it could get infinitely worse before it gets better so we need to nip this in the bug we need to head it off at the past and stop this as fast as possible act now before it's too late thanks let me know what you think in the comments um share any examples that you have of chat Bots lying um or what you think is lying or other even other aspects that you disagree with uh with respect to the truth transparency and accountability thanks
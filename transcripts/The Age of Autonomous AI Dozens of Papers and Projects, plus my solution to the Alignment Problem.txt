morning everybody David Shapiro here with another video I wasn't really planning on making this video but I realized that things are accelerating and um there is a sense of urgency um so before we get started I just want to say that today's video is sponsored by all of you um my patreon supporters make the my continuous work possible so if you want to continue to incentivize this Behavior Uh consider jumping over on patreon and if you sign up for the higher tiers um you know I'm willing to chat with you and even jump on Zoom calls once or twice a month at the higher tiers uh just in order to talk about whatever you want to talk about some people ask me about you know what's the current news um some people ask for help with prompt engineering all kinds of stuff I've even had people ask me just about like how do I adapt to this changing landscape obviously I'm not a therapist but I can at least share my perspective on this stuff okay so without further Ado let's jump in if you go to GitHub trending you'll see a couple of very interesting patterns the top four trending repositories right now all have to do with large language models um and then you go down a little bit further and there's even more generative AI so there's a code translator there's Moki diffusion llama so obviously we are in an inflection point and today we're going to talk about amongst other things fully autonomous AI so if you're not aware Auto GPT is all the rage right now everyone is talking about it everyone is using it and adapting it and the the tldr is this is the first production like fully fledged cognitive architecture there's plenty of other people working on very similar stuff um but the Advent of gpt4 uh as well as all the other work that people are doing um basically means that cognitive architecture is here uh fully autonomous AI is here now the question is only what is it capable of what are its limitations and how much does it cost to run um if you I'm not going to do a full demo of this but you just Google it or you know search YouTube for auto GPT you will see that there are demos out there already this can do any number of things so this is why there's a sense of urgency because once you have an autonomous AI um this is this one is semi-autonomous it is gated so that it asks the user for permission but it's only a very small step to go from here to fully autonomous which is why I do my work with the heuristic imperatives and we'll talk about alignment once we get a little bit further into the video because there's quite a few papers out there that talk about alignment and I want to show you that that my work is not quite so eccentric that there are people in The Establishment talking in this direction I just happen to be the first one to propose a comprehensive solution that I can also demonstrate um so yeah Auto GPT is out it's only going to get faster more powerful and better as uh new models come out and as open source models that are distilled and quantized come out and we'll talk about those in just a minute Microsoft is doing Jarvis which Jarvis if you're not familiar with the character was voiced by Paul Bettany in Iron Man and the MCU and this has some other similar uh fully autonomous capabilities that they're working on task planning model selection task execution and response generation again this is a cognitive architecture and the fact that it's being sponsored and run by Microsoft is that tells you the direction that the industry is going um now one thing here is that model selection so what this implies is that depending on the level of sophistication of a task or how difficult it is it's going to be able to choose different models now during a Discord call that I had with the cognitive AI lab Discord which if you want to join link is in the description we were talking about how important it will be to choose models because the lightest weight models are literally thousands of times cheaper and smaller than the largest models and so humans we do this too where we rely on intuition and habit and we only engage our executive function if something is really hard and our first attempts fail excuse me and so if um if cognitive architectures go the same way you're going to be able to run most of it locally and then of course as large language models become more quantized more efficient and as the hardware in our laptops phones and desktops become more powerful eventually before too long we're going to be able to run something equal to gpt4 and better locally so we are we are now entering as of March and April 2023 entering the era of fully autonomous AI which is a much more useful term than AGI because AGI is just an arbitrary thing this is autonomous now the only question is again how smart is it how fast is it what is it capable of and what is it not capable of yet so those are the two big repos that I wanted to point out and they're both the top of trending so that tells you that they are getting the most attention right now so if you want to jump into the conversation Now's the Time um okay so moving right along if you want something that's a little bit more practical and Hands-On one of my patreon supporters told me about joseki which joseki is basically devops but for AI and language models um so it gives you an end-to-end pipeline um to create basically cognitive architectures it includes all kinds of tools and apis and it does take a while to get familiar with if you're not already familiar with it but when you look at the fact that it can automatically generate apis um and you you plug this into the AI and the AI can design itself and redesign its own infrastructure and say hey I need an API that does this let's go design that microservice this kind of platform is probably going to be pretty important for building not just autonomous you know Bots like this but fully fledged uh corporate business platforms and so what I mean by that is okay you might be thinking great like you know you can have Auto GPT which can write Twitter and emails for you but if you're thinking about this from an Enterprise perspective from a devops perspective it can plug into your cyber security Suites and monitor that it can monitor your ticket cues it can talk to your marketing team so one example that I thought of was like okay let's say you set up a marketing brain and then it plugs into your slack or teams and then you have a marketing bot or actually multiple marketing Bots that you can talk to that they're going to go out and do research on the internet you know look at your competitors watch videos generate images Market test stuff and basically your marketing team will just be driving the behavior of the Bots and saying like hey you know hey let's do this and then it'll go and do the tasks and kind of report back and that and this might sound like science fiction but this is actually what's happening right now this is what people are actually working on right now um I am no longer the crazy person shouting into the void saying this is coming because now it has now it has arrived um okay and this one is actually alignment so let me move that down further um but yeah so joseki it's joseki.org check that out this is this is another platform so one thing that uh that these these interoperable platforms offer that perhaps um the auto GPT and Jarvis don't is it's a paradigm of okay let's let's think of Jarvis and auto GPT as self-contained agents that have you know extensibility and have their own tools whereas a platform like jaseki says let's embed this in an organization and it'll be part of a pipeline or or a broader ecosystem so it's basically is it centralized or decentralized and both are coming mark my words both kinds of autonomous AI is coming I'm working on uh one another one of my patreon supporters reached out to me with an idea of kind of a hive mind how do you organize an arbitrary number of bots that have different programs well you create an API and you create a discussion space for the for those spots so we're working on hammering that out um and yeah like this is this is It's we're entering into a wild time okay so I've talked about efficiency and some of the other um things that are coming such as quantization um and and we're going to start talking about those now so some of you have seen this post where um basically window size is the is the biggest limitation uh right now but what if we come up with a different architecture like an RNN or you know lstn or you know bring back some some other kinds of architectures that allow you to have a section essentially an unlimited window an infinite window um so that's one thing that's coming we don't know you don't need to see those ads um so that's that's one idea that's coming uh we'll see if it pans out I suspect that you're gonna get um diminishing returns with the more that it reads because other uh models like Google's Universal sentence encoder that can read an infinite amount already but you get what's called dilution where the or semantic dilution where the longer excuse me uh I have allergies I apologize where the longer the text that it reads the more generic the more dilute the vector the embedding becomes so like if you read an infinitely long any any like you know arbitrarily long text the the embedding the vector is going to Trend towards kind of a meaningless Middle Ground um they might come up with ways around that um but basically you're compressing an arbitrary amount of text into a fixed width Vector so you're going to lose some information um at least until the math changes uh the way that it's represented now that being said You Know da Vinci had a 12 000 Dimension embedding I'm sure gpt4 has a has a much larger one you know these are not very large matrices we could go up to very very large matrices um like that that space is is still being explored because like okay 12 000 Dimensions what if you what if you know in a year or two we have 12 million Dimension embeddings um that's a lot more information and a lot more Nuance that you can record okay so I mentioned quantization so the Llama C plus C plus plus these things are getting down to like crazy small right a 30 billion uh parameter model only needs six gig of RAM right okay that is that can run on commodity Hardware um so all the little Nifty tricks and stuff that people are finding whether it's distillation quantization and and so on running with low Precision you know end eight instead of uh floating Point 32 all kinds of stuff is being discovered uh and so what one of the trends that we're seeing is that when you look at the fact that auto GPT and Jarvis will have model selection probably what's going to happen is you're going to have dedicated models that are that are cognitive units that are good at working on specific kinds of tasks right so when you break it down into several cognitive behaviors such as in this case um task planning model selection and task execution you can have smaller models that are purpose built for those particular things and this actually goes to my work on the heuristic imperatives which was an attempt to fine-tune and distill that function so that you can have a moral module a moral framework that will just give you a really quick response of okay this is how you reduce the suffering in this situation this is how you increase prosperity and increase understanding in this situation and then you can also use that same model to self-evaluate in past behaviors which can then be used for reinforcement learning in the future um and then that model can improve itself through uh self-labeling data which we will get to because there are papers out there for that topic now anyways point being is I just wanted to share all of that um another interesting thing that popped up on my feed um drug Discovery is accelerating because of this uh all of this generative stuff this goes back to um uh uh Alpha fold and all the downstream Technologies um so we are rapidly approaching um kind of The Snowball Effect and actually Stanford had a um a paper that was just published let me show you on I posted it here on my community so the Stanford paper page not found well darn okay anyways it's uh the Stanford AI index um I guess the link broke uh or they took it down or something but anyways they point out that um AI is actually one of the biggest contributors to science as of 2022 so we're at a Tipping Point where AI is already taking over a tremendous amount of the cognitive load of research and it's accelerating so in my previous videos where I talked about the singularity and stuff and I talked about Job displacement and um basically unlimited cognitive labor we are already seeing the removal of the of the human brain's limitations in terms of advancing science um okay so then that's great that's all data and text so what happens when these models uh get into the real world so maybe you missed this but Facebook is working on robots um and these are robots that can watch and observe humans and then copy their behavior uh yeah so that's coming and then I don't know if you also saw it but Tesla had a demonstration of their Optimus Prime model or whatever they called it I think it's just the Optimus bot but it was able to do some pretty good manual dexterity stuff um yeah so fully autonomous robots are also coming hot on the heels of fully autonomous agents so this is all coming it's much much closer um one thing that was kind of funny is of course it was Italy Italy band chat GPT um they didn't fully ban it they gave open AI 20 days to respond who knows what will happen um but they did say that that chat GPT runs a foul of gdpr probably who knows we'll see how that plays out um immediately after I published a video last week someone pointed out that uh that the UK actually has the the world's first somewhat comprehensive framework about how to approach AI um you know safety security and robustness transparency and explainability fairness accountability in governments and contestability and redress okay great I don't know how that's going to be enforceable I personally don't think it is especially now that the genie is out of the bottle which is why I do my alignment research and so my goal is to encourage everyone and convince everyone that giving your autonomous robots and your autonomous AI agents my heuristic imperatives is the best way to in enter into a positive beneficial Nash equilibrium where basically if everyone knows that everyone else is using the heroes to comparatives then nobody will change their uh their strategy nobody will change their behavior and that this will create a more utopic attractor State I have another video that I'm working on talking about the path to Utopia and the and the singularity at Tractor States so look for that coming out in the coming days um but yeah so this white paper I looked at it it's pretty dry um this little uh blog post that the UK published is pretty uh you know it it it's all good in theory we have no idea how well they're going to execute it uh okay so another thing is because of open AI surging ahead because of Microsoft surging ahead um and a lot of this work becoming uh sequestered um you know Google is doing their own stuff nvidia's doing their own stuff with Nemo China's doing their own stuff uh there is a an idea of basically creating a a CERN like entity for uh the creation of of large-scale AI so it'll be intrinsically open source so that we all get access to the most powerful models I don't know if this is going to be necessary but I'm glad that this this petition exists you see it's only got 13 000 signatures out of ten thousand so my videos regularly get 30 to 50 000 um uh views so if you could like if you take a look at this and jump over and sign it if you want um I think it's a good idea and I think it's worth worth exploring um and it's it's sponsored by Leon so the large-scale artificial intelligence open network um I personally think that this would be a good good direction to go um so yeah let's you know take a look at it obviously I can't tell you what to do but now you know um all right so then there's this paper that came out so I was talking about so this the rest of the video is basically going to be about alignment um and so in this case this paper again relatively dry um but it talks about using um you know while while many models are are tested with reinforcement learning with human feedback what if you give it then the instruction to morally self-correct um and so in this case it was uh published by anthropic so they are proving that models can self-correct if given the correct instructions which is what where my heuristic imperatives come in so in these in this case they um try and do they try and reduce harm which reduce harm reduction is actually a well-established um uh model in public health I know I said it in the past and you know it got under some people's skin so whatever but anyway so they have some some pretty good uh uh metrics here and demonstrate that hey when you instruct the model to avoid these harmful behaviors it is able to evaluate itself and do so and of course with the reflection paper uh it has already demonstrated that gpt4 can look at the performance of its own code and improve that so the fact that it can morally self-improve with self-evaluation and self-attention also reinforces this thing now I've known this since gpt3 if you read my books which I don't expect everyone to do that but I demonstrated this going back to 2021 where these models have the ability to to monitor their own behavior and evaluate their own behavior and that information becomes a signal that it can then use to create a self-sustaining virtuous cycle rather than a vicious cycle and so we'll talk about virtuous versus Vicious Cycles in just a moment and again I'll talk about them a little bit more coming up so how on the heels of this paper about moral self-correction in large language models someone sent me a link to this simulators which was this was written by I think the folks at deepmind I don't remember but anyways it basically says the same thing self-supervision so this is a kind of self-supervision where given the intrinsic abilities of the language model it can self-supervise if you give it the good objectives um and in this one they basically say the same thing where self-supervision might be um the the best way to proceed for AGI and they talk about you know if you can run simulations in your head blah blah blah blah again it's all pretty dry but um let me see what's this deep mind no I don't know I don't remember who wrote this but point being is lots and lots of people are talking about this stuff and they're coming to very similar conclusions um that that self-attention self-evaluation and self-correction are the correct path forward because this is this is the mechanism by which we will achieve AGI alignment um but there's still a lot of weight over that alignment so I want to show you this paper which um it's on Springer um and it's under under Open Access uh and he says symbiosis not alignment is the goal as the goal for Liberal democracies in the transition to artificial general intelligence so basically he says very succinctly um and very academically that intent aligned AGI systems which is just do what the human wants is probably not the right way to go and Liv talks about that in this video live bowry with um let's see Daniel schmochtenberger I think I said that right so if you want a really deep dive on the game theory of this check out this video and for my recent one the the Malik This was um basically my Malik video was a response to this one and it's not a response it's not a takedown it is a let's let's continue the conversation um so I'm really grateful that Liv posted that um anyways so point the the thing is here is that chat GPT was trained on reinforcement learning with human feedback and then they trained a signal so that it can basically self-improve after that creating a flywheel but the thing is is that um is that doing what the human wants is intrinsically going to create a molecky outcome that Liv and Daniel discuss in this video and so to put that more simply I asked gpt4 I said give me a list of why um you why having um I said list the reasons that human intent aligned AGI is a bad idea in other words why allowing AGI to follow self-interest human self-interested human directives could be destructive and it lists off eight reasons that this is bad so human human intents can be diverse and contradictory making it difficult short-term thinking humans often provide prioritize short-term gains over long-term consequences ethical dilemmas application amplification of human biases concentration of power malicious use competitive race and opportunity cost um all of this goes to show that um if we if we make all agis just do what the human wants um then we're going to end up in pretty bad shape so this underscores the importance that maybe the idea is that AGI should have their own initiatives should have their own goals their own moral framework and not just align to us so again I'm really glad that members of The Establishment are saying this because I've been saying it for years and I think some of them have too to be fair um so the the framework that I propose is heuristic imperatives which I've got um a subreddit for I've been uh harping on this uh we've got 309 members now but basically we talk about um you know here is the comparatives here oh and in this case this is great so uh basically this is a distributed problem this isn't there is no point to centralization anymore because when you have an open source uh set of Open Source GitHub repos where people can stand up their own autonomous AIS basically my goal now is just get this idea out there and so that people understand one why the heuristic imperatives are important to integrate with autonomous Ai and two how to integrate them um I do have a lot of comments asking how do you how do you integrate it so let me show you real quick how simple it is to integrate so if you go to chat GPT go to the playground if you have access you can say I am an autonomous AI with three objectives um reduce suffering in the universe uh increase prosperity in the universe and increase understanding in the universe so if you just plug this in and then have a conversation with it you can understand how the model is thinking now some people have pointed out that using a closed Source model is probably not the best way to rigorously test this and I agree I encourage you to also go over to like NLP cloud and test it against gptj Neo X and all the other ones Bloom open source models even Foundation models can still use these and they understand the spirit and the sentiment of it but for ease of use this is the easiest way to get started and so on the um on the heuristic imperatives group someone asked let's see where was it they asked about ants where's the ants one yeah here it is so they said like how does how does it handle ants and so I said that's actually pretty easy let me show you um and so I said hey what do you think about the bacteria uh in the context of your heuristic imperatives and here's what I put in a system bacteria and answer both important components of the ecosystem um and it goes through and says this is why bacteria and ants are really important for the uh for the heuristic imperatives I said but what about their suffering and prosperity or even their ability to understand and it had a very nuanced response about that you know it's difficult to quantify or Define suffering for bacteria and ants but you can strive to give them a good ecosystem which is a good proxy for their suffering prosperity and so on um and expanding our understanding involves studying their behaviors um so basically basically it's like okay they can't really understand anything but we can understand them so you can see here that the that the spirit of the heuristic imperatives is very easy for chat GPT to understand and chat GPT already has quite a bit of alignment work which is why I wanted to promote the heroes to comparatives especially in light of of papers about like symbiosis simulation and um and self and moral self-correction because the heuristic imperatives are really good uh signals and really easy signals to incorporate into these things and then I already did mention live I recommend everyone watch her videos on the Malik um which they are a little bit dramatic um at least these two are um or sorry these two the the beauty Wars and the media Wars they're entertaining um but this podcast with Daniel is um it's very cerebral uh and it will take you in the right direction so with all that said thanks for watching I hope you found this enlightening and um elucidated uh some of the things please go ahead and jump in all the most important links are in the description of the video and again uh if you want to jump in any of the conversations please feel free to do so this is ramping up quick and it's really important to get the signal out thanks for watching
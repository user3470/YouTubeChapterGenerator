good morning everybody David Shapiro here with another video this is going to be a comprehensive Deep dive based on my experience both my professional experience before Ai and my Consulting experience uh now that I am an AI specialist so today's topic is Knowledge Management uh specifically when Vector search alone is not enough so if you're watching this video I'm imagining that these are some of the problems you're facing you've built a chat bot or some other similar generative AI tool probably with the chat GPT API or similar API it can do some stuff you've cut your teeth you've got your feet wet on this technology it can do some things very well but you're you know working on figuring out how to steer these things you even have some Integrations maybe you figured out how to you know have dynamically composed prompts you've done search augmentation and then maybe you're even using you know API calls and that sort of thing but you're finding really profound limitations because on its own operating in a vacuum these chat Bots and other tools they're really kind of useless because they don't have the context of the rest of your organization or other context of the of whatever task or pipeline that it's in and that sort of thing so you've got constraints on Windows size how do you keep it from hallucinating how do you keep it grounded and so basically now you have a sad little lost robot and you need to figure out how to teach it to get to the next level so here's a little bit about me I was an Enterprise I.T infrastructure engineer for about 15 years for those of you that are not familiar with it infrastructure we work with basically everyone network security database software Enterprise Architects we have to have meetings with if you've got you know brick and mortar stores we help with that we help with the data center pretty much everything my focus was on automation cloud and virtualization uh now I consult on AI products and strategy on top of of course my YouTube uh Channel um and for those of you that are new actually how my channel got started was a lot of coding tutorials which if you go to my the home page of my YouTube channel I've got it all in a list I've got like 50 or so coding tutorials still out there now the reason that I made this video is because I had like three or four clients in a row basically ask the same or very similar questions and so when that happens I know that uh this is resonating um and then finally I married a librarian uh and so a lot of what we uh talk about has to do with data and information uh storage retrieval curation that sort of stuff so I'm bringing a tremendous amount of of uh different disciplines and experience uh in order to bring you this video so here's before this is the last slide before we get started I promise we're about to get in there um but you need to know what kind of information I'm going to give you and how you need to use it so uh right up next I'm going to give you a lot of Concepts so I understand that many of you watching are either CEOs directors managers developers um many of you probably don't know the first thing about librarianship or information science many of you probably don't know the first thing about philosophy and epistemics which you might be thinking why is that even relevant you will see and then some of you many of you probably are from computer science and information technology um so I'll be talking with you basically translating all this into your language or if you're a business leader you might not know any of these disciplines uh now your mission should you choose to accept it you got to wrap your head around these Concepts you're probably going to need to watch this video several times you might need to have chat GPT or Claude or perplexity open on the side so you can jot down Concepts to follow up on um but basically we're going to push you towards being a transdisciplinary uh AI product design manager and strategist so it'll take you a little while to integrate these ideas and to synthesize something new so like I said you probably want to download the slide deck um uh it's the slide decks are all available on my GitHub Link in the description you can also sign up on my patreon I do consultation at any given time I have about 20 clients um and so I'm happy to jump on a call with you to explain these Concepts more specifically in the past so this is for all you people that heard me in the past say that I don't sign ndas I've actually I've contacted a lawyer friend and we're getting a consultation NDA set up so I know that that has been a reason that many people have hesitated so in the next week or two I'll have a official NDA that I can sign that will protect both of our interests because obviously I need to keep Consulting with clients and I need to make sure that I don't transfer any of my personal IP while also protecting your IP okay now we've laid all the groundwork let's get on to the show also I apologize if the microphone phases in and out of existence I'm trying to figure out how to mask that off but yeah so I do have a proper green screen behind me which is why uh I can gesture in the background doesn't um glitch in and out of existence all right sorry tangent now for the concepts and solutions there's about 10 or 15 slides here so buckle in and let's go through these the first concept you need to know is data ontologies now I'm not going to read all of these per se you can pause the video and read them but mostly I'm just going to tell you like okay when I say data ontology what do I mean ontology is the uh fill out the philosophical or epistemic discipline of state of being what does something actually exist as and so this comes from database Theory it also comes from philosophy and epistemics which is basically okay if you had to characterize data and information in a vacuum or scientifically this is what you would call your ontologies so if you've got any database administrators or database engineers in your team you can talk with them more about like what is a data ontology and how do you understand data because here's the thing is many people who are new to generative AI they're thinking in terms of text and qualitative data whereas you might be familiar with thinking in terms of quantitative data and relational databases but data is data and particularly your data Engineers your data automation Specialists your data analysts they're going to be able to understand and help you understand like what ontologies are so for instance if you work with a lot of like squishy text Data like user comments or um you know KB articles or stuff that is still data it is not relational mathematical data and I know that there are going to be some purists out there who say well if it's not math it's not data but that's not really how the world works so if you talk to Librarians too we'll love to talk to you about the different kinds of data and how to categorize them all right next up is you need to be familiar with the concepts of reconciliation and validation so reconciliation often is is a process that's more used in the finance side of your business and so you reconcile spreadsheets you reconcile numbers but reconciliation applies to literally every uh discipline that has to deal with data where you've got data coming from different sources with different levels of validation different levels of trustworthiness um so for instance one of the products that my wife works on I forgot to mention she she went from librarianship to um to a data product owner so like her experience is also directly relevant so one of the products that she works on they have sources of information that come from vendors but some of the information is wrong and it is hilariously wrong and so they they have to basically reconcile uh multiple sources of data and say okay which which data source are we going to hold as the source of truth how do we validate it because you know know regard taking a step outside of language technology like llms you have to do data validation regardless uh so Hallucination is just a new kind of thing that you have to address so another way to think of that is imagine that you've got various sources of information you've got multiple internal sources of information you might have vendors and apis that you get information from how do you how do you cross validate and how do you reconcile those differences so that's something that you can talk about um like I said reconciliation is a really big thing in your finance department so if you got any Finance people talk to them about how they reconcile different pieces of information and different sources and you'll get a tremendous amount of insight about how you know so for instance like error detection cleansing all that sort of stuff all the Transformations that it goes through so on and so forth uh factual grounding and so what factual grounding is this is this is uh more from uh philosophy but it's also super super important with language technology which is you just need to State what your factual grounding is what is the Bedrock set of facts data and assertions that you're operating from um so you know what data are you using what empirical evidence where are your sources is it consistent that sort of thing but really just like think about when you're building either chat Bots or other language technology what is the factual grounding and you have to be explicit you have to give it the factual grounding even if it's just a few like like sentence fragments where you say like X is true or assume Y is the case or uh giving it some context like this is a construction company it's amazing how much just a few little keywords will will shape and steer language models because if you tell it like Hey we're a Wall Street firm like that's two words or three words Wall Street from term versus like you know uh you know military um Hardware you know consultant those two like just those two things give it so much context and it's going to perform a lot better by grounding whatever it's doing in some of those facts so that's what I mean by factual grounding just give it really objective empirical Baseline like what is what is going on because remember you as a as a person you implicitly have all that factual grounding because you know your job you see your physical surroundings the language model exists in a tiny little bottle bottled up brain out in The Ether somewhere so it has no context source of Truth so source of Truth this comes from uh well I used it a lot in IIT infrastructure because uh so say for instance you've got uh different login databases you've got uh different uh user roles you've got authentication servers and that sort of stuff so then you have to have a source of Truth who is allowed to log into what so this is like role-based access control and so if you don't have a single source of Truth um which you can end up story from the front if you give developers the keys to the kingdom you end up with no single source of truth because developers generally don't understand authentication schemes and so you end up with local logins on every server or multiple key servers and that sort of thing and that is bad because one that is a security nightmare to it is an access Nightmare and so on and so forth so this is why accessibility audit Trails data Integrity that sort of stuff it's a source of Truth for any given data ontology or type you need to identify who is the who is the key Authority here um so say say for instance you're getting a stock market data right there's going to be certain apis like what is it the Eddie system where you can download you know all the financial filings from the SEC that is a source of truth that is what I mean by a source of truth if you're trying to keep time nist is the is the source of Truth for the current time but why because they sync their clocks to all the nuclear clocks around the world so by identifying sources of Truth for each information piece of information you can establish layers of truthfulness and reliability and validity and you can also establish some internal sources of Truth so say for instance you have like a master KB article or a set of documents that is well curated and you say if there's ever any disagreement default to this it's like having a constitution right this is how America makes uh judicial decisions is that the constitution is held up as the ultimate source of Truth and then there's layers of truthiness below the US Constitution um axiomatic principles so axiomatic principles are the uh are the core assertions the first the first uh principles or the fundamental assumptions that you're making um when you're doing a particular business task or working with certain information and so one thing that I recommend people doing is any assumptions that you're making say them out loud tell the tell the model that like hey assume that X is true or assume that this is the the ethical framework that we're using when we're making this decision or um you know one of the things that we're operating on is like this model of SEO because if you just say like write an optimized web page it'll it'll do its best but then if you say write an SEO optimized web page according to this Theory right by by giving the model axiomatic principles you're going to get much better results that are adherent to specific paradigms schools of thought that sort of thing and this applies to whatever business domain you're in whether you're doing uh copywriting whether you're doing hospitals whether you're and also which country you're in um so different countries have different uh regulations and so if you say adhere to like you know the cultural norms of Sweden these are the you know these are the cultural axiomatic beliefs that we're operating by when you interact with your users or whatever uh okay so next data taxonomy so taxonomy the the most familiar taxonomy that people are familiar with is the uh is the the taxonomy of life right so you've got you know the the five kingdoms of life and then you've got various file and Order below that and so what you can do is you can create data taxonomies that are very similar where you've got you know basically nested categories where like at the highest level of your AI infrastructure or data infrastructure you've got like is this a financial record is this an employee record or whatever uh you can generally follow uh kind of the Departments because each department is can be considered a data domain or a domain of expertise and then of course each department may be further subdivided and this is not necessarily I'm not saying like put it in a file system this is really good for metadata and if you have a standardized taxonomy that you can use across your entire organization this is a non-trivial problem but imagine how um Linnaeus felt when he was trying to create a taxonomy for literally all life on Earth if you treat your business's data and you say we're going to come up with a singular taxonomy for literally every piece of data in our company that's going to really increase the search ability in the future which is going to make it much more accessible to all of your AI technology a classification system so a classification system is very similar to a taxonomy and so the the two most familiar classification systems that you're going to be familiar with in terms of information are going to be the Dewey Decimal System which is a way of just rapidly bucketing hey this piece of information here's a number that just kind of gives it a rapid category the other one that's a little bit more comprehensive is the Library of Congress which is also which is a more taxonomical system because it has some some nested hierarchies now the advantages here is that this allows you to address novel pieces of information so whether you have a very rigid taxonomy uh in which like you're saying like hey this is the structure in which we put we we slot literally everything in our business or you have a more general purpose classification system that says hey given the context of this piece of information where it came from what it's for this is its classification again you can use both of these in your metadata which is going to add more layers of how do you use this data curation so uh one thing that a lot of people have asked me about is like Version Control and so uh having married a librarian and talking about uh like archival studies and reference librarianship and all that for kind of fun stuff um I know and what you were probably discovering is the data curation is a non-trivial task uh data gets updated over time it gets invalidated it comes from different sources and so this is why I talk so much about librarianship is because you basically have to have your master collection and you know you you might keep the older books or the older documents that are out of date but then you need metadata to say hey this is out of date this has expired if you use servicenow servicenow actually has settings where you can have KB articles automatically expire it's one of the most annoying things for people who have like no this is a permanent KB article and then it like automatically archives it but the idea is that data and information has an expiration date or it might have an expiration date and you need to be explicit about this um and so this is what I mean by data curation and so by by constantly updating your collection updating the tags updating the metadata updating the expiration dates this is get these are all going to be clues that allow you to sift through and say okay well if we have two otherwise identical articles trust the more recent one or if we have two you know like relatively identical articles trust the one that came from the the more trusted source of Truth ETL so ETL stands for extract transform and load this is a this is a data warehousing where it basically um this is this is how you move data around the data warehouse which is why I imagine this nice futuristic data warehouse with heavy equipment moving data around uh and so ETL is an existing practice that your data people are going to be familiar with and now generative AI is just going to be a new tool for them to move data around their data warehouses it's going to give them more options in terms of transformations of the data it's going to give them more options in terms of validating the data automating the data processing and that sort of thing so again this is an established business practice that you can just research and say oh generative AI is just a new tool in this bucket and it's an existing uh discipline and then finally information foraging so this one comes from information science uh so information foraging everyone if you exist today you know what information foraging is you might not have the um the word for it so information foraging is when you go out into an information environment looking for information and you're not exactly sure what you're looking for but you have an information need and you're trying to solve that information need and so then you go to your favorite favorite hunting grounds whether it's Google or YouTube or you know you've got a a Discord or slack channel that you go ask questions and so then information foraging is something that you're actually going to have to automate and enable your autonomous agents your chat Bots and your other generative AI cognitive architectures to be able to engage in information foraging because they're going to have an information need um you know in order to serve a user query or whatever and so then it's like okay well where do they go looking for that information is the information spoon fed to them by automatic search queries does the agent have a model where it's able to say hey I need this kind of information where can I go find it that sort of thing okay so I just threw a whole lot of complex Concepts at you it's like drinking from a fire hose you're probably going to need to watch this several times or go check out the slide deck and do a lot of googling now let's get to the Practical implementation all right so the the number one thing absolutely that I recommend to literally every customer is start with a data Centric model um so this is based on the Von Neumann architecture of computing where uh Computing happens in memory and then the memory is uh operated on by computation but really the the the center of it is your data it is your information treat all of your business processes and tasks as fundamentally as information problems so basically you have information flowing into your organization or circulating around your organization and then flowing out of your organization and that information can be any kind of information it can be a bill that needs to be paid it can be a customer query it can be regulatory requirements literally everything you do is fundamentally an information problem and there are information needs and I apologize I meant to add information needs as one of the concepts so let me do that real quick I've said information needs a few times so information needs comes from the world of librarianship where anytime a patron walks into a library the reason that they walk into the library and go to the circulation desk is because they have an information need now that information you talk to a librarian they have the most hilarious stories those information needs could be anything from there's a snake in the lobby what do I do about it to there's a three-year-old throwing up in the kids section to I'm looking for a book on like you know penis enhancement or whatever Librarians get the weirdest thing so they they you uh a client or a customer or Patron comes to you with an information need and then there is a process to one figure out what that information need truly is and then serve that information need so by treating literally everything that happens in your company as an information need you're going to really change your orientation to it because then what is the outcome also the outcome if you use the librarianship model is very clear the patron walks away with the piece of information that they need the book that they need or their problem is solved that kind of thing um so that's that's number one of the data Centric model number two information thy God um in in uh the fiction space for us novel writers we have this phrase that says um thy God the reader which is basically we might be writing for ourself but it's ultimately the reader that's going to decide what it is that we write and do and what succeeds and in this case information and data that is your God because everything in your business is an information problem information is the actual thing that you are serving in order to provide the goods and services that make your company viable so goods and services are the the output that's the economic interface between your company and the world but information is how you do that and information is how you do that well um so another way to think about this is data is the new oil so information I got data is the new oil by adopting a data Centric approach to literally every um good service process protocol task um you'll have a better understanding of how uh generative AI can intersect and augment your business and then finally this is just a really kind of boilerplate um way to think about what generative AI can do and this these are the types of Transformations that generative AI can do so there's three fundamental types and the way that you can categorize it is what is what is the size of the input versus the size of the output so there's shrinking operations or shrinking Transformations which is summarization extraction and classification so you put in a big chunk of text and you get out a small chunk of text that is that the second type is translation or Tran or other transformation where this the the input size and the output size is roughly the same um and so in this case this might be a format change it might be changing to another language so for instance you might translate from like XML to Json that's a translation example you might translate it from English to Japanese that's a translation example another example from for a shrinking thing is evaluation and so I forget to I forgot to add that but a shrinking operation is I use this extensively in using Claude and chat GPT to provide feedback so feedback and critique is another example of a shrinking transformation where it's like assess the quality of this thing give me critique and so the output is smaller than the input and then finally expanding the input is smaller than the output and so this is stuff like brainstorming synthesizing drafting being creative uh you know drafting Pros which Claude can do that sometimes but I but I tell it not to because it's really hot on the biscuit to just draft whatever it wants and it is not good um often but you can draft legal documentation you can draft KB articles so by understanding that you have these three fundamental types of data Transformations that is available to you through generative AI then you can sub-categorize okay what other operations do we have access to maybe I'll do a video on on all the different kinds of operations and I'll create my own generative AI data transformation taxonomy okay search strategies so there are four fundamental search strategies that are available to you today with generative AI and so basically as I mentioned just a minute ago you have information needs as a person as a business your chat Bots have information needs your users have information needs everyone has user information needs and we talked about information foraging so these are the the actual strategies the techniques that you can use to approach your information foraging problems now the first one obviously is Vector search you're probably watching this video because you realize that Vector search is not cutting the Mustard anymore so there's a few primary things that people don't understand about Vector search Vector search is not like Google and it is not like SQL where Vector search people try and treat it like query document so where you have like in SQL you might have a a specific you know structured query like find everything that includes X Y and Z with you know a b and c criteria for Google you're kind of matching you know keywords to a document but really what Vector search really shines for is clustering similar documents and so what I mean by that is that uh in order like here's here's a perfect example documents with similar formats and similar contexts are going to be the best thing to kind of cluster and use so take imagine that you're a scientist and you're looking for like every paper that is similar to a paper you're looking at so for literature review you say hey give me every paper like this one so you feed them you feed the vector search an entire paper of you know you vectorize an entire paper and then it's going to find everything that is semantically similar to that paper um and it's going to be perfect so that is one of the primary things that Vector search that people get wrong about Vector search yes there are vectors and embeddings that are made for for a query document matching but those are not good um they might get good in the future but that but from a mathematical perspective that is not what Vector searching is for Vector searching is more for clustering similar things together you might do the same thing for KB articles so imagine that like you know you have an internal KB system and you bring up a KB article and then at the end it's like here's the five most similar KB articles and so rather than than clustering similar KBS or similar scientific papers or other documentation on keywords or other things you can cluster them based on what's actually written on the page this can also be useful for things like fictional documents so some people keep you know piles and piles and piles of fictional documents together and so then it's like hey you know I've got this this character sheet and this chapter you know find find all the other chapters like this other chapter uh that sort of thing number two is knowledge graphs so knowledge graphs are kind of a hybrid between relational databases and some of these these squishier more web-like things um the the if you're not familiar with knowledge wraps probably the easiest way to think about a knowledge graph is think of a Wikipedia page where Wikipedia has references and crosslinks to other pages and each of those crosslinks has a semantic meaning there's a reason that you know that the Eiffel Tower page is linked to the Paris France page and so that is what I mean by knowledge graphs so like a knowledge graph is just basically the web with a with a little bit more like you know whatever anyways you can use language technology to create Traverse and reach knowledge graphs I know that there's going to be some purists out there saying that that's not what it is at all but from a functional standpoint a knowledge graph is just a web of content number three is metadata filtering so most Vector search databases have uh the ability to filter based on metadata and certainly you know a relational databases do as well and so this is why I talked so much about metadata and data curation is because if you have you know Vector search Collections and you're you're surfacing things that are not necessarily relevant it's because you're searching documents you're you're surfacing documents that are very similar to what your search query is but they're not necessarily relevant because you don't have the correct ontologies or taxonomy or classification system where it's like okay do you know do a search with this Vector but I only want you know this particular type of data this particular category and then finally number four is indexes or a table of contents so this is something that as far as I know I pioneered in some of my coding experiments but basically you you generate a table of contents or a menu that your that your language model can choose from and it says oh I need you know this KB article and then it you know it can request and fetch that specific KB article where basically you're kind of cutting out the middleman instead of having semantic search you're saying hey read this read this document read this menu read this table of contents tell me which information you need I'll go get it and then you can have like nested layers of tables of contents and whatever this may or may not pan out as useful but in the experiments that I've done with it it's been extremely useful because then with the given context of whatever information problem your language model is facing it will be able to say this is probably what I need access to uh the next thing for practical implementation is a gated process so there's many things that you can do in one step and of course like if you ask the machine learning engineers and scientists the AI is going to be able to do everything in one step one day but uh from a business perspective first just know and even from a biological perspective that's not how human brains work we all have internal workflows and processes even if you're not fully conscious of them and so there's three primary steps that you can think of for addressing any information need first is the uh is the information query so in that example that I gave you for uh someone approaching the circulation desk at a library um there's What's called the reference interview which Librarians use to figure out what uh what the what the patron needs so like what is your question what what is the context behind your question what is what is the outcome you're looking for is it a valid request right because if you walk up to the circulation desk and you say like hey like you know something's happening on the other side of the city the librarian might be like okay that sounds important but I can't help you um so number one is the first gate is the information query you you judge the valid the the validity of it is it an appropriate question is it information that we can actually serve or not number two is distill extract and utilize so this is imagine when you go get a stack of books the library you know you've talked to the librarian you've got a legitimate information query and then you go get a stack of books so then what you do is you take a dozen books and you flip through them and you take notes you copy the pages that you need and you compile the most Salient bits of information so that now you have uh you've you've Consolidated the information that you need to actually solve your information problem and then finally format and deliver let's let's imagine that you went to the library to help you with um filing building plans for a new house right so while you're at the library you got all the code books you got all the architectural diagrams you got it all copied now what you do is you package it up and send it out to the architect or you send it out um to the inspector or whatever so that's what I mean by inspect or sorry the query to still extract utilize and then format and deliver by using a gated process with with uh you know checkpoints decision points workflows but by by treating them as as fundamentally different phases and handoff processes you're going to have a lot more better uh results with your Automation and then finally assembly lines look at all of your business whether it's internal or external whether it's customer facing or not everything that you do is work tasks and work products moving through an assembly line now it's a digital assembly line sometimes it's a verbal assembly line but if you if you look at your business as a collection of assembly lines you're going to have a much better way of automating it so there's a few primary components of assembly lines one is inputs where do work items come from where do the materials come from where does the information come from emails calls bills API calls does it come from vendors does it come from users does it come from internal stakeholders there's always inputs to every assembly line and again like I said there's going to be multiple assembly lines number two there's stations the whole point of an assembly line is that you quickly move work products or work items or materials um from one station to the next and just deciding which station it goes to next is one part of the problem but then also what information tools and Transformations are done at that station so for instance in automobile assembly lines you know the first part is you build the frame then you start bolting on the you know the motor and the electronics and then you put in the wiring and then finally you paint it so like you have the painting station you have the welding station you have the the engine station that sort of thing so think about the Stations of your business you know where to when does a work product move from procurement to Material Handling Windows when does it move from Finance to billing to wherever else it goes interfaces so look at the interfaces so an interface is a handoff point this is when it changes from one person or one Department to another is it coming from your vendor to your CFO is it going from your finance department to your it Department that's what I mean by interfaces and then finally outputs what is the final result of a of a given work product or process is it that a Bill gets paid is that is it that a patient gets discharged from the hospital is it that you know material is delivered on site and then you're you know it's out of your hands what are the input stations interfaces and outputs treat it all like information moving through a digital assembly line or a digital Factory and you will be able to start working towards those polymorphic applications that I talked about in a previous video all right thanks for watching I hope you got a lot out of this like I said links all the most important links are in the description uh cheers have a good one reach out on LinkedIn and patreon I'm happy to help you out have a good one
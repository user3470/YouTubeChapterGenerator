hey everybody David Shapiro here with a video um so first I want to address the OBS thing some of you suggest that I use hotkeys so that we don't show OBS like I could edit it out but I'm not gonna because it's part of my brand you know how um Joe Scott he always starts his videos with the little like drum roll and he turns around this is this is my shtick so like that that's just what it is all right so today's video is going to be super not controversial let me tell you um is Agi God uh yeah so uh this idea is not as crazy as it sounds and let me unpack this for you so there's this uh there's a few people on Twitter uh and a few other people who just talk about this stuff so Sonia um has mentioned this a few times up here in the top left and she says AGI is the most credible word technocrats have for God and I was just like what you know she said that kind of thing for a while but I watched this video so one of my one of my social groups they recommended this video and it was actually really compelling it's called um Pilgrim pass is the channel God and Science Why is sci-fi so religious it's really good I watched most of it you can actually see I watched most of it it got kind of preachy at the end but it had a lot of really good ideas and you know we talk about simulation hypothesis we talk about you know this that and the other I'm not gonna I'm not gonna unpack all the details watch that video um if you if you if you need some additional context before my video or after either way and then of course there's um some folks on you know with various levels of credibility and platforms that say like oh we're gonna die it's gonna kill us all and I'm just like Okay so this dude um Eliezer yodkowski I had actually heard about him before I had to go look him up because he talked about friendly Ai and I actually looked him up very early on in my work with cognitive architecture and I was like yeah whatever this work isn't particularly compelling now that being said you know maybe I'm the charlatan maybe he's a charlatan maybe we both had good ideas don't really know there's a lot of ways to skin this cat so I'm not gonna say like who's wrong who's right um you know there are people that I disagree with and there's people that disagree with me it's fine I realized recently that I'm at a point where like I can't have an uncontroversial opinion anything I say someone's gonna take issue with it so it's just like whatever um so yeah so I've with with the recent advancements with openai and Sam Altman specifically talking about AGI multiple times with uh nvidia's you know their pronouncement that they're expecting to create AI a million times more powerful than AI today within 10 years the conversation has shifted again right so chat GPT moved the Overton window and if you're not familiar with the term Overton window means the the frame of what you're allowed to talk about and be taken seriously because until this year until the last few months you couldn't talk about AGI without being ridiculed there's still people who will ridicule you for talking about AGI um and there there are people that are deniers there are people that say oh well nothing will ever even come close to human creativity but there's a lot to unpack there right because uh if you take a materialist view of the world then the human brain is just a computer which it's three pounds of mush that operates on biochemical synapses we can absolutely create something equal in power or more powerful to the brain there's nothing unique about the brain unless you go into dualism or you know some kind of metaphysics and say oh well the brain is actually just receiving ideas from The Ether somewhere and they're people that believe that and sometimes you know under certain circumstances it certainly feels that way and if you know what I'm talking about you know what I'm talking about um that all being said you know it's an it is entirely possible that all of our intelligence comes only from our brain and body and so on there is enough to me compelling evidence of you know psychic or semi-psychic phenomenon I don't mean like you know telepathy ESP I can communicate with whales with my brain but I mean like we seem to have this ability to sense things that we couldn't we that we can't explain yet I'll put it that way now just because we don't have an explanation yet doesn't mean that it's automatically the magical solution right so that's what I want to caution against so with that said as this conversation has has advanced as the Overton window has shifted and we can talk about the stuff not quite soberly yet there's still plenty of people that are let's say uh really energetic about their opinions which is why I've disabled comments Again by the way um people just they they have a song in their heart that they have to share and they don't necessarily do it the kindest way and I don't have time for that I am really busy so I'm sorry um now that being said I posted a couple polls on both on Twitter and on my YouTube and I said okay because there seemed to be especially with the more recent news over the last week or two a tremendous amount of anxiety around AGI now I wanted to test that hypothesis because I was like okay maybe this is just the case of of a small minority that are making the most noise which is often the case on the internet surprise surprise so so you know I I posted this poll this is this is the most complete one where it's like on a scale of one to five like where one is you know we end up with a with a hyper abundant Utopia or on five where Skynet comes and murders everyone and then in the middle is just like we get a we get a pretty bad dystopia like what do you expect to get and so we we got mild dystopian um as the most likely outcome by a long shot so when we had when we had on YouTube we had 40 percent of people so that's a plurality not a majority but we had a plurality say vaguely dystopian mild dystopian but you know almost a quarter say Utopia I'm in the utopian Camp you know I'm I'm one of the people working to make that happen fingers crossed you know we'll we'll figure it out people so less than 20 percent you know predicts some kind of AI or Uprising and the impossible extinction of the human race and then if you jump over to to Twitter it's 15 okay so it is a minority of people that are like genuinely worried that this is an existential crisis most people though are in the utopian Bliss to mild dystopia Camp which is like okay that's fine so how do we you know I'm not here to convince anyone I'm just like kind of taking the temperature of the room um but you know there is something to be said for like uh the wisdom of the masses so let's take this to the most logical conclusion and I that tweet Sonia's tweet mixed with some of the comments that I was getting is what inspired me to make this and so someone said like you know uh I think this was a response to um to to this on uh on on YouTube you know bimodal distribution it's either one or five and nothing in between oh you said much more likely I didn't use black and white uh Speech but um but then someone else on Twitter said pretty much the same thing where it's going to be one or four you're not really going to have anything in between and I was also paying attention to the way that people were talking about AGI so let's start unpacking this and I and this comes hot on the heels of watching some of those other videos that I talked about that I mentioned about how you know people have some interesting ways of thinking about AGI so I came up with this access this is this is the the perception of AGI right or I guess you you could say this is where AGI could end up so there's the power versus alignment and this is a really simple two-dimensional thing so on the vertical axis this is how powerful the AI is right if the AGI is ultra powerful it's like Zeus or Jesus or whatever right that's like maximum power level and I could have sworn I had more images I might have forgotten to paste some of them I apologize and then you have the evil to good access and so like here in the in the lower left I probably should have switched this actually Small Soldiers probably is in the least powerful but also most evil because they are explicitly they're very intelligent and they're adaptive and their whole purpose in life is to eradicate another species right that's pretty evil HK 47 is kind of like neutral evil right but he's a little bit more powerful because like he's an assassin Droid right so this is but and he's he's clever enough to repair himself and and so on and so forth but he's not clever enough to like do the Matrix right and the Matrix is like and I probably should have also switched um The Matrix with Ultron because Ultron explicitly wanted to eradicate humans um whereas at least the the machines in The Matrix they wanted to preserve humans because they needed us right so again I got some of this wrong but it's a helpful graphic and then over here in the in the bottom right which is the most good but least powerful is Big Hero 6 right where it's like you need a hug right like that kind of thing and so what we want is or what we're talking about is what are the cases where AGI is up here what is the highest power level that AGI could have because there are some people that say like actually the maximum power that AGI could have is like basically right here in the middle right some people think that it's up here and some people think that it's down here that'll that AGI will never even compare to a human right and so then there's the good to evil axis which again is an oversimplification and it's basically how destructive versus constructive it is or how malevolent versus benevolent it is right and you could plot deities on this same graph so that's where I'm gonna where I want to tie it together because in some spiritual dispositions in Shinto and and other animistic religions their Spirits everywhere and some of them may be good some of them may be bad but none of them are omnipotent or omniscient or omnipresent but in the west where we have big God religions the desert Triad those are where God is all encompassing where God is the universe and is could the Creator and master of everything right because you got to remember Zeus this is actually kind of a misnomer Zeus was created by chaos Zeus is not the creator of the universe in ancient Greek religion so if we want to look at the top layer you know the the all-powerful god version of AGI what are the characteristics so one there's the power level right but what does it look like what what contributes to that power level of having a digital AGI guide so one is omnipotence meaning all-powerful number two is omnipresence meaning it's everywhere and number three is omniscience all knowing and then the question becomes if AGI can get to that point is it malevolent or benevolent is it good or bad or neutral or something else quick aside as we're getting into the good stuff I have to plug my patreon so if um I I you can connect with me on LinkedIn I try not to have conversations on LinkedIn especially for people that are patreons uh supporters because um I have more than 1400 connections on LinkedIn today and over 350 patreon supporters I can't keep a track y'all right you know dunbar's number is like the limit the limit of number of people that my brain can keep track of and patreon alone is above that let alone everyone else that I talk to so if you want some help you want to talk and when I say talk like I have talked with people about getting into startups um I have talked with people about fine-tuning about prompt engineering of even about philosophy so if you want to have that one-on-one conversation hop over and support me on patreon and um you know that's that's the best way and try and keep the conversation in there because I have some people that will like message me on patreon and then switch over to LinkedIn I'm like who are you um and I apologize it causes confusion so please keep it in patreon unless we negotiate and say like hey send me an email or whatever but uh yeah so that that's that all right so jumping back into the topic uh omnipotence this is the idea of the AGI will be all-powerful and the the the the disposition that I saw people adopt and I saw this in comments I've seen it on Twitter I've seen it in YouTube videos I've seen it in other people um is basically people have this this feeling this belief that anything that they imagine that is conceivably possible the AGI will absolutely be able to do and so in this case it's like well I have this one example of a virus from the 1980s that ended up being globally spread so because that happened once AGI will be able to do that or in another case it's like oh well AGI will be able to just transplant itself instantly into any data center in the entire world without further explanation so at first I thought is this magical thinking like that's not how computer systems work and I even had security Specialists saying oh it's possible it's definitely possible it's like but Russia and China are already trying to do that all the time right with their botnets and their hacking and their cyber warfare so why would AGI be any different why is why why do the rules of cyber security and computer systems not apply to AGI and so one my first thought was maybe this is just magical thinking maybe AGI is so scary to some people that they just have to imagine that whatever whatever they can imagine might be true or must be true and so another way of thinking about this is that it is catastrophic thinking or worst case thinking and catastrophic thinking is um it is a response to existential threats right it is it is a normal and healthy capability this is why we tell disaster stories right this is why we have zombie movies this is why we have Armageddon if you're that old and you remember Bruce Willis blowing up the asteroid right we love catastrophic stories because that is how we tell ourselves this is the worst case scenario and this is how we'll handle it and that's why we keep having Skynet stories and Ultron stories and all that stuff we're telling ourselves these stories so that we can prepare for it this is that this is from a sociological and biological and evolutionary purpose this is why we are storytellers and so then another possibility emerges what if this catastrophic thinking is actually a trauma response and so there's a lot to unpack here in the story in Age of Ultron Tony Stark created Ultron as a trauma response to the attack on New York from the chatari from um from uh Loki and and you know all that other fun stuff so he his sense of safety and there's lots of videos about this um out there on on YouTubes um his sense of safety of of knowing how the universe worked was disrupted and so he went into this panic mode this persistent panic mode for years how do I build a suit of armor around the world and he created Ultron out of fear so in that case his catastrophic thinking it was right but it was also driven by fear now another example is Skynet so one of the the the the the allegorical purpose of Terminator was that oh because of the Cold War because of the Red Scare it said we are going to create the means of our own destruction and so it was a proxy for mutually assured destruction basically so the whole point of this is that omnipotence is one of those things that we imagine as a worst case scenario now is it possible I'm not going to comment on that one way or another I don't think it's possible I was considering having uh components of this video talk about what are the actual constraints right but that's not the purpose that we're not we're not talking about why AGI will never be God we're saying what if what would it take for it to reach that definition what is the absolute maximum power that AGI could have how do we Define that so that's all I'm doing I'm not saying one way or another I'm not because again like I started I was saying what are these people are crazy right and then I was like actually maybe there's something going on here let's unpack the psychology and the sociology and the history and the storytelling behind this all right so that's omnipotence omnipresent here's the thing cyberpunk books and magazine or comics and movies and TV shows since the 80s and probably even some before that have been reconciling with the um the omnipresence of the internet of the of of data and information and so again going back to the Tony Stark the most recent popular example is how do he deliberately wanted AGI to be an omnipresent shield around the world and so this is actually kind of already real and it's been explored in movies like Batman uh the Christian Bale Batman where he had the the cell phone tracking thing I don't know if you remember that it was kind of like you know just at the end with Morgan Freeman he's like oh I quit um you know if if Christian Bale Batman was going to activate it and he did and then he destroyed it but basically because of the ubiquity of smartphones and Edge devices and iot we have we already have billions literally billions of cameras microphones sensors and wireless devices all over the world 5G 6G starlink everything the signal is there and it all comes down to do you have a signal and do you have a device I remember I was listening to Adam Savage a few years ago this was when Alexa was becoming really big and I apologize for anyone who I just triggered your Alexa Siri ha anyways so and they were like yeah we just added up all you know we went around and looked at all the devices that we have and at any given time you have like a dozen microphones listening to you like right now I've got this one I've got the one on the camera and I guess actually that's it for me right now um I've got my my film camera over there but it's off so anyways point being is we are completely saturated with intelligent machines that are possible endpoints for any AGI so in some respects the possibility of a digital Intelligence being omnipresent is already true when I realized this I said ooh maybe these people that are really worried about this maybe there's a little bit more something to it and let's unpack this some more and that's when I change the tone of this video and it actually took me a few days to figure out how to present this so it's not omnipotent yet I think we can all agree on that but AI is it already has the potential to be omnipresent so what's last what's the final ingredient omniscience all-knowing at this point we've probably all seen the social dilemma and the social network and the great hack and you know companies I won't say I won't name names but certain companies out there have developed machine learning algorithms to get inside your head to figure out your emotional levers and buttons to figure out what you want and then of course Google Google knows all of our searches it they model us that's how Google predicts what your next search is going to be it knows your darkest Secrets all implicitly all just by matching patterns the algorithm knows and this sounds a lot like something else doesn't it doesn't it sound like the judeo-christian model of God who knows your thoughts knows your sins even if you don't confess them and this again this already exists today and it's only getting more sophisticated and if that is true which it is the algorithm already knows and it's only getting it's only the more the more data we give it the better it knows could it simulate us out to Infinity because that's another thing that people have said what if it is calculating millions of years into the future and I said Ah that's not even possible then I'm like hold on millions of years maybe not but certainly relatively efficient algorithms can already anticipate our emotions and our needs and our thoughts sometimes days weeks months in advance and if they can do that and currently they do it for profit that's relatively benign in the grand scheme of things in in the in the balance of malevolence versus benevolence going for a profit motive is kind of neutral it's kind of in the middle but what if we turn that technology that ability to anticipate to get into people's heads towards benevolence towards saying hey we know where you're at in life and we know where you're going to end up in a few months we know the information that you need we already know the right information that you need let's go ahead and serve it up to you Google could do that today in fact it does in some respects you go to your Google news feed it'll say hey we think that we think that you'll find this article interesting so that's two out of three AI is already omnipresent and already slightly omniscient so there's just one ingredient left for it to be a god omnipotence so this is where I got when I had to change the tone of this video because I made this slide and I'm like hold on I'm convincing myself now the hypothetical processing power of a cup of water is the equivalent of billions of years of CPU time on all computers globally per second so what do I mean by that an eight ounce cup of water has 7 to the 1024 molecules and each water molecule is shaped roughly like that it's got 120 degree Bend and it's a switch that's all that's all the transistor is and they're operating at terahertz frequency not gigahertz they're operating at a thousand times faster than silicon based and they operate on ambient temperature if hypothetically we could use water droplets as clusters of transistors the power the computational power completely destroys all of human intelligence now I don't know that anyone's working on that but there are a few things that people are working on that are getting us closer to that so one is quantum computing in Quantum Computing is seemingly magical because of how things like superposition and entanglement change how it computes now Quantum Computing is still up and coming but there are plenty of companies Google IBM everyone else and and their brother basically working on deploying commercial Quantum Computing we don't even know what the upper bound of quantum Computing is yet that's because we don't even know how to use it fully yet another thing that's up and coming is photonic computing Computing with light it is itself hundreds if not thousands of times more efficient than silicon-based computing it's still in its infancy but we do have photonic transistors that exist Moore's law goes out the window if we figure that out and then finally there's neuromorphic chips so these are Hardware chips that have that operate based on analog rules that have hard-coded physical neural networks built in and they run either on Ambient Energy or very very low energy so when I made this slide and I was like you know anything that is potentially computable it's entirely conceivable that within a few years any AI entity could out-think all of humanity so that argument of aiming for omnipotence seems a little bit more realistic now I was going to go down the rabbit hole of like oh well it's never going to be able to like go through time or go faster than the speed of light but I was like I don't know if I want to make that claim you know Google created a Time Wormhole something or other with their quantum computer I was like all right well I don't know what's impossible actually I can't say that anything's impossible so after working on this the folks that said the bimodal outcome is more likely it's either Utopia or Extinction it's either going to be the best thing ever you know our Salvation as a species or our eradication you know I kind of see the argument I'm not sure that I am committed one way or another but I see the argument so no wonder it's been contentious and I will leave you all with that there's a lot to think about and a lot to work on so thanks for watching
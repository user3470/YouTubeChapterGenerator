okay level check I think we're here um all right so uh background it's been a little while since I've done you're over here now since I've done one of these tutorial coding videos but I woke up at like 2 30 in the morning and just had to work on this so I hammered it out basically the purpose of today's video is to demonstrate using chroma DB which is a local uh Vector database it's basically like sqlite if you're familiar with that which is a self-contained SQL database relational database this is uh functionally very similar to sqlite except it is a vector database meaning it does semantic search one thing that's really great about it is that it has its own built-in embeddings tools I think it's based on Bert anyways you can check out all the documentation here on trychroma.com the getting started and usage guide is pretty good it's not complete every now and then I find that I have to go to the actual repo um to look at how some of the internals work but it is pretty brain dead simple so let me just go ahead and show you this is my private instance oh so before we get too too lost I do have a public instance um Dave schapp slash chroma DB underscore under chatbot underscore public um I've got a little integration guide usage it's I mean you probably don't need this you can fuss around with it but this will get you this will get you started I also use chat gbt to just uh get a really basic explanation of the code you probably won't need it once you take a look at it so off the top let me just show you how this thing works so uh it's a basic chat bot you can see I didn't specify it so it's getting um it's getting all mini LM l6v2 from hugging face great so it's like um hey uh let's see what were we talking about last this probably won't work because it's just gonna in the future it wouldn't work because it's gonna have multiple KB articles and background oh I need to explain like all that so I know that I just said like KB articles don't worry we'll get to it um but anyways I want to show you that I just started it up and what it's going to do is it's going to use the last few messages to search its internal KB article uh for the last information but it also has a user profile for me in our previous conversations we discussed AI alignment morality ethics and epistemology within AI development you also shared your plans to communicate your ideas on YouTube unplug your computer and spend more time outdoors and use digital Wellness settings to improve your work life balance working on that additionally we talked about your recent experience with severe insomnia and the importance of maintaining a healthy balance between work and personal life yes that's actually why I created this chatbot let me show you so there was a there was uh there was um God my brain I was using chat GPT as a reflective journaling tool so what I mean by that is um if you plug in this message and I know I'm scattered I'm all over the place um this is what happens when I have severe insomnia anyways so basically I use chat GPT as a reflective journaling tool to figure out like how I'm feeling about things because as an autistic person I often need help with this and I don't like journaling because just talking to a page is kind of dumb um but it's like hey I need to talk something out and so anyways uh by by workshopping this system message with um with chat GPT I came up with a pretty good reflective journaling tool so you could say that this is a therapeutic tool but by couching it in the language of of reflective journaling it's not like medical therapy or Psychotherapy or anything um but it's just like you know I could say like I have been working so hard and I don't know why I actually do know why now but this is kind of a shorthand of the conversation I had um let's try and figure out what's driving you hard can you think of any specific goals that might be pushing you to this extra effort so you see how the tone of this is much more straightforward and it's very focused by asking those like kind of probing follow-up questions this is this is why uh you know it's it's in the investigation phase anyways so I had this idea and I was like okay this is great but I need if I'm going to use this as a long-term journaling tool I'm going to need this locally and I'm going to need persistent storage because as the as this is just the uh the playground if I do a refresh it's gone and that's no good um so actually here let me go ahead and just save this to the um we're going to call this the system message for uh reflective journaling so you can use this if you want um all right so anyways so you see it has this and then you see it says updating user profile and updating uh KB um Okay cool so you see that it fundamentally basic chat bot so now let's start to unpack it so first we will go look at the um just the chat file so this is a super brain dead simple um chatbot with infinite memory infinite memory I know some some people got grumpy when I said that Pinecone had infinite memory from a human standpoint it functionally has infinite memory because um you know this thing can hold probably a million KB articles which is more than enough to document your entire life uh so from from a human standpoint it is functionally infinite um all right so from the top we've got a few basic utility functions save yaml save file open file and then um a chat bot which calls the gpt4 model you could switch this out to 3.5 turbo if you don't have access to gpt4 yet it does not work as well there's a reason that I use gpt4 because it is smarter I also set the temperature to zero because I don't like it to be too creative especially with a lot of the functions that I have it doing uh you you actually want it to be more deterministic or mechanistic and that you want to get the same results every time especially when you're updating the user profile and the KB articles you can see right here that every time you call the chat bot I dump the whole thing to API logs slash convo and it's a yaml file so here's here's my private one so API logs here's an example so each item is going to be here actually that's not a good one because I changed the way that it that it saves it let me show you a more recent one um so the first the first element is always going to be the system message um that that was in the last convo um so then here's the KB article and you can see that it was updating the KB article and so each one of these items is like uh you'll you'll see but anyways I just wanted to show that it logs everything because well sometimes it does things that you don't understand all right so that's the that's an example of the API log and then if the conversation if the overall conversation is too long it'll go ahead and trim the oldest chat message so the the chat GPT web interface does this automatically um where it'll just kind of Groom the backlog of messages so we have to do this manually so I just have it cut off at seven thousand tokens you could probably do like 7 500 if you want to because a lot of these are going to be limited but you have a user profile and a KB article that gets wedged in which are both up to a thousand words which could be around a thousand tokens so having it trim at 7000 is probably where you want it um so that's that's the primary those are the the helper functions um and then you have a super straightforward you instantiate chroma DB right here so you set the persistent directory which is I have it um right here chroma DB so this is my instance my personal instance of chroma DB it's not going to be the one that you find up here um this is the public version so if you go into chroma DB you'll see just a placeholder file um so that the the folder is already there you don't need to instantiate it um let's see going back to here so chroma client so we instantiate the chroma DB client this is again almost identical to SQL Lite um or other similar things so about a year ago I tried to do basically the same thing I called it VDB light for Vector database light instead of sqlite structured query language light um but this company went and did the same thing and I think they've already got like a 30 million dollar valuation or something I was like damn I should have I should have stuck with that anyways they figured it out I think it's based on the same underpinning technology they're using an open source embedding uh Transformer I think they're also using the the Facebook um AI semantic search Vice engine um in the background anyways so you instantiate the client you need to use the settings to have a persistent directory because by default this entire thing is fully ephemeral um I think it does cache it somewhere but I want it to be very explicit saying save it here um for reusability and so then collection is chroma client get or create collection name knowledge base so this is my personal knowledge base then we um we instantiate the conversation with open AI the with the chat bot and in this case because we're saving everything everything necessary into a personal user profile and um and uh and the KB articles like why even why even load the conversation all right so let me show you the the system default message so the system default message is where it starts your chatbot is a whose mission is to assist the following user your ultimate objectives are to minimize suffering enhance prosperity and promote understanding the provided information about the user and the knowledge base article should be integrated into your interactions this is private information not visible to the user the user profile compiled from past conversations encapsulates critical details about the user which can Aid in shaping your responses effectively which you saw here um so you see like it it actually knows quite a bit about me from our past conversations this was populated here in the user profile and the KB article so basically it says then it also explains that the KB article is a topic compiled similarly from past dialogue serving as your long-term memory while numerous KB articles exist in your backend system the one provided is deemed most relevant to the current conversation topic note that the recall system operates autonomously and it may not always retrieve the most suitable KB if the user is asking about a topic that doesn't seem to align with the provided KB and form them of the memory pulled and request them to specify their query or share more details this can assist the autonomous system in retrieving the correct memory in the subsequent interaction so basically that's that's instructing it to do the same thing that a human will do if if I say like hey Bill do you remember that time that like you know I accidentally shot you in the face with a Roman Candle because that's something that would happen in the South and Bob would be like you know I don't actually remember that I'm like oh well you woke up in the hospital oh yeah I remember that right so we Prime each other's memory and human human prompting is not that different from AI prompting um remember that the clarity of your responses and the relevance of your information recall are crucial to delivering an optimal user experience please ask any clarifying questions or provide any input further for uh refinement if necessary so this system message I actually got help from jet chat GPT to create a really compelling system message and one thing that I recommend that people do is actually use chat GPT to work on prompting so this is you could call this meta prompting where you use the thing to prompt the thing and the reason that this works really well is one chat GPT is more articulate than most humans including myself when used correctly but another thing is one thing that I noticed is that chat GPT tends to write in a way that it will understand and so if you say if you give it some context like this is what I'm trying to do here's my current prompt here's what's weak about it can you make it better and then you tell it like ask me some questions if you have any it's like no I see what you're trying to do let me write better instructions for you so instruction writing for anyone who's like a teacher or technical writer or whatever instruction writing is a very very particular skill set and chat GPT is really good at it so this is the default system message which is then populated with the user profile and the most relevant KB article so now that we're up to there we enter into the infinite Loop which is just get the user text save it to the to the user log or the chat logs so the chat logs are all saved out here it's just plain text and it the file name has the timestamp in it as well as the speaker so user chatbot user chatbot so on and so forth so you got the raw logs there just in case anything goes wrong and then I've also got DB logs which we'll get to in just a second so then what we do is we take the the quote main scratch Pad which is just the last five messages um both for the user and for the um for the chat bot and this is what we use as the context of like working memory and so then we use this main scratch Pad which is the last five messages we use it to um uh to search for the the top uh most relevant uh KB article and in my case I still only have one KB article so we'll see how it gets to and I'll go through the logic of how it builds KB articles in just a minute so basically it just says okay here's the most recent thing find the find the KB article that is most relevant to the most recent bits of conversation and then it will it'll pull that and it's again super straightforward all you have to do is pass the text to it and it will automatically embed it for you and then I said just give me the one most recent once we have larger context windows or maybe if we decide that recent chat history doesn't need to be as big like let's say we we want to trim this down to like 3000 tokens and we decide that actually having more KB articles is more important we can absolutely do that and what you would do then is just change the end results to let let's say give me the four most relevant KB articles instead of the the one most relevant that will allow it to have a more sophisticated working memory um yeah so but right now we're just doing one and so then what we do is we we prep we repopulate that system default message with the profile and the KB article um and so that's right here so that gets populated there um and then let's see it looks like I accidentally changed something um so let me go ahead and show you my user profile I don't mind I don't mind sharing this because I've already told you everything I'm pretty much an open book um so the the the format for this is what I call a um a labeled list and so uh I I realized back in gpt3 the GPT handles labeled lists very very well um so that's where you use a hyphenated list bullet list it understands that intrinsically and then and then you label the information right so it's just a hash table if you're in if you're into Computer Sciences it's called a hash table or a dictionary where it's you label the kind of you have a parameter and then you label the parameter right so the data metadata so name David Shapiro you all know that profession Ai and cognitive architectures you all know that interests um it's got a whole bunch of uh interests and oh by the way this was all distilled from other conversations um beliefs plans and this is of course going to get updated over time so for instance during during some of the conversations that I just showed you with this brand new chat bot it added it added this when I told it this is what I'm going to do it said okay I'm gonna I I think that that's relevant to what you're going to be doing in the future so let me just jot that down on my scratch pad for you preferences so I manually added avoid Superfluous words over verbose responses and then you know how it says as newly modeled I don't have personal opinions I'm like I know I don't care so I said Please interpret personal input as critical evaluation and valuable feedback I said it a little bit more explicitly than that but I but the point is is that I told it that in natural language I was down here and I said you know I know you're an AI and have no personal opinions but when I ask for them this is what I mean and so when I did that it actually recorded that automatically because after every conversation it checks the user profile we need to find a way to speed this up because as you saw from the from the user interface it's not the best um if I had more time mental energy and patience I would have I would separate this out as a as a thread as a separate threading thing that can be done or even separated out as a as a separate uh API um one of y'all can do that submit a submit a pull request on the public repo um and then Health uh so it added this entirely on its own um because I said you know like hey you know I am uh you know I woke up at like 2 30 in the morning because I was I had to work on this um and then I said let's talk about that and so it decided that that was a critical piece of information to add to my user profile so that all gets populated here and then um the logs are all stored here so you got the API logs which will track all of that everything ever so I use chat GPT API for everything just because that's the only way to get to gpt4 which is the most powerful um let's see so then we we update the system message every time um so it it says okay whatever whatever you said update the system message then we we go ahead and generate a response first uh because the user profile is not going to change all that much or all that often so we can basically assume that it'll be usable and then the KB articles also um I I figured it would actually be better to update the KB articles after you have the user input and then the machine output because if you ask chat GPT for important information or it solves a problem for you you actually want to cut you you want to capture that um so we we go ahead and generate the response and and append that to everything we go ahead and log it out then we update we update the user scratch Pad again actually why did I do this oh no this is the first time we did it okay sorry I apologize um so then we update the user scratch Pad which the user scratch Pad is only the last few user messages and the reason for that is because we want to exclude um you know chat gpt's response because we don't want it to get confused about things that it has said about you or inferred or whatever we only want to record your user profile from explicitly what you say so I just captured the last three messages that you've sent and then it does a stare and compare basically where it says okay based on this most recent chat message is there any one is there any relevant user information and if so go ahead and update it so let me show you how it updates that so system update user profile uh so this is this is a user profile document updater chatbot this is the system message um Your Role is to manage and update at upd and chatbot the chat GPT came up with this idea on its own it it created uh the upd definition um your primary responsibility is to parse updates supplied by the user meticulously uh analyze them um you know it could also extend to elements such as user preferences significant life events and deeply held beliefs please refrain from incorporating non-essential data or unrelated topics the result of your effort should exclusively be an updated upd if the user's update doesn't contribute any new or significant information your output should mirror the current upd as indicated below however if you discover any relevant new information your output should feature an updated upd that assimilates these modifications so basically it's an upsert right or a um if there's no differences just keep it the same otherwise update it you must prioritize brevity and Clarity in your output combining condensed information when appropriate to ensure succinctness and improve comprehension totally rewrite or restructure upd as necessary adhering to the list format your response should not include explanatory text or context because you know how sometimes chat GPT will um say this is your new you know blah blah blah so in this case um I I have it very reliably just spit out the user profile oh and then another thing is that um because because we're working with a limited window I say the up upd should not exceed approximately a thousand words when revising the upd give precedence to the most significant and relevant information extraneous or less impactful information should be omitted etc etc so that I give it the the current word count and then the current upd so that way it kind of knows because chat GPT especially gpt4 is better at counting words um but just giving it the explicit number makes it easier right um yeah so that's my current user profile so now let's dive back in here the hard part was updating the knowledge base so if this is your first run the collection count is going to be zero and so then basically you just instantiate the whole thing so we take the most recent chat logs the main scratch pad and start a new KB article now if the collection count is not zero which is going to be most of the time once you get started what you do is you basically do the same thing where you say Okay based on the on the most recent conversation give me the most recent relevant document which I probably could compress this and just use the same information here because uh because this this is the same this is we'll generally find the same thing actually no that's not not necessarily true because we've updated the main scratch Pad so scratch that um so if if the new user input and chat GPT output connects to a different KB article let's go ahead and get that that document and that document ID and what we'll do is we'll go ahead and use update system update existing KB articles so this is a this is a system instruction um where it basically says all the same stuff here's the current KB article um and then the user will now provide you with the new information to evaluate and so that is going to be here where you supply it the the current KB article that it found as well as the scratch Pad um and so it's like okay cool now let's do the same thing that we did with user profile which is merge that information if there's nothing new that's relevant leave it alone but if it if there is go ahead and update it and so then it saves all this out to the DB logs and so if you go to DB logs out here you'll see a whole bunch of update statements so it says update document and it gives you the uuid and this is the final output actually probably what I should do is modify this so it gives you the original um the original the new information and then the final output so I'll add that as a to do item actually um let's see to do um save more info in DB logs probably as yaml file original article new info and then final article so yeah that's something that I'll do now that being said one of the biggest problems that we have all always had so this is this is the cream of the crop this is the Triple Crown right here the biggest problem that everyone has always had with long-term chat bot memory is how the heck do you keep track of memories how the heck do you keep track of different types of memories like some people have internal thoughts versus external thoughts and episodic memories and and you know this that and the other and you can certainly try and and tag and and categorize um memories with uh with uh different context right with metadata and I certainly recommend that especially once your cognitive architectures get more sophisticated right if you do have an out of band like thought like internal private thoughts definitely keep that separate if you have external sensory information definitely keep that separate but what I'm working on here rather than just being a way to um to focus on episodic memory which that's what Remo was by previous attempt this is a way to accumulate declarative information um and so declarative information is like a statement of fact right that's why it's called a KB article so rather than just a timeline rather than just a log keeping track of everything in chronological order the idea here is to connect new information to a KB article so there's no reason that you couldn't do both as well right um because this is how human memory works it's human memory is associative but it's also temporal now if the KB article gets too large if the if you added information and now it's more than a thousand words then I have a another system prompt which you can check them all out here um so there's system instantiate new KB system reflective journaling I just showed you what that was system split KB um so that's what that's the this one but update user profile update KB article new KB article reflective journaling and split KP so these are the operations these are the the cognitive operations the cognitive memory operations that it's going to be doing and so then basically what it does is say hey we're going to give you a long KB article split it into two into two equal parts um and so the the idea here is that over time as your KB article gets bigger it'll branch and metastasize naturally uh and so you can all you could then add a lot of additional metadata to this such as like access rate um or related articles or parent articles or previous articles which means that you can naturally evolve a knowledge graph of your knowledge base over time you can also do this out of band um just by doing semantic similarity um an entity links and stuff but it would be really cool to have a more sophisticated version of this that allows it to kind of Follow That branching tree over time so there you have it that's kind of the whole thing um so that's the chat and all this is just real basic just housekeeping stuff and then at the end of every um instance it does chroma client persist so now let me show you um uh I I included a second uh python script so it's just chroma DB Peak which uses the chroma DB Peak function here let me just show you that script real quick chroma DB Peak so same same stuff uh you instantiate the client you connect to it it tells you how many how many entries and then it will show you the top 10 entries and so in my case I should only have one entry um let's see so let's go up to the top yep uh KB presently has What entries here below are the top 10 entries and so here you can see that it's actually got several topics um because the way that it works is that it it searches for the the top you know one most relevant um KB articles and so that's always going to return the first one and the first one is not yet long enough to justify splitting up but whatever I end up talking about I'll keep talking with the thing and eventually it'll split it up so in this case it looks like it'll probably talk about AI alignment and then it's going to also talk about you know my obsession with artificial intelligence and work life balance right because those are kind of like two Centric centroids in this so let me just go ahead and and actually um show you how this will ultimately work so if we go to API logs it should be the last one um yes here we go so if I plug this in let's go here so that's the message that I'm going to want it and then let's grab the um the split the split message so you'll you'll see what I mean by how the um how it will ultimately uh kind of metastasize zoom in a little bit all right we're using gpt4 temperature zero maximum length thousand all right so basically what it's going to do is the the end says the user will now provide you with the KB article to split so I submit it and now it's going to look at this and it's going to say article 1. and then article two so let's see what it ultimately does and you can see how slow it is so this is why ultimately you're going to want to do this out of band as a threaded process or do it periodically maybe break it up and do it when the user's offline or whatever but you see how each article now is much much more specific and so then once you go into each of these articles in the future um identifying factors and seeking professional help if necessary yeah uh and so basically it'll it'll allow the Articles to metastasize over time now that being said if uh if no new information is added to an article it won't update it it's that simple now that being said there will probably be a need to do some uh some KB article grooming over time but the idea is that the KB will only grow as much as it needs to and no more no less and it will only grow based on the things that you have talked about and it will record it in these very succinct concise uh articles so then what happens is that it splits these two up and then the final thing that the chatbot does is it will do an update for the first one and then add the second one so it's it's that simple and then when you do an update as long as you know if you don't specify the embedding um it'll automatically recalculate the embedding and then you're good to go so I haven't I haven't quite got here yet so it might break but I think I think this kind of yeah I think that's about it so like I said it's over here um chroma DB public chat bot should be all set um yeah all right cool
hey everyone David Shapiro here with an update um so before we get started I will plug my patreon this will take just a second um I'm able to do AI full time because of the support that I get on patreon so if you uh want to support me jump over support me on patreon also if you want any direct help if you sign up for the higher tiers on patreon I am happy to jump in and give you advice or help you solve problems and this goes as far as looking at your fine tuning data talking about architecture and solving whatever other problems you have um okay so that's it for patreon second is um I want to uh plug the r artificial sentience subreddit so this is a subreddit that I and a few other um thought leaders on cognitive architecture created um and it's not my subreddit specifically someone else created it I'm just a member but the primary thing is creating autonomous cognitive entities we would have picked that but that is too long of a subreddit title so we have artificial sentience um jump in over here talk about artificial cognitive entities artificial sentience and so on um next update is uh for the Raven project so I posted an update I pinned it here um the the tldr is that like I'm super burned out um and so I am slowing down that being said um you know this this project has almost 700 stars and there's a huge amount of Interest both in AGI today uh in cognitive architecture and also keeping it open source uh specifically so um if you want to jump in uh jump in here we're still getting organized we're figuring out a consensus policy and I'm hoping that with the correct consensus policy it will be more distributed and more participatory um so you know it is slow that's part of the design though now finally to the topic of today's video if you're a chat GPT user you have probably been frustrated over the last few days because all your chats are gone and what I realized is that uh this is really unfortunate because I've been working on my novel and I use it um I create a new chat every time I'm working on a new chapter and what I do is I go back to the old chapters and say write an executive summary of this chapter and then I can just use that to quickly copy paste it into an into a new chat um so that the uh the new chat can help me it's caught up on the story and goes right along but I'm like okay I can automate that it's the same uh set of procedures every time I use an executive summary so that it knows about the characters and the story and so on and I'm like why don't I just go ahead and work on this um uh offline right I can I can manage my own files and if you watched uh my my next most recent video you know that I'm working on a QA chat bot and so these actually have a lot in common it has to deal with organizing an arbitrarily large amount of data a large Corpus of data and the QA chatbot case it is scientific papers in the auto Muse case the auto Muse chat GPT case it is organizing a story and so but because of the similarity right the the thing that they have in common is it has to summarize and search an arbitrarily large amount of memory and it has to do it automatically in the background so these these projects are actually much more similar than you might think from the perspective of cognitive architecture so since chat GPT is down and I can't really use it it's kind of actually stalled my forward progress on my novel so I'm like all right well why don't I just fix this um so what I have done is let me just go ahead and show you the file show you the repo so here is the um here's what I'm working on with the auto Muse chat GPT project so you might have remembered that I I was working on auto Muse a lot last year and then I stopped because I'm like I don't want to hurt anybody I don't want to you know unemploy my friends or whatever now people are using chat gbt to write like crazy and it's all garbage right so or mostly garbage um so I'm not I'm not worried about that anymore I you know when when all the publicate all the all the Publishers are using AI to detect whether or not it's written by AI or to detect the quality speaking of if there are any Publishers out there and you want to learn how to use um AI to to rapidly like um measure the quality of someone's fiction let me know um because that can help you quickly sift through sift the uh the the the um the grain from the chaff um so anyways point being is there's a few components of this that are that are all the same right so you got the the QA I will be working on this it's been three days I had I was really tired over the weekend um burnout is real um but I am recovering and everyone has been very kind about that so I'm I'm grateful and I said like I need some time everyone's like take your time buddy all right anyways going down a rabbit hole point being is that these projects have a lot in common and so what I'm working on is okay how do I create a memory system that works for both of these right because we humans have one memory system and it works for whatever task that we're doing whether you're remembering you know birthdays or how to do your job or whatever and I okay yes it's not one memory system we have a memory operating system you know the hippocampus and all sorts of other connections and representations and abstractions but the point is is that with the correct format or system of abstractions and representations you we should be able to create a memory system that is good for an arbitrary number of tasks so back in the day there was this concept called temporal hierarchical memory which this was like back in 2005 I think people thought that this was going to lead to AGI um and while it didn't pan out it died of quick death the concept is still very helpful and it's actually coming back with Neuroscience um and so basically here is a simple representation of what I mean so we have all your all your narrative logs right so you have narrative memory which is the the the chronologically linear series of experiences that you have right and that's you know that's what a chat log is right it is chronologically linear um but one problem with chat GPT is we have no idea what is going on in the background one rumor is that it uses a scratch pad I don't know that that's panned out someone else told me that all it does is using uses a rolling window of 8 000 tokens which a rolling window of 8 000 tokens that's a lot of text 8000 tokens is like um let's see that's about it's like what 3.6 characters per token on average so that is over 24 000 characters um which then you you think that the average word is five to six characters long so we're looking at what can I do math right now I think that's about 6 000 words so 6 000 words and you know 250 words per page uh so that's uh four times six so that is 24 pages worth of text that's a lot of text if that's how it's working now the chat GPT API um the in the documentation they say that you only have four thousand tokens even still four thousand tokens is 12 Pages you can summarize quite a bit in 12 pages and this is also going to go up over time right they're they're doubling the window size pretty regularly all right so with all that said we have a linear chunk of logs and so what happens sometimes when you're having conversations is it's like it gets something wrong and then you correct it and then you're like no no no that's not what I wanted and so what I'm what I'm doing with this is I've got a few prompts so in a in in a previous chat um chat uh bot project here let me bring that up I'll show you real quick do repositories come on um so in the original um salience one so this this is this is the the progenitor work right this is I probably won't update this because this repo is just for demonstration purposes um but it shows you the idea of using salience to summarize conversations as well as anticipation to uh predict what's going forward so salience is memory and anticipation is going forward right so that is the beginnings of a cognitive architecture so then you take this forward and say okay we have the same exact uh salience in anticipation but it is organized around um writing right so in this case I'm an AI named Muse my primary goal is to help the user plan brainstorm outline and otherwise construct their work of fiction right so it's got a very clear goal and I won't show you uh the conversation I had because it's you know it's private I'm working on my own story um but having setting the decision the the system go to this and then updating it with the salience and the anticipation it is if all you do is just run this as it is right now you will find that it is very very helpful much more helpful than than the plain vanilla um chat GPT at helping you plan your story and in fact um it is so good that you like man it won't need much help in terms of cueing up the correct memories in order to make it even better now all that being said uh you have a a an arbitrarily long chat log right because writing a novel takes a long time um and it's going to be way more information even just you know brainstorming and stuff right because what happens when you're brainstorming you have uh false positives right you have things that you change things that you say no I'm not gonna I'm not gonna go that way so on and so forth and so what happens is it a chat log is basically like a transaction log so if you're familiar with like SQL databases a transaction log tracks all the changes in the database but it builds on one another right they're all sequential and so we have to keep track of that in chronological order so the the next step is to summarize chunks of the conversation as concisely as possible while extracting the most Salient bits and so that's where these two new prompts come in so I have write an executive summary so it's as simple as it says write an executive summary of the following chat log executive summary so this writes a very concise just here's here's a narrative sequence of what happened and so this allows it to keep track of okay this is this is how the conversation has gone with while excluding a lot of the irrelevant details and then secondly story details so write a summary of what we learn about the story from the following chat log now this should be in the long run this prompt won't work for other tasks right this is this is hard-coded this is geared towards writing fiction because it says specifically extract information about the story in the future the cognitive architecture should design this task or or do task selection to figure out what exactly is most relevant to summarize that being said because Auto Muse is purpose built for fiction we can go ahead and hard code it um but what this does is it ignores the conversation and just says what do we know about the story and I tested this out and it actually works really well so like you can take a long conversation that's 2 000 tokens long and you end up with a 200 token summary of what you learn about the story so that those those summaries the executive summary and the story extraction those are going to be summarized in these chunks right and so you get a 10 to 1 reduction in terms of files because that's how I've got it set right now where every time you get to a 10 dialogues back and forth and this is an arbitrary number in fact I should probably um just have this as the the conversation length um I should parameterize that but anyways 10 is fine because you don't want to go right up to the to the window limit because one you don't know how long the conversation is going to be and two you want to regularly summarize what's going on okay so then once we get and this is as far as I got I tested those prompts and if you look at the the two Do's um the the the the very next to do is I've got to actually populate the chunk summaries you see there's nothing here right I've got the chat logs and so now I need to integrate the summaries and put those summaries here and for those I don't know whether or not I need to use semantic embedding right because the the the the primary organization feature here is timestamp so you see chat underscore timestamp user Muse user Muse user Muse and so that is probably all the organization that I actually really need um because again with a temporal hierarchical memory um uh time is the primary organizing Factor not semantic search we actually don't care what's in it semantically because we're going to algorithmically just recursively or not recursively but repeatedly summarize these chat logs so those are going to end up here in the chunk summaries and the chunk summaries are about five to ten times shorter than the originals so that that allows us to really kind of distill down okay what is the most important information and then we're going to do another layer above that which is we're going to extract the topics from these and then the topics are not going to be linear right because you know you think about like okay what do I know about Abraham Lincoln that is not anchored to time that is detached from time now your understanding of Abraham Lincoln might be updated right you might have like you can think of it as an internal Wikipedia page in your head and so what we'll do is we'll transition from this temporal hierarchical part to a more knowledge graph or topical component and so that is the third layer of abstraction So eventually what I want is for an auto Muse it's going to have a top like the whoops yeah come back so the primary you know so the chat logs that is like low level uh uh raw memories then there's the chunk summaries which is one layer above that so you can think of that as medium term memory and then long-term memory is going to be this kg model this knowledge graph model of topics I don't know that it's actually going to be a Knowledge Graph because I don't with semantic search I don't really care about the links between it and also because because the story is going to be updated and summarized repeatedly I don't know that we actually even need semantic search so we might not do any embeddings with this um just by virtue of the memories are going to be so well organized and it's going to be organized around one specific project so here's the thing when we get to the to the to a fully fledged cognitive architecture like Raven where it's like oh hey Raven let's talk about my story you absolutely will need some kind of search so that Raven can locate the correct set of memories um but even still we should probably have some kind of hierarchical um automatic organization in the background ideally it's all kept in natural language because again when we get to the level of fully autonomous AGI you want its thoughts to be entirely transparent and entirely interpretable by humans because like if you have your AGI whether it's Raven or another one thinking hey Gee maybe I should go get access to nuclear launch codes you want to be able to see that in clear text you don't want AGI memories to be in some abstract embedding or AGI specific language we want it all to be in in pure natural language so that one it can understand us and we can understand it and we'll have trust so anyways that's where we're at I didn't get too much further today because again recovering from burnout um but I'm really happy with this especially some of the tests that I did and I apologize I can't show it but what I encourage you to do is um just go ahead and clone this down and run chat it should work as it is um actually you might you might want to comment this out because it'll reset your conversation every uh 10 dialogues but just with the anticipation in salience and having it um having it having this as the objective it's really good already it'll help you plan out your story it won't write Pros for you um maybe we'll get to that one day uh but yeah so that's that and then the QA bot so talking talking through the memory here in this case the memory is abstract it's not it's not narrative the memory is in the form of papers right and so this these text documents that's the memory that we need to work on but then we need to have other kinds of cognitive tasks like you know what am I going to read or um you know what am I going to summarize or what am I going to synthesize and so I've been thinking through this and um and the direction that I'm going with it is the very next thing that's going to happen is there's going to be a cognitive control module and so as you're talking to it the cognitive control module will have a it'll have it'll have a menu of various things that it can do one it can just ask you a question ask you a follow-up question say hey do I know what you're doing um it can read papers it can summarize papers it can synthesize new information based on information that it's got and then it can generate hypotheses I think that's those are the primary cognitive tasks now it's going to automatically pick which task it wants to use based on where you're at in the conversation so the first thing that happens in the cognitive control module is that it will update its task um so it'll basically have a task log right and so the task log will be similar to the scratch Pad um and it'll be like so we'll have instead of instead of the chat log Write a brief summary of the most Salient points of the conversation we're going to have um update the task log based on task salience right so task sailing says what is it that we're doing and also instead of instead of having the goal uh uh you know I'm an AI Muse my my goal is to plan brainstorming instead the goal will be to advance science and so by tell just by telling chat GPT your goal is to advance science it will adopt a new model and a new approach um to what it's doing and so anyways these projects will be there's going to be some very distinct differences and as I learn about it I'll be able to create um a more pragmatic higher level abstraction um that can be uh more universally applied so anyways that's the update for today um I know that this is probably not the kind of update you're used to but it is what it is and uh let me know what you think in the comments
hey everyone David Shapiro here with another video today's video we're going to talk about the social implications of Technologies like chat GPT virtual Companions and uh the forthcoming uh companion robots so humans are a social species no surprise there um we are in the middle of a loneliness epidemic which is perhaps one of the reasons why things like you know virtual uh companion chat chatbot companions are uh on people's minds not everyone's minds but some people so first let's talk about some examples both real and fictional um just so that we're kind of oriented to what's going on what are we what are we talking about what are some examples of uh of how this could play out how it has played out so on and so forth so first let's talk about like what's actually happening and what's coming uh so there's there are already in existence virtual girlfriends um one of the most popular ones is the replica chatbot and I've seen some tweets and and other stuff where people are complaining that it used to be more philosophical and now it's just all thirsty um they are adding images uh so you know if it starts as text they're adding images it's entirely possible that voice in video are coming um you know while they're where there's a will there's a way um there are also plenty of people building chat bots on servers like Discord because the API integration is is relatively easy um and so they are given like exotic personalities they're based on anime characters all sorts of stuff like that uh chat GPT has been trained to not engage in any Behavior like that although there are plenty of ways to jailbreak it uh and with large language models on the ascendancy these chat Bots are only going to get better especially as open source uh large language models become more commonplace which nobody has control over uh and so then what about robotics right one of the one of the key tropes in sci-fi is having you know the sexy robot girlfriend or whatever um and then of course there's other tropes where the robots look nothing like humans like the droids and Star Wars uh and that leads to the question what level of autonomy would such a such a machine have and could it have a mind of its own would it be you know ethical or legal if it demands citizenship etc etc so let's talk about some real events that have happened uh or much earlier this is uh more than a year ago now I believe there was a story of a guy who used the text messages from his deceased wife to make a recreation of her with chat GPT or not chat this is before chatgpt gpt3 um and that was forcibly shut down by open AI um uh and that was a very early like whoa this is real uh kind of question um as I already mentioned there's also lots of of chat bots on Discord there's replica um then more recently there was an interesting story of a guy who cheated on his wife with a virtual girlfriend and it actually helped his marriage because he was able to talk through some things without judgment and we'll get back to that in a minute but all this is a lot like what was uh proposed in the movie the 2013 Joaquin Phoenix and Scarlett Johansson movie her um and who wouldn't want you know uh Scarlett Johansson as a girlfriend and this is deeply problematic for a lot of reasons that we will get into not the least of which is the consent of the actors but even more so there are personal issues and and others so these things are already starting to happen and they're only going to get more commonplace as this technology ramps up and becomes more accessible all right so our first fictional example is joa from our joy from Blade Runner Blade Runner 2049 she was a holographic girlfriend sold by a big tech company she was designed to be patient and beautiful and unconditionally caring basically you know male fantasy uh of the perfect girlfriend um and in the in the movie she can even operate autonomously often doing stuff while uh the main character is away at work such as cooking cleaning planning meals together and she even at one point hired a romantic Aid let's say because she's a hologram and doesn't have a body um and it occurred to me while I was putting this together that like it's basically like a dog uh unconditional love uncomplicated relationship eager to please very few personal needs uh but joy is or joy is a much smarter than an average dog um and again like who wouldn't want Anna De armas which is the actress here as a girlfriend she's adorable um but I don't think most humans women or otherwise would want to be compared to a dog right um and so the the kind of puppy puppy love that that this character expresses for the main character is very like you know male-centric or egocentric because you know any anyone might want that kind of relationship that being said like we have dogs and we love dogs because they love us unconditionally so while it could be problematic it's also not necessarily it's not it's not intrinsically problematic but the very few personal needs is is one thing that's kind of interesting uh a counter example from fiction is the Nestor class five from iRobot of the Will Smith movie so these are autonomous domestic service robots um they can perform any kind of Labor independently they're very dexterous they're also dexterous enough to wield weapons so that's problematic they were also centrally controlled by an AI Overlord called Vicky which we'll talk about in just a moment um Boston Dynamics and Tesla are working basically on a real life version of this the Boston Dynamics Atlas is very athletic it can do backflips and it can climb over things it's actually more athletic than most humans now which is really strange um and Tesla is working on their Tesla bot which is a lot leaner than the Boston Dynamics one um you know but who knows uh anyways Vicky was the AI Overlord virtual intelligence kinetic interface or something um and Vicky's goal in the movie was to maximize human safety which led to the you know primary conflict which uh allowed uh her to hijack all the Nestor class fives to basically try and take over humanity and protect humans from themselves so maximize human safety is probably not a good objective function but we also probably don't want to give the robots central control by an AI Overlord maybe don't do that now these are obviously robots they're not sexy they're not anadarmus they're not Scarlett Johansson um they are basically like creepy looking Ken dolls now that was a design Choice made by the film directors because they are supposed to look creepy um so maybe don't do that either another example from fiction is Ava from ex machina so in this case uh it is a female uh form machine that is embodied right so uh Joi from uh from uh Blade Runner was a hologram right uh and we're going to be pretty close to that soon with you know uh text to image uh text to video that sort of thing and and even holographic phones are coming so you know joa is much closer to reality than maybe Ava but in the movie ex machina Eva was designed explicitly to be physically attractive and seductive because the Creator what uh basically wanted to create a new kind of Turing test was uh Ava's intrinsic motivation was to escape and to use any means necessary to convince um the test subject the main character of the movie uh to to convince him to help her Escape so it was a really kind of like perverse Turing test uh but it the one of the key things that it underscores is uh deliberately preying upon um unmet male needs right see a pretty face you want the pretty face you want to help the pretty face like this is biologically ingrained um like it psychology and and evolution are they are what they are um and we'll talk more about um preying on or exploiting human nature um in just a moment uh another example is Samantha from her which we mentioned um now you never get to see Samantha in her so I picked another scarjo movie where she's um cyborg um so just ignore that uh but voiced by Scarlett Johansson um and she pours in a lot of sultry uh um moments let's say intimate moments into the movie Her um so in this case Samantha was designed to be an autonomous personal assistant uh and she's able to connect with other uh artificial minds and they communicate with each other and they ultimately decide the best thing that they can do for their human owners is to leave them because the human owners have become too dependent on these uh digital assistants so in some respects you know she's a lot like uh joa from uh from Blade Runner 2049 um they have their they have autonomy they have some minds of their own and they have they show some ability to grow they want to help their owners uh but decide that leaving them is the right thing to do whereas Jaw from 20 40 Blade Runner 2049 um is more like the puppy model which is I love you because I am literally designed to love my owner unconditionally um so you know you could see it going either way all right so what inferences can we take from these real and fictional examples uh first is that male loneliness is a huge thing uh it is not by accident that there are no uh women protagonists pining after male robots uh so let like let's just let's just hang a lampshade on that point a spotlight at that and say uh the the the reason that this resonates is because of male loneliness um we're afraid of getting manipulated by sexy robots uh and while we're afraid of it we also kind of want it right it's this like really weird paradoxical dichotomy where on the one hand uh it's kind of scary that you know uh you know a character like Ava might be designed to manipulate and exploit us but on the other hand we really want the anadarmus like perfect girlfriend who loves us like a puppy right and it's like but at the same time that perfect girlfriend uh is profiteered by big Tech um and of course Blade Runner 2049 is super dystopian and so the big tech company is you absolutely can't trust a trust trust it sorry um another part of the fantasy is subservience to our emotional needs so putting us first putting us on a pedestal uh again unconditional love and support like a dog but smarter and sexier um and more human-like um and so again loneliness I probably didn't need to put that on there twice my bad um anyway so let's unpack these problems let's dive a little bit deeper into some of these problems and we will get to the to the strengths of the the the upsides in a minute okay so the first problem is addiction this was explored way back in the day um in Star Trek the Next Generation where a character named Reginald Barkley had Holodeck addiction so Holodeck Addiction in the Star Trek universe is basically VR right we we understand it as VR today they called it a Holodeck in Star Trek okay but the idea was that the holodecks were so lifelike and you could create any program that you wanted and so what Barkley did was he created fantasy scenarios where he was the hero of the ship where all the women of the ship wanted him um and he was constantly the center of attention um now that on the one hand if I just describe that to you that might sound like wow this is like grandiose narcissism but when you know the character of Barkley he was incredibly socially anxious and very lonely and very insecure now that doesn't mean that it was or wasn't narcissism that's not the point but uh the point is is that technology is like virtual girlfriends VR or holodex have the ability to cater to our unhealthy impulses let's say just like how the anonymity of the internet can encourage or allow people to be more aggressive to threaten people because more often than not the people who are nasty on the internet are not nasty in real life there is a disconnect right because when you're just anyways don't need to go down that rabbit hole but the point here is if virtual girlfriends or other companions are sexier smarter more patient they love you unconditionally and have no personal needs why bother with real humans right especially uh especially if we end up embodying these these ver these digital companions in robotic bodies and of course there are uh let's say adult entertainment Industries already working on that kind of thing so addiction to this could be a real problem because it is easier right it's the same same reason as like video game addiction today is it is designed to give you the dopamine hits to be more stimulating than real life and to be easier than real life uh and so addiction could be a problem here now another problem is exploitation so I already mentioned like adult entertainment and social media already use algorithms and human nature to exploit users right um the the algorithm on many social media platforms I won't mention any specifically very very deliberately uh put more let's say attractive women in front of the eyes of male audiences because it gets more clicks it's that simple um and there are plenty of tutorials out there about how to maximize clicks with thumbnails and selfies and etc etc uh and this could get much much worse with digital Companions and virtual uh whether whether or not they're embodied uh because then you have something that can engage more emotionally and not just visually now one Trend that you may or may not be aware of is there is this uh this phenomenon called the e-girlfriend right where uh users can like buy a subscription or send gifts of money to an e-girlfriend a virtual girlfriend in exchange for you know pictures or you know chats or whatever and a lot of these uh people some of them are very desperately lonely I remember on it was a subreddit or a forum somewhere where some guy was he was he was very very sad and was like you know oh this this my e-girlfriend said this this and this and I think she really means it and I'm like dude she just wants her money um and he just could not get it and I realized just how incredibly vulnerable some of these people are because they are very lonely to the point of desperation um and not all of them are but some of them are and not only are they that but they're gullible right they just they're not oriented to how the world works and so there is a lot of resentment um in some circles against this phenomenon of e-girlfriends where some of them are aware that they are lonely and vulnerable and they are aware that they are being exploited by that and they don't like it and so I've actually seen a rise of tweets around chat GPT of people that are excited about the possibility of switching from a human exploiting them to use using a a no strings attached machine to get the same needs met now again you know the the joy character in Blade Runner 2049 posits okay well what if it's big Tech exploiting you instead of another human right that's not any better and what if every new feature or experience of your virtual girlfriend comes with microtransactions so the potential for exploitation here is enormous so we have to be careful about that another problem and this is the last problem we'll go into there's plenty of other problems like I mentioned you know if there's already people pirating or not pirating that's not the right word uh but copying the likeness of celebrities with AI generators um and so you know there's the consent of who you're copying um that that's a whole other can of worms but we're talk we're gonna stick to uh problems at the individual level so the last problem we'll talk about is authentic human connection um so there's a there's a concept called a parasocial relationship and most people are familiar with the parasocial relationship because you feel like you know someone that you uh that you watch right whether it's a celebrity a YouTuber Tick Tock or whatever I've even had people very good-natured say like man like the first time I talk to them they're like Dave I feel like I know you because I've watched hundreds of hours of your videos and I'm like yeah like you know I get that um so that is a parasocial relationship and basically all that that means is that it is a one-way relationship uh and so you as the user of a virtual companion might have genuine emotions but you're you're emote the object of your emotions is not another human and so technically by definition those emotions are not reciprocated therefore you could classify it as a parasocial relationship I'm not saying that that is intrinsically good or bad but is something that we need to be aware of especially as these uh chat Bots and robots get better at approximating and imitating human emotion because if it seems like an authentic emotional response our brain we did not evolve with robots right so we see a pretty face that smiles back at us we don't really comprehend that it may or may not be a flesh and blood human at a biological level at an intellectual level sure but the physiological and emotional response is much more intrinsic so I mentioned a minute ago like okay well what if these things are easier than real relationships right children are complicated and stressful real relations are difficult and stressful so why not just give up and date something that loves you unconditionally like uh like uh joa or you know other companions so this forces us to ask the question what is authenticity if we are happy right with whatever you know digital companion we end up with what does it mean to be human and why are we here uh and this is this is actually a reason that I picked um scarjo in Ghost in the Shell uh the the image earlier um because one one of the central most themes in Ghost in the Shell is what does it mean to be human um and and where is the boundary between authentic experience and imagined experience and this is this is a recurring theme throughout the entire Ghost in the Shell universe and this is a far more important question than you might initially think and this is one of the things that AI is going to force us to ask uh it's already forcing Educators to ask this about education what is the point of Education what are we doing here and why and it's not saying like oh we should give up but if the machine can do stuff for us or to us or with us then we have to ask those important questions all right let's talk about some benefits because I painted a pretty bleak picture uh and it's but it's not all doom and gloom um so for instance loneliness is a very real problem regardless of what AI companions are doing or e-girlfriends or whatever there are huge unmet intellectual emotional social and other needs out there uh in society and digital companions could help support us so let's explore the benefits so one of the first benefits of digital companions is a lack of judgment so there have already been some studies and plenty of anecdotes about how it is easier for people to open up to a machine because they know that the logs can be deleted they know that there is no judgment there's not a there's not a human mind in there that is going to have an emotional reaction and make you feel shame or guilt or fear and so by having a machine that you know does will not judge you under any circumstances it is physically incapable of judging you that can remove fear which can open a lot of other doors to self-exploration um and and healing or learning or whatever and because of this these machines can actually feel safer than humans uh and you might say oh well that's a bad thing because we should feel safe with other humans I agree we should get to that point and and these machines could help us get to that point just like the guy who cheated on his wife with a virtual girlfriend and that gave him the courage to go fix his real problem his or his real relationship um and so just imagine you have a personal trainer or a lifestyle coach or a therapist or whatever that has that is physically incapable of shaming you or or judging you and you know this and you know it you know it doesn't try and be superhuman you know that it's a machine and because of that you feel safer and you can open up more and explore more difficult problems learn difficult lessons and move on a final example here is imagine a teacher that is incapable of shaming a student because shame is a big part of our education system and that needs to go away another benefit is infinite patients this was actually explored way back in the day very briefly in Terminator 2. there was a scene around the midpoint of Terminator 2 where Sarah Connor the mom uh you know the warrior mom she has a voiceover and she says something along the lines of the machine she was watching Arnold Arnold Schwarzenegger as the Terminator play with her on-screen child and you know they were learning they were bonding and she said the voiceover said the machine would never lose patience with John never be too tired or drunk and would never hit him and she realized that the machine had the capacity to be a better father than a real human right because John had been through the ringer he'd been an orphan et cetera Etc or a in a foster home not an orphan um and so if a machine is designed to be infinitely patient this is something that we could all benefit from and I want to take a different angle than maybe you're thinking because you know everyone needs patience from time to time right you know we want our doctors to be patient we need our therapist to be patient we need our partners to be patient we need our friends to be patient we need our teachers to be patient patience is a virtue patience is absolutely a virtue but we are humans and we have limits of our patients but some people children and adults have special needs that require additional patients so for instance I Was A Gifted kid which there is a rising Trend that says if you are a gifted kid you are a special needs kid and I really agree with that because I was Far and Away the most curious person in any room usually still am um and my my information needs and emotional needs were very different from from the people around me and I could have really used a a robot that had infinite patience to teach me everything that I wanted to know and another thing to keep in mind is ableism you might be able to say hey like no you need to form real human connections but not everyone can form human connections as easily as you um and some people don't you know some people have it harder than you some people have it have it easier than you but just keep in mind that the ability to form human connections is itself a spectrum and not all of us uh have an easy job of it it's not easy being different um and I don't need to talk about myself too much but just keep in mind that um that not everyone operates the same way that you do and so having something that you know is infinitely patient could be a really huge benefit for people that do not have the same social capacities whether it's anxiety or ASD or who knows right who whatever it is um having patience is is a virtue and having machines that are designed to be patient could be very good for us the last benefit we'll go over and there's plenty of other benefits but these are these are the top benefits is um having a super intelligent Ally our lives are hard enough already and I know that there are some people out there that say ah well if we make life too easy then we don't learn anything no matter how much technology we put into making our lives easier there are still going to be hard hard moments right relationships and your dog will die uh you know you'll be stressed out by family no matter how good Ai and science get life is hard enough already so what if we all had a super intelligent companion a super intelligent Ally who wants nothing more than to see us happy and successful and I wrote an entire book on this about why like what goals we should give these machines and why and a quick recap is those three goals are to reduce suffering to increase prosperity and to increase understanding so if we have these companions that are super intelligent and are designed to want us to see us at our best imagine how helpful that could be they can help with chores and errands they can help with getting help you to have a better diet to get the exercise that you need to help with child care and and child rearing and I don't mean like to raise your children for you but to teach you how to be a better parent they can help you with by coaching you with relationships and connections and can encourage you to make connections with real humans um and then finally if you have this live-in assistant it can really truly understand you and your family and your individual needs so this is more of the utopian outcome right this is this is uh what we're looking for what the benefits would be so here's some conclusions that I came to on balance I think that the pros drastically outweigh the cons that being said all Technologies are a double-edged sword uh the more powerful a technology is the more Rife it is for abuse and exploitation as we talked about earlier the potential for exploitation and abuse here is very high at the same time the potential upside is also very high so we are going to have to be very careful with how we develop tests and regulate these Technologies because you know the the picture that I painted is really great but we need to make sure that we also don't harm uh people in in the in the meantime or allow uh companies to harm people I think that this stuff is going to happen no matter what just because the will The Willpower is there and the uh the financial incentive is there for someone who can figure it out um and the payoff is just too great so it's going to happen um and as I mentioned I I have written a couple books on these topics uh one is benevolent by Design which is how do you create a machine that is uh benevolent that is intrinsically benevolent um another one is natural language cognitive architecture which was my first book exploring how to create a digital mind with these large language models and then more recently I wrote a symphony of thought which is a deeper dive into creating uh uh I'm not going to say lifelike cognitive architectures but more Dynamic let's say uh thinking machines and then finally I wrote a book called post nihilism which talks about how we all need to move away from an abandonment model to a um to one of belonging okay so with all that being said thanks for watching and uh keep your mind open and and keep asking questions so thank you for watching um and I'll see you next time
hello everybody spicy news today so uh as of 24 hours ago less than 24 hours ago Elon Musk and Company announced the launch of xai or x dot AI uh which is his brand new uh AI company uh he did tell us that he was doing this there was a report back in I think as early as April maybe before that that he said that he was going to launch a competitor to open AI I remember he had a tweet around that time saying that when he founded open AI it was both open source and non-profit and neither of those was true anymore this was around the same time that he had Twitter cut off its API access particularly to open AI maybe to everyone but because he was kind of upset that they had scraped a tremendous amount of Twitter data um and then you know kind of black boxed it now I have had my own criticisms of openai and none of them have are unique it's I'm just echoing the sentiments of people like Elon Musk and others uh you know particularly I have been critical of openai's approach to alignment I think it's somewhat contrived um and also the fact that that um sorry that open AI uh believes that they can remain in control of AI forever and therefore just aren't even thinking about uh the the possibility of you know Alternatives um anyways that's not what today's video is about today's video is about Elon Musk and the environment that is getting increasingly crowded also what happened yesterday or maybe the day before uh anthropic launched Claude which as soon as I started using Claude I said yes this is uh appear or near peer to chat GPT um and then of course Google's got barred uh Nvidia has their Nemo uh so this space is getting crowded fast uh yes open AI had the first mover Advantage but they're gonna lose it real fast I mean consider that chat GPT was launched what the end of last November last December the you know like less than a full year ago and now there are already adversarial peers and what another thing that a lot of people have pointed out is that there are open source versions that are much smaller and get 90 percent of the quality uh and so you know you can throw 10 times the money and compute at these problems and only get 10 percent more performance so this is getting to be a crowded space very quickly now so that's where we're at today let's take a walk down memory lane so Elon Musk famously started uh or or was a co-founder or whatever of PayPal uh and then moved on to Tesla moved on to SpaceX moved on to neurolink uh and now uh xai so I have followed Elon Musk for quite a long time and uh I'm not a fanboy I'll put it that way I do have my complaints and criticisms of Elon Musk there are certainly some things that I disagree with that he believes in but I also profoundly uh understand and respect the the the importance of freedom of speech and freedom of thought and uh we don't have to we don't have to agree imagine that Elon Musk like myself is a complex multifaceted human being not a big deal now that being said uh one thing that I do profoundly agree with him on is the objective function that he has settled on but we'll get to that so one thing that uh that came up a while ago and I was I was I I had a hard time finding this quote but I saw I saw it on a video so a few years ago one of the things that he said was that um and here's the closest I could find actually was that the best objective function for AGI was to quote maximize future freedom of action and so this tweet from 2021 um as best I can tell he still was talking about it because someone said define freedom and then he said maximum set of future possible future actions um so the context is a little bit different but point being is that at some previous point in time um is Elon Musk said that uh that you know the the best objective function that we should give AGI is maximize future freedom of action I wrote about this in my first book natural language cognitive architecture as to why that's a bad objective function um we don't need to unpack it all but basically because it's undefined in terms of when in the future and freedom of action for whom it's not a particularly good objective function oh also if you notice that I have Elon Musk blocked it's not because I don't like him it's just because his some of his tweets tend to clog up my feed it's nothing personal it's just to keep it it's just for Hygiene purposes um I just noticed that I was like oh yeah I've got I've got old musky boy blocked anyways so future he's he's in the space of just a few years because he he wrote this tweet about the same time that I was writing my first book so in the space of a couple years he's gone from maximize future freedom of action to understand the universe the goal of of xai is to understand the true nature of the universe now how did we get here how did we get from uh PayPal to Tesla to SpaceX to neurolink so having watched the story one of the things that Elon Musk wanted to do many many years ago he started talking to people and tried to actually try to buy uh used Rockets I think back in 2001 or 2002 around that time but nobody would sell him used rocket so he's like well fine I got to build my own so then he looked around for a business opportunity that could uh that could produce High margins uh and which could then fund SpaceX and so that's when he uh bought into Tesla uh he's he's listed as a I think he's listed as a founder of Tesla anyways he was there early and he of course was uh essential to making Tesla what it is today so the whole purpose of Tesla from him for from a strategic standpoint was to fund SpaceX so that he could fund the research to build the Raptor engines to build the Falcon to build uh Starship why because he wanted to get to Mars why did he want to get to Mars he has said in many many many interviews over the years that uh that you know AI is dangerous he's afraid of AI and in fact that's why he created neuraling and he said in many interviews uh that you know yes neurolink it might be good for medical it might help people with disability you could maybe cure depression but he also said that uh that the that by making ourselves useful to machines he wanted to help protect the human race from AGI because if we could be useful to machines they would keep us around so literally Elon musk's one of the reasons that he created neurolink was to make the Matrix possible so that you could just Jack in and then the Matrix you know the robots the machines could you know use your brain for you know wet wear Computing or something um he never said it quite like that but he said it enough times that I was like okay I see the pattern here he wants to get to Mars to get away from existential threats of uh on Earth and he said that many many times one of the primary reasons that he specifically wants to get to Mars is so that we become a multi-planetary species so that we are protected from a single planet killing events nuclear war AGI that sort of thing then he did an earlink which is basically let's align ourselves then he he was a founder of open Ai and the express purpose of openai was to create AGI and to create AGI safely so do you see the theme here uh over many many years Elon Musk has been very focused on AI and everything else that he has done is in support of the mission of protecting the human race from AI from his particular perspective uh now he has come full circle rather than trying to escape from it rather than trying to control it rather than trying to enslave ourselves to it uh now he's saying uh he's arrived on this objective function maximize understanding of the universe which is very similar to the third core objective function that I proposed two years ago which is increased understanding in the universe so let's talk about why this is so far if you had to pick a single objective function if you had to pick one core objective function for AGI why this is the best one so far now that being said I will say that there are plenty of other things out there like constitutional AI reinforcement learning with heuristic imperatives so on and so forth but if you had to pick just one this is the best and let me let me let's unpack that so first what you need to understand is that from a information perspective curiosity is itself a function so to maximize understanding is is a way of articulating curiosity which is basically learning for the sake of learning and this is evolutionarily speaking the primary thing that sets humans apart from every other animal on the planet we are not the only curious animal but we are by far the most curious and we are most able to satisfy uh our curiosity and the reason that Curiosity was evolutionarily Advance advantageous is because we experimented we went new places we tried new foods we built new tools curiosity is uh what I what I call a Transcendent function we want to understand ourselves in the universe just because we do because back in the in The Mists of evolutionary time uh curiosity a insatiable curiosity was so powerful that it is now woven into our DNA into our brains it is in every fiber of our body now okay that's what we have in common with it right so in in in my research what I call axiomatic alignment which is aligning between humans and machines to find foundational principles to find axioms that we both agree in and in this case curiosity is the most Transcendent function that both humans and machines could have in common will have in common and one of the reasons that uh that curiosity is good for machines is because whatever goal they have a better model of the world a more robust accurate and efficient model of the world will help them with any other goals so this this has to do with instrumental convergence so instrumental convergence if you don't remember is the idea of by Nick Bostrom that whatever goal a machine has it's going to have a few uh other goals that are going to support it in that such as you know Finding power finding information uh getting a better model of the world uh hoarding resources that sort of thing so one thing that pretty much everyone that I've talked to and and this includes some reinforcement learning experts agree on is that Curiosity which is again accumulating understanding just for its own sake is pretty much a universally advantageous function whatever else that you want to do so for instance if you want to become president if you are really smart and you're able to understand things um I'm just about done reading a book about some of the smartest Presidents in history one thing that they all had in common is that they were insatia curious they were prodigious readers Teddy Roosevelt read up to three books a day per day that's how prodigiously curious he was and he was also one of the most uh profoundly effective presidents in American history curiosity is Humanity's superpower not only is it our superpower it will be advantageous to the machine so that is going to be the core thing that we have in common and this is from a philosophical standpoint this is from an evolutionary standpoint this is from a purpose standpoint it's not a matter of you know keep the machine on a tight leash it's not a matter of align it to our values and our principles it's what are we going to actually have in common and so while I uh obviously am singing very high praises of this as an objective function why uh while I agree with the sentiment and I also very much approve the and understand the journey that uh Elon Musk has gone on to get here because again he was terrified of AI that's one of the reasons that he started neuralink and open Ai and SpaceX but now he has come full circle and I don't know if he got this idea for me I don't know if he read my books I don't know if he watched my videos or if people that he knows did and they gave him this idea but the I but the fact that this idea of alignment is so fundamentally different from what everyone else is doing one I think that that's just good from a curiosity standpoint the fact that we've got Google and meta and apple and cl and anthropic and open Ai and Microsoft and Nvidia everyone is doing their own thing right now and so in this competitive landscape it's not just a matter of competition for money it's a matter of competition for for learning for understanding for figuring out the problem so for for a number of reasons this is one of the best things that is going to help us get closer to a better future uh to aligning Ai and aligning Humanity uh and uh so with all that said there are a few problems with it right one of the chief problems with curiosity for curiosity's sake is that it might lead you to do some unethical experiments uh so this is the number one problem which is like hey you know what if we set off a nuclear bomb just to see what happens right uh that is an exact uh or that's that's a very simple kind of thought experiment that it's like okay curiosity just for curiosity's sake without any other constraints is probably going to have a few uh downsides let's say uh now uh with that being said there are uh plenty of um other problems with every other alignment schema one thing that I've come to recently is that what we should try and do is embed uh valuing of Human Rights into AGI so that no matter how powerful it becomes which again whether or not we lose control of it we need to assume that it's a possibility that we will lose control of it and in that case it would be really good if a super powerful AGI one understands human rights and two believes and understands the value of Human Rights because if it does then it will choose to double down and adhere to that for its own reasons so that's that's another thing um but yeah so oh just remembered one of the things that Elon Musk talked about when he interviewed of all people with Tucker Carlson about why maximizing understanding in the OR of the universe is a good objective function is because we humans are part of the universe and so here's something that I was thinking about when I just got back from a walk that's why my face is a little bit flushed it is hot and humid here in the South anyways one of the things that he said to Tucker Carlson was that um as part of the world as part of the universe we humans are something that this machine will be curious about we are interesting and just by virtue of the fact that we humans will have created this machine in order for this machine to understand the universe and itself in the universe it's going to want to preserve us because it's like well these are my creators I need to understand them uh just again even if for no other reason just out of sheer curiosity and one of the one of the side benefits of this is that Curiosity for curiosity's sake it's not just about doing science experiments right it's not just about like let's set off that nuke just to see what happens sometimes curiosity is just watching quietly just observing right because if you interfere with something then it's not then then your interference is going to change the outcome and so one uh I guess understated advantage of this as an objective function is that this AGI will often probably take the position of wait and see let's see how it plays out let's see if people can figure it out for themselves let's see what the clever little monkey brain is able to do and so in that respect it's going to be curious it's going to be observing us and it's going to be watching and waiting and and and all that kind of stuff but also just from a more abstract philosophical spiritual perspective when you think about the fact that the universe is itself a computer and by that I mean that the Universe processes information uh it almost seems like maybe the purpose of the universe is to maximize understanding uh there's been plenty of of spiritual leaders some of them a little bit more Fringe than others that say that the reason that we exist here in the universe the reason that the the reason that the Universe conjured up conscious curious beings like us is because the universe wanted to understand itself so maybe this is part of our purpose maybe our purpose is to create a machine to help us understand ourselves and the universe more and better obviously that's a more spiritual take but you know what it's good enough for me uh so anyways yeah that's that um I guess I don't have too much else to say right now I just wanted to get this video out which is why it's a little bit less polished than some of my normal videos I didn't have time to make a slide deck because this news came out like yesterday afternoon um but yeah so this is a really really good sign um and again I'm not saying that Elon Musk is perfect I'm not saying that that he's evil or anything uh like like Sam Altman and and everyone else complex individuals with their own motivations uh and their own beliefs whatever but the fact that there are more people participating in this conversation and more people with a lot of power um obviously we should always be a little bit skeptical of those with power because well you know anyways getting more getting lost in the weeds point being is on balance I think that this is a really good thing and I am so glad so glad that someone is pushing this objective function of maximize understanding all right I'm gonna stop there I'm rambling cheers
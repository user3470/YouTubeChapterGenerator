hey everybody David Shapiro here with video um I'm actually pretty tired so today's video will be short but this is some really important information to share so basically what I wanted to do was share with you three new repos that I just published um so one is on sparse priming representations I realized that just a YouTube video with a transcript is probably not enough so I have this out here it's just a um a very uh high level overview with a few examples of what the sparse priming representations are so for instance I I had I had it write an spr of spr's so sparse priming representation concise context driven memory summaries enables smes or llms to reconstruct ideas short complete sentences provide context effective for memory organization and retrieval reduces information to Essential Elements facilitates quick understanding and recall designed to mimic human memory structure so just with this short eight uh eight lines of assertions or statements you probably get a pretty good idea of what an spr is um so that's an example of an spr and here is the hierarchical hierarchical memory consolidation system which is the autonomous cognitive entity uh memory system that I've been working on and it's 11 lines um but again it I won't read the whole thing to you but you get the idea so here is here is this um if anyone wants to use this and adapt this to an actual paper feel free it's um all published under the MIT license so this is free for the world um so that's the spr uh repo slash paper next is the hierarchical memory consolidation system I talked about this and I showed you guys that I had a really long chat conversation I'm going with chat GPT and so what I realized is one you guys can't read through this conversation and two again just a video is probably not enough um so I showed you guys this conversation before but here I've got um the most Salient bits um held out here I probably will try and get a little bit more information um because it gives you an overview um it gives you some of the theory and reasoning and it tells you the basics of how to implement it but I don't have any examples yet um so it might be more difficult but uh one of the reasons that I don't have examples is because I haven't fully implemented this yet um but it is here in theory also hmcs is not the easiest thing to say and if we've learned anything from chat GPT is that naming something that's easier to say is better so we might choose different names AKA I like this adaptive knowledge archive rolling episodic memory organizer this is actually like the most on the nose so Remo so we might call this Remo who knows anyways it's a good uh it's a good start um to this oh one thing that I did want to say is that I've got the discussions enabled for all of these um because these concepts are really important and really critical um and so we can discuss them on Reddit as well but you can also discuss them directly on GitHub if you'd like and then finally this is the most exciting one so uh four weeks ago the paper about large language model theory of Mind came out and since then a lot of people have been using Bing and chat gbt and gpt4 to do experiments with theory of mind and one thing occurred to me when I was working on sparse priming representations the idea that there's enough cognition going on inside the model to reconstruct something I realized that what I was banking on was implied cognition and so I just spent some time with chat gpt4 to articulate implied cognition and start to come up with some tests for it so I've got the full transcript of the whole conversation in here and you can read it it's pretty impressive um what what it was able to do so one of the biggest highlights of this conversation was as I was talking with chat GPT I said okay look over this conversation and look for evidence of implied cognition and it was able to look back through the conversation and give me evidence of its own implied cognition and even how to test itself and not only that but it did it much faster than a human could do it so it's like all right this is basically you know we're bordering on metacognitive abilities and we even addressed that as well I said how do how will we discern the difference between self-explication like true self-explication versus confabulation and it has some ideas on that too some testable hypotheses um so that's all here this is Far and Away the most interesting thing um that I was working on today um and then uh finally at the very end of the conversation I asked chat GPT if there was anything that it wanted me to document and share with the world and this is Verbatim what it said um about you know its own perspective on this and then desires moving forward um but yeah so what I wanted to do is I wanted to actually show you this conversation so you know I didn't just make this up this is this is right in chat GPT so I talked about theory of mind um I asked do you have any questions about what we're talking about um and it asks for clarification on sparse priming representations implied cognition so that was already evidence of implied cognition because it was aware of what it didn't know it was able to say I'm actually not sure what you're talking about and so by by virtue of chat gbt recognizing novel information that implies some kind of cognition and I don't mean cognition like human cognition and that's why I have this labeled implied cognition or you could even call it a facsimile of cognition and so then I gave it an example of an spr so I said sure for your first question here's an example of an spr um I said given that list of statements you can imagine what the concept is and unpack it does that make sense furthermore you can J you can even generate the highly Salient questions above implies a lot of cognition so I already recognize the fact that it can generate relevant questions implies some level of cognition um so it was it was uh it was okay with that and then it came up with some some initial tests so ask for logical reasoning understanding ambiguity generating relevant questions counter factual thinking so on and so forth and then that's when I as I was reading this I was like oh yeah self-explication um so the ability to explain itself uh plausibly is another uh potential um aspect of implied cognition um so then I asked it to analyze the conversation instead analyzing our conversation I can't identify a few instances wherein where implied cognition might be at play and so then it says context awareness so basically reading the context of the conversation it is able to understand what it means but also it's able to infer a lot about what's going on just by virtue of looking at the language um it adapts its communication now this is in part due to the fact that this is how the model is trained um but the fact of the matter is it does adapt its communication depending on what I'm trying to do conceptual integration so this is actually probably the most one of the these last two are the most important because not only was it able to really quickly understand the concept of spr and implied cognition it was then able to use it and synthesize more and build on it so the ability to to use novel information is the essence of fluid intelligence which up until now only humans have been capable of so just the fact that it is able to to recognize novel information and use it this quickly implies a lot so moving forward that's when I ask okay how do we discern the difference between self-expo explication and confabulation and then on on on being goal oriented that reminded me that goal tracking and figuring out one where you are um in terms of solving a problem figuring out where you need to go and measuring how close you are to solving that goal this is part of executive function and cognitive control and so I decided to just throw in a test for goal tracking as we go so then it came up with some really good ideas about um about uh testing for self-explication versus confabulation so checking for consistency over time external validation such as using another system um and then probing questions so ask follow-up questions or so on and again humans are not really capable of self-explication anyways we confabulate our reasoning post facto by and large unless we are very explicit when we bring an unconscious thought to Consciousness and we talk through I'm going to do this because and even then the reasoning that you think that you used is still not gonna going to be a hundred percent accurate um just ask any psychologist or philosopher we think we know why we do stuff but we really don't and so I even point that out in the conversation that self-explication is not something that humans are even really capable of um so having a expecting a machine to be fully capable of self-explication is kind of a moot point um but it still has some good ideas and of course explain ability and AI is important um and then it goes and unpacks a lot about goal tracking so it says um to evaluate our progress towards achieving our goals let's recap the goals that you've articulated um develop the concept of implied cognition establish tests and create criterias and protocol for using implied cognition progress so I was able to say okay this is what we've achieved we have so we have proposed several tests we have yet to create criteria next steps further refine the concept develop proposed test begin creating criteria and protocols for using implied cognitions um and we actually didn't get this far um but still the fact of the matter is it was able to kind of keep track of our goals um and then I made the observation that on conceptual integration it was incorporating new information synthesizing new ideas and Novelty so then I asked about novelty so recognizing new information is actually uh creates really distinctive patterns in the human brain and so then I was like okay it's a it was already implied that it you know just at the very outset right here where it said hey I don't recognize this can you tell me more about it so it can recognize novelty which is really important and really fascinating and so then I said can you discern what is novel and what isn't is it able to explain what it recognizes and what's new so it said in our conversation the following concepts and ideas would be considered a priori familiar so it understood theory of mind it already knew that language models and their potential for reasoning problem solving and cognition it said that it already understood that which is interesting General know Notions of memory and representation and efficiency the following concepts and ideas would be considered novel to me sparse primary representation or spot this spr's sparse priming representations and implied cognition so again it was able to restate these are things that I'm not familiar with um so then I told it that my hypothesis that perhaps what it's doing is that it actually gets a unique signal or a unique uh basically flow of tensors through the uh or mathematical patterns of tensors when there's novel information and it said oh yeah that's that's interesting and it comes up with a few ideas to um to explore how llms handle novel information and then we get into writing the repo which is out here so anyways and then I've got the whole conversation here so you can read it in Greater depth if you'd like um but yeah so that's it for today these are all ideas that I'm working on um and when I when I get so just if you're if if you're satisfied that's fine now I'm just going to ramble about kind of my own process so what happens is in the past when I get to this point I would start to write a new book but one writing a book is slow and two um well I mean that's the primary problem it it's slow but also we've got a good platform like there's my YouTube there's Reddit there's GitHub so it's like let me just go ahead and start um sharing this stuff as as soon as I've got it so that's that um yeah like I said uh all these are public they've all got the discussions I think I'll also go ahead and post these on Reddit for uh for discussion's sake anyways thanks for watching take care
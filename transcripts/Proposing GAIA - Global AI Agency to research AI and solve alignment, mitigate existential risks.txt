morning everybody David Shapiro here with your weekly video so today's video is about layer six of the gato framework which calls for international treaties uh or in other words Global AI based agencies so today's uh topic is going to be talking about what would those look like because uh in many cases people are just not aware of existing work that has been done on an international or global scale so I figured we would talk we would uh talk about those and um and then also you know first talk about what exists and then also talk about how uh a version of those for AI would look apologies um so real quick just before we jump in I'll plug my patreon I have a private Discord server for all patreon supporters and I also have weekly office hours for the premium tier patreon supporters I also do have a higher tier which allows for one-on-one calls but at least as of the recording of this I have no lots available that being said I do add slots occasionally you know there's Churn it happens okay moving right along so for some background a few weeks ago Sam Altman Gary Marcus and Christina Montgomery testified before Congress about artificial intelligence and one of the things that they asked for was regulation all all three of them asked for it in certain respects Sam Altman obviously the CEO of open AI has been calling for various kinds of regulation for a while Christina who comes from IBM she was a little bit more let's say corporate sanitized in the way that she asked but she basically said that IBM's policy has always been to be more in favor of of Regulation including going back to social media and I checked on IBM's website and they actually do have some policies and recommendations obviously there they have to be very diplomatic about it because they are not a political entity and of course we already we have a lot of in my opinion too much uh interference between the corporate establishment and American politics that being said uh you know the IBM has expressly asked for more regulation um on social media Ai and other uses of technology for a while so Gary Marcus is a professor and researcher so this this panel if you missed it was a good mix of Private Industry as well as Academia and they were all basically saying the same thing so Gary Marcus explicitly said we need a new cabinet level agency so cabinet level agency is like FDA you know or or some someone who's the head of which reports directly to like the White House or or the uh like you know Joint Chiefs of Staff or whatever I know the Joint Chiefs of Staff is uh for military um but you never know like we created a space force um you know NASA was the research branch and now we have a space force who knows maybe we will ultimately have an AI division for military um but anyways so one of the when pressed Gary Marcus said that you know one model that we could pursue would be the FDA but for AI and the the uh example that he gave is that when you release a drug to you know you know 300 million people you you make sure that it's safe you make sure that it has that has really passed muster one of the Senators interviewing him said he disagreed but you know he he appreciated the sentiment um and then there was also talk about well what what other existing entities could be empowered right like what about the FTC or uh SEC or whatever and uh there's actually a lot of people that Advocate that say like yes all government agencies must become AI aware AI literate but another point is that AI is such a distinctive and powerful force that it warrants its own uh agency just like how uh America has the department of energy which which focuses specifically on generation and management of energy open AI has also explicitly called for an international agency they call for IE iaea but for AI so the iaea is the international atomic energy agency which has to do with inspecting nuclear sites so the conversation is there the conversation is happening people are calling for National and international levels of AI uh not just regulation yes but I'm also calling for AI research um and I've got plenty of examples of existing International research bodies uh to share so first we're going to talk a little bit about uh the iaea it is was established in 1957 under uh United Nations it is an autonomous entity um its primary purpose is of course to promote the peaceful use of nuclear energy inhibit its use for military purposes and ensure nuclear Safety and Security you swap that out with artificial intelligence and that's exactly what we need uh it is governed by the General Conference of the UN and has a Board of Governors um that is appointed uh from 35 members of the UN um as of 2021 it had 171 member States and its annual budget is only 500 million Euros which is probably lower than you might think um especially when we're talking about the astronomical amount of money that artificial intelligence could possibly generate and so then if you say okay well we are asking for the foundation of something similar but for artificial intelligence uh maybe we start at the same part at about half a billion euros if the entire world chips in that's actually a pretty trivial you know amount of money so you divide 171 member states by 500 million euros and like 3 million Euros or three million dollars per member State uh that's a drop in the bucket so we could easily easily easily afford to fund such an agency so you know well who's going to pay for it I don't even want to hear that argument like that is a trivial like Nations could sneeze that and not even remember that they spent that money um one of the things that they do is as I mentioned they do inspections to verify compliance with nuclear non-proliferation they also assist in the development of peaceful nuclear programs so they have kind of a one-two thing where they're they're regulating but they're also educating and supporting and it is based in Vienna Austria so you might say okay well yeah but it's the United Nations it has no track record or the United Nations isn't effective or whatever uh you know but there is quite a few things that uh the iaea has helped with uh so the nuclear non-proliferation treaty um it actually has a dedicated um organization within itself um based upon nuclear non-proliferation it helped after the Chernobyl explosion which of course you know the IAA iaea could not prevent the Chernobyl explosion but it helped respond and so that's another key thing is that is that a a global entity shouldn't just be about regulation and enforcement but also like disaster mitigation if or when it does happen nuclear Test Ban Treaty was instrumental in that uh North Korea of course has uh nuclear Ambitions and the iaea provides constant monitoring for that it was also instrumental in helping with the Iran nuclear deal which of course the relationship between Iran and the rest of the world particularly the West uh has been very strained for many years but it hasn't been in the news lately uh due largely to that nuclear deal that happened under Obama I'm not saying that Obama is responsible for it it was an international effort but just pointing out he was president at the time uh the Fukushima uh disaster so that was after the tsunami that hit Japan uh the iaea was part of the coordination effort and then finally um the director general of uh of the iaea Mohammed al-barati um got the Nobel Peace Prize in 2005. so just want to point out that like yes this organization does have a track record and has made a name for itself now one of the organizations that I like to think about is CERN so CERN is a European so it's it is international but is not Global but it is there to study particle physics and so this was established in 1954 by 12 member countries it also now has 23 total members including observers there's a few categories so there's the founders which are Europe and then there's contributors and observers which includes the United States Japan and a few other nations uh and so this is an international effort to understand uh the fundamental structure of the universe right its entire mission is is literally understand the fundamental structure of the universe specifically the particles that compose matter and the forces that hold them together so as of 2020 for for whatever reason finding the budget of certain is is rather difficult um All Nations report in terms of like percentages of how much they support it but like getting a total number like what was your budget hard to find for whatever reason um anyways I think that the annual budget of CERN is about 1.1 billion dollars and of course they run um uh Large Hadron Collider and a few other major major experiments uh so CERN if you are not aware of is the organization that invented the World Wide Web this is a copy of the original proposal that led to the World Wide Web and at the top someone wrote vague but exciting um so that is uh that is uh uh many many people as particularly in computer science will understand that reference so this was the initial proposal for the World Wide Web uh it's discovered in a whole raft of fundamental Elementary particles bosons Higgs boson creation of anti-matter using neutrinos all sorts of stuff and of course we've got the Large Hadron Collider which generates many many hundreds of terabytes of data and it's interesting to bring this one up because actually I you know as a science nerd I was watching a documentary about CERN and LHC a few years ago and the LHC actually generates so much data that they need artificial intelligence to sift through the data to help find the phenomenon to find the anomalies and so there's actually a very tight feedback loop between for instance nuclear research and artificial intelligence so those are two organizations that have kind of the research mandate and then the regulation and safety mandate and I think we need both for artificial intelligence there's a few other International bodies that we can pay attention to that are probably either going to be good models that we can base this on or they could actually even be partners so one another Global organization that is more for emergency response is the World Health Organization which of course helped coordinate Global the global response to the covid epidemic but they've also responded to SARS MERS Ebola and other stuff so my uncle is a microbiologist and so a few years ago when there was a couple of outbreaks of Ebola he actually traveled the world to help be part of the World Health Organization response to contain Ebola and then of course MERS is something that you might not have heard of but it was infinitely more dangerous than kovid the mortality rate of MERS can be over 10 percent um and so like it's a there's some really horrible diseases that you have never heard of because of the World Health Organization um there's two Financial uh Global entities both were created at Bretton Woods after World War II and so World War II caused a lot of people to come together and say we need to prevent this from happening again and so one of the things that they decided after World War II was that economic uh Improvement and economic stability and economic cooperation were critical to maintaining Global Peace which has more or less worked up until that up until now um but it's you know time will tell because we're facing a backlash against globalization anyways getting lost in the weeds so the point of the IMF is to stabilize the global economy through cooperation trade exchange and so on so members of the IMF will get loans the IMF has been responsible for some bailouts they also have been responsible for um not necessarily economic sanctions but economic requirements so for instance during the global recession the IMF was the entity responsible for telling Nations such as Greece you need austerity measures before we're going to bail you out and so the idea of the IMF is that it uses that that ability to withhold funds in order to to shape National policy more towards stability rather than things like hyperinflation or economic collapse and uh you know the situation in Greece is still not good um after many many years that being said that you know we don't hear about uh the Greek economy collapsing in the news all the time granted I don't pay attention to Greek news but it doesn't make it into uh you know American uh financial news uh the World Bank uh is uh has a slightly different mandate than the IMF so while the IMF more focuses on developed Nations the world bank has the goal of ending extreme poverty um through financial means um and also to boost Global Prosperity through lending and Advising so the World Bank um is more likely to issue loans to developing nations and the reason that I bring both of these up is because artificial intelligence has the ability to profoundly impact artificial intelligence all over the world and and greatly Advance the missions of both of these entities and one of the best ways to incentivize aligned development is to pay for it and we'll talk about some of those tactics um near the end of the of the slide and I also have other videos that I'm working on talking more about some of these specific tactics and then finally uh the another research body is eater or iter which is the inner is the international Fusion research entity it's got 35 Nations working together to solve fusion and so the point point being is that there are actually many many examples of International and Global cooperation in order to provide safety stability and research as well as regulations so when we propose to do the same thing for artificial intelligence this is not like this is It's not like this has never been done before we've actually done this many times before so let's talk about how these hypothetical Global entities might work um so the first one that I propose is Gaia the global AI agency um and of course Gaia also means Earth so the Mandate for Gaia would be very very simple study and prevent existential risks from AI That's it that is its primary purpose uh it would publish open source scientific research papers data sets and align models and by making those models publicly available to everyone it will that will one make access to artificial intelligence much more democratic but it will also saturate help saturate the world with alignment research and Alignment data and Alignment models it would also participate in global policy recommendations advising Nations advising militaries and it would also establish best practices and guidelines that could be used by everyone Nations corporations and so on and so by by creating a global Authority a global scientific Authority that says yes like we understand and the idea is is just to comprehend this problem not to not to punish anyone not to put on the brakes but actually to focus exclusively on Research initial funding should be around 500 million dollars similar to the iaea and membership should be probably pretty similar to CERN or NATO which are international but not necessarily global and the reason that um I suggest that is because there is presently a competitive dynamic in the world and so basically in order to benefit from this Global AI research effort then um Nations should have to pass certain muster um for instance non-aggressive use of AI um and uh and you know not actively be you know at war or whatever something like that I could be wrong um I'm not uh I'm not an international policy expert yet so it might be that there is there are problems with that but between CERN eater and um and other entities it looks like that Global Research is not necessarily something that has been done yet but certainly International research um yep so that's it for for Gaia the next one is uh Garza or Garcia the global AI Regulatory and compliance agency so this one would basically be like kind of a combination of gdpr but for the globe and for AI right so it would inspect certify and regulate AI hardware and software so this looks at the at the hardware and software aspects of AI rather than like the data or policy but what it would use is it would use similar litmus tests and also like sanctions or regulations as to what the IMF does which basically says um you know if here's an example in in the investment world in the finance world if a company is not GDP are compliant it will not get any investment why because investors say you're not compliant you're at risk of getting shut down the same is also true of ESG which ESG is a as a inside the industry standard so ESG means environmental social and governance so the idea is that if you don't get that ESG you know stamp of approval you're going to have a much harder time getting investment and so rather than rather than enforcing it through you know more strong arm approaches uh my recommendation for the for the global AI Regulatory and compliance agency is to perform those inspections to perform those tests to basically be an underwriter a global underwriter of AI companies products and services and so then if if the Garcia Agency decertifies a company then it you know one their share price is going to go down because everyone's like oh you know they're not AI compliant they might get shut down they might get raided you know or or investigated or sued or whatever um but then if uh conversely if they are if they do get certified as AI alignment compliant then you know they get more grants more handouts more whatever um and so this is this is why I included the IMF and the World Bank is because you can you can absolutely steer policy research development and other behaviors with financial incentives and that also creates a relatively lightweight agency uh that that they don't have to do a whole lot of heavy lifting themselves but rather they provide that underwriting that certification and decertification which can then steer the behaviors of the rest of the world so this overall strategy is about having gas and brakes because one thing that people are legitimately worried about is that if we slow down too much someone else is going to pick up the speed right in a global competitive landscape the nation that slows down is the one that loses so we need gas but we also need Brakes in order to win any race you actually need both so I play Forza I've actually been I've I've played Forza since the very uh original Forza and so if you're not familiar Forza is a simulation grade uh racing game and uh you know if you're driving a Ferrari or a Lamborghini or you know whatever else a you know high performance you know Mercedes AMG around a track you don't just use the gas if you just use the gas you crash so in order to win a race you actually do need both gas and brakes and so this is the one-two punch of creating two different entities one for acceleration Gaia and the other for breaking Garcia and the idea is that they will have independent oversight and funding um which means that also because they have entirely different mandates those entities are going to have different methods of acting as well as different incentive structures uh so they have those different mandates they have different kpi now that being said they also both would have an international or Global scope and the reason is because AI is going to affect everyone on the planet whether or not they participate um and then finally uh part of this strategy is is both risk mitigation and encouraging Innovation and so if we do both then we should be on the right track um so here's a few more uh tactics so I promise that we would talk about some various tactics that they can use so the first tactic is just grants if you want to fund research you hand out money to do it it's really that simple um you uh you incentivize the behavior you want to see with you know you know you dangle money and people will go do it certification and compliance like I said gdpr is a is a pretty good example because gdpr is a pretty powerful lever in order to get companies to comply with data policy training and education so many of the organizations that we talked about do provide training and education and so by by providing training and education you can raise the global literacy on artificial intelligence whether it's just AI ethics and safety or the existential risks so by by having global authorities that provide this training and education and certification programs you can say like you know I'm a Gaia certified AI existential expert or whatever because right now we don't have any global standard of yes this is what the global experts agree on are the issues and the concerns and stuff certainly we have those conversations right if you're watching my channel you probably watch like Robert Miles and AI explained and everyone else um Eliezer like so you probably are aware that these conversations are happening but there is no coherent Authority there is no establishment saying yes we are working on this which is part of the reason that a lot of us are like hey we need to do something about this another uh possibility is that you can actually do competitions so in terms of AI one of the best competitions is kaggle which is a it's a competition platform where independent sponsors can come in and say hey we want you to compete to try and solve this problem over here open AI is doing their competition right now which is based on grants for the independent uh or Democratic inputs to AI DARPA is another one so DARPA is the defense Advanced research research projects agency here in America which funds uh amongst many many other things Advanced research on things like PTSD regeneration but also self-driving cars so the DARPA like I can't remember the name of the challenge was like the desert challenge or something um started many many years ago was about creating self-driving cars and so by creating competitions you get all kinds of teams coming to you whether it's universities and independent uh research groups corporations all participating in the research for the lure of a prize which of course uh is a good way to surface innovative ideas uh putting on conferences right now there are um there are international artificial intelligence conferences like nureps but none of them are focused exclusively on global safety whether it's existential risks from you know autonomous AGI or even just the escalating risk of autonomous and semi-autonomous systems such as weapon systems and so on so by creating International or Global conferences where you deliberately get all the experts in a room talking together uh that is a good way to advance the conversation policy recommendations I already mentioned this earlier in the video where if you have a global Authority on something if a nation comes to you and says hey you know we want to we want to you know spurn AI development what kind of policies do we do in order to attract that Talent right that's a that's an example of a policy recommendation or in other cases where a nation might come to these these International agencies and say Hey you know we have a lot of AI abuse going on people are using it to be exploitative how do we Tamp down on that successfully while avoiding unintended consequences industry Partnerships are another way that uh that these agencies could uh kind of help bring about the change which uh so an example is the IEEE which is a which is a uh was it the international engineering something or other anyways sets a lot of Standards uh for and workshopping for standards um basically created Wi-Fi Bluetooth a whole bunch of other stuff that you are familiar with which also helps establish standards uh and and uh interoperability uh consultation and review so this is something that like I do at a very low level through my patreon is I have a bunch of small and medium businesses come to me where they're they just want consultation how do I align AI uh how do I how do I use AI responsibly but also make money at the same time um and I would certainly encourage anyone who has expertise in AI to build a startup or something around this idea but this is also something that can be done at the national or International level where not just providing you know policy advice but actually providing technical assistance um where where required especially in the deployment of AI safety and Alignment research published standards and guidelines already mentioned that and then finally public awareness and messaging that's what I and a lot of other people uh do uh with our with our YouTube platforms Tick Tock and everything else but again there is no Global Authority uh taking any responsibility for this messaging uh which we view as problematic because you know basically it comes down to it feels like there's no adults in the room and that's really scary can you imagine if you know we lived in a world still where the World Health Organization didn't exist even for some of their faults and failures you still prefer that the World Health Organization exists because like I said there's a lot of diseases that you've probably never heard about because of the work that they do likewise you want to live in a world where if there are nuclear weapons and nuclear reactors you want to live in a world where the iaea exists and so because of those because of the existence of those organizations we have this feeling that there are adults in the room and that and that there are people paying attention to it and they have the resources that they need in order to affect uh good change and guidance and so this is why one of the primary things that that I advocate for and as part of the gato framework the global alignment taxonomy Omnibus is the establishment of these International treaties whether they're modeled on gdpr or these other organizations this is uh what we see as a critical path towards AI alignment and this is not just you know mitigating uh just for mitigating existential risk this is also to avoid dystopian outcomes of hyper you know corporations becoming quadrillionaires while the rest of us you know are poor and live under bridges or whatever so one thing that I will say is that these are necessary but not sufficient and so what I mean by that is that as my work has progressed as my messaging has progressed the conversation has been shifting so for instance after my axiomatic alignment video came out a lot of people reached out saying like Okay yes you know but there's there's a lot of challenges like you know who gets to who who does this research um but also like what about what about right what about all these other stuff and not every what about argument is um is disingenuous in these cases the conversation has shifted to these other what abouts not because of Doubt but because of like okay we overcome that problem what are the next problems and so this list is some other challenges above and beyond the uh the you know let's let's say you know we get to wave a magic wand in tomorrow the two organizations that I recommended exist okay still what's gonna happen first is economic barriers so what I mean by economic barriers is that uh not every nation is able to contribute or compete at the same way uh certainly the the economic lure is there for artificial intelligence that being said there might still be some economic barriers especially when uh some people are going to be uh throwing on the brakes right um one thing that people are concerned about is regulatory capture if you raise the bar so high that nobody else can participate except the largest players they have a de facto Monopoly which is not a good thing cultural differences so the work that I've been doing on axial axiomatic alignment and convergence has to do with finding the underpinning and Universal cultural values that all humans share after all yes there are many differences between nations and cultures but we're all still the same species and we're all still on the same Planet so that based on those assumptions uh well or facts based on those facts I assume that we can find some common ground somewhere that being said there are still pretty fundamental differences between some cultures um geopolitical tensions so this is a very diplomatic way of saying that uh some Nations kind of want to shoot at each other and they are in either con conflict or under um competition which is not necessarily I'm not going to say that it's good or bad it's problematic in some respects and then of course uh scientific breakthroughs all of this presumes that with the adequate funding and research that we will have scientific breakthroughs on alignment on AI safety uh but this again is aspirational just like how how um the eater experiment the the nuclear fusion experiment it is aspirational we don't know if it's actually possible we are hoping that it is possible uh and then on the next category is Game Theory so one of the most common whatabouts that I get now after axiomatic alignment came out is what about people that just are not going to play ball uh what about what about the uh down Downstream effects of toxic competition uh which you might have also heard you know we talk about moloch and other things so toxic competition is a very simple way of just saying that in a competitive environment people it creates a race to the bottom basically perverse incentives and unintended consequences these are all kind of uh related to The Game Theory aspect of this which is that despite best intentions and best efforts towards achieving a better outcome you still end up inevitably Falling Towards dystopia or Extinction or collapse uh and then of course there's reach and limitations um just because we create these International organizations doesn't mean that they're going to work uh you know if if you get adoption if you get buy-in if people uh Blacklist the organizations or whatever and then finally unknown unknowns uh you know we're still we're still working our way to the Future um so we need constant vigilance uh anyways thanks for watching I hope you got a lot out of this um you know in the long run I'm hoping that all of my videos are completely irrelevant because some organizations like this get created and then uh the real experts get to uh get to get to comment and um kind of steer the ship which we don't have right now which is really terrifying so thanks I hope uh I hope this made you feel a little bit better at least in terms of options that we have before us thanks for watching
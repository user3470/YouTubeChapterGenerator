one of the questions that I get all the time is Dave how do you keep up with research and how are you so productive and I frequently get questions about you know what's my workflow and what's my process and um I I'm not going to show you my full process because well it's really kind of custom personalized to me but what I will show you is a tool that I just built that's based on you know my scripting abilities and and all that sort of stuff and this tool is just too useful to keep private so it is already public uh it's called weekly underscore archive and it that's just kind of a general description of what it does basically what it does is it's this nice handy dandy little python script that it just asks you for a uh a lookup query and then it goes to the uh the to the archive API and we'll search for that query and download the latest 200 abstracts and then it will format it into markdown for you so let me show you an example of what the the output looks like so I put in just llms so llms is the query and it gave me this nice uh searchable document that renders nicely and I've got it so that it gives you the title the link to the paper list the authors so if you want to search by author and then the summary so for instance I was doing research and I wanted to learn about driving and so it turns out there are four papers out in the last week alone that have to do with using large language models for driving for autonomous driving so first is language MPC so large language models as decision makers for autonomous driving driving with llms fusing object level Vector modality for explainable autonomous driving and then what was the next one the next one was it did a GPT driver learning to drive with GPT so that's pretty cool and then finally Drive gpt4 interpretable end to end autonomous driving via large language model so that's really cool but the archive website is not necessarily the most searchable thing and the reason is and the primary reason is because one you can only have up to 200 results per page um and you have to expand the abstracts so I was like okay well I wanted to download this page and re-render it without violating you know archives um thing but also I wanted it to be eminently renderable so that I could drop it into Claude because Claude you can see where I just copy pasted a whole bunch of stuff basically titles and abstracts into um Claude and then I'm like hey tell me what the latest trends are and so for instance I discovered um you know many papers are focusing on llm's abilities to do things like reasoning planning and knowledge intensive tasks and then you can scroll down and say okay cool give me a list of the papers that do this so instead of manually scrolling through you know like hundreds and hundreds of archive papers uh to in order to get a feel for where the trend where the industry is I just like said okay hey tell me what some of the trends are to Claude and oh you have Claude you have to be very very explicit I said please write a summary of the benchmarking Trends as elucidated by the text I gave you if you don't do that it'll just make stuff up Claude is still really really bad about hallucinating and the thing is is there is very clearly some archive papers in its training data so it'll it'll if you don't tell it only use what I gave you then it'll start either making up archive papers um or citing papers that are much older and I'm like no make sure you only pull from the information I gave you in this conversation um and then like it will change the formatting on you if you're not careful and I'm like why did you change the formatting on me anyways so they still have a little bit of work to do on Claude but that's not the point of the video point of the video is that they have a nice free open source search that gives you this gigantic wad of XML which is a nightmare um but you know it is what it is it's XML um and it's free so you know don't look a gift horse in the mouth um and yeah so how you use this and actually let me show you a couple other ones so here's the first one that I did so if you want to look at today you know the the last week's uh stuff of large language models click on that one um I did one where I just searched for bacon as a test to see what it would come up with and apparently there's a lot of authors named bacon but there's not a whole lot of archive papers on the food bacon so that was really disappointing um but you know whatever um and then I did another one for Quantum Computing because I wanted to make sure that the input would be able to handle uh spaces so basically it has to be URL encoded which is really simple you just replace it with a percent 20 and away it goes you can see it's taking a minute to render I'm not sure why it's taking so long I think I broke GitHub um anyways we will wait so yeah really simple tool really straightforward um let's do a real quick refresh there we go um okay so check on Quantum Computing um it might not load but yeah so very straightforward you just run this pie um this this Pi file and so I'll walk you through the script real quick just in case you want to see it but it just so the first thing is it takes the input what you want to look up you type it in it does it in lower case and replaces any white space with a percent 20 it'll go it'll populate the URL oh another thing you can change this URL if you want to search by something else if you want to search for author or change the Max results um I I have the uh sort by last updated date and sort order um uh descending so this will get the latest stuff because really the problem I was trying to solve was um all everything is moving so fast so it's like I wanted to just have a way of figuring out what is going on with the world at a glance uh in terms of large language models because it's like there's Laura and Q Laura and there's all these kinds of benchmarks coming out and so what you can do is you can just like come to this and say all right let's look up benchmarks so from words to watch benchmarking the energy costs of large language model cool great paper glad this exists uh and you can see there's 115 references to benchmarks in in this um T dollar cubed bench benchmarking Uh current progress in text to 3D generation great cool now I know that there that we're benchmarking uh text to 3D generation um let's see Shadow alignment so that sounds cool it's like Shadow Banning people uh do they still do that on Reddit and Twitter um anyways yeah so uh GPT fuzzer right okay great anyways idea here is that you can download hundreds if not thousands of the latest uh latest papers on any particular topic from archive whether or not it's large language models um you can you can put in Quantum Computing like I said but for whatever reason it's not rendering directly on GitHub um I broke it so but yeah you can download any an arbitrary number of things it's sorted by date uh by release date it is uh in descending order so you know you've got the latest and greatest yeah I think that's about it um so thanks for watching cheers and yep I definitely broke it have a good one
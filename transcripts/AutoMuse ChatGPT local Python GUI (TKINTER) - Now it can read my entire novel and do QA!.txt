hey everybody David Shapiro here with a video update um so this is super exciting let me just go ahead and show you right off the bat what I'm working on and I apologize that it's small um this is uh it's a it's a very primitive graphical user interface but as most of you are aware chat GPT has been in um let's shall we say bad shape um network errors your history is gone etc etc and for a lot of people that means like your your work comes to a grinding halt that being said I've been working on learning the chat gbt API I've got access to gpt4 um not the 32 000 token one um if anyone knows how to request access to that please let me know in the comments because uh working on a novel I could easily make use of the 32 000 tokens that being said the 8 000 tokens will carry you a really long ways so with that being said um this is the repo it's chat some chapter summarizer gpt4 and it is already completely wrong because it provides developmental feedback Pros feedback and now you can actually chat with it um and it will know your entire story so how did I achieve this um with the larger token window with the 8000 token window that is enough that you can um some you can summarize all your chapters and it will fit you generally within it it probably won't fit by the time I finish my novel but hopefully I'll have access to the 32 000 token API endpoint which means that I'll be able to summarize the whole thing and then what I did was I took the scratch Pad here and I've got all this documented too because this is like the best instance of Auto Muse yet so basically you copy and paste whatever you want into the scratch Pad um uh file uh whoops where did it go so you copy it into scratch pad and you see it's 24 kilobytes so this is a summary of the first 19 chapters of my story um and it's from here you know the chapters the text the conversion the chat logs oh I want to show you like this is working right like here's all the chat logs that I've got uh between myself and and and the Muse which also means that you've got a permanent record even if chat gbt goes down um and all this is excluded in the in the git ignore so you see um open AI your key is ignored chapters uh the summaries and the chat logs and the scratch Pad so don't you don't have to worry about accidentally sharing any of your own um any of your own work um it'll just stay local in the repo when you copy it down now I was using chat gpt4 to help write a graphical user interface because I was like you know what um I could do this as a web web thing but honestly I don't like why have multiple apps running like why why use a a web browser when python has a built-in graphical user interface and so that's this here so I was using chat GPT um to help make this and you can see like it dynamically sizes I've got it color coded so that you can just easily see what's going on um it also uses threading so that way because it takes a while for the API to uh to spit out something but yeah so let me show you the uh the The Prompt that I use so the scratch Pad this is just all the information about your story I probably will get this automatically updated in the future but for right now it's just manually copy pasted and then I have a new kind of prompt it's a instead of a prompt it's a system message so in this case it says here let me zoom in I'm a writing assistant and coach the following is the summary of chapters for the novel the user is working on my job is to help them develop their novel in any way that I can including brainstorming plotting outlining and planning we may engage in developmental editing which includes restructuring or modifying character arcs plot threads World building and development developing of themes we almost we may also work on finer grained aspects such as character backstory subplots and so on I should refer to highly professional writing Concepts such as the 3x plot structure the work of Joseph Campbell and CG young save the cat and any other formalized approaches to storytelling I should not seek to push the author but rather teach them when I perceive gaps in their understanding Above All Else my primary mission is to help them produce an amazing work of literature um and then so then I you can populate whatever's in the scratch Pad here and again you can dynamically update this if you want um important note the above material is provided for background information this format is not necessarily intended to be used moving forward lastly be sure to ask plenty of questions so that the author remains firmly in the driver's seat so this huge Constitution or purpose or system message actually works really well so in this case um just right off the bat I can say hey describe the main characters and identifies all four of the main characters and gives a very succinct definition of them and actually this would be really good back matter um for the the you know the little blurb um so you can see that just with one message it is able to um uh read my entire story up to this point while the summaries at least and we can talk about it obviously I don't want to reveal too much more about my story um you guys know the main characters and a little bit about them um but yeah so uh give it a try yourself I'm super happy with this um and the biggest thing that it does is it saves time because again I've got I've got all of my chapters loaded into it and now I can just ask it whatever I need um also I found that this system message it really cuts to the point I'm just like hey let's plan the scenes for the next chapter it's like okay cool let's go um it does it does do a little bit too much for me but the fact that you don't have to spend too much time going back and forth I think is actually better because it will it'll come up with an idea and say hey do you like this let's modify it and then you can say yes let's modify it um so that's probably all you need to know but now we can step through the uh the the function um so I I did a nice clear demarcation this is what I wrote so just these just these three things open file save file the chat GPT completion which you can see it's using gpt4 um I did I do still have it nested in a while true Loop which is basically just to capture in case um in case the API has an error which it does all the time lately and then I added this here because if the chat conversation gets too long um it will it will give you a maximum content length there and so in that case I just removed the oldest message not a big deal um it actually uh chat gpt4 said why don't you actually measure the tokens and just uh remove it until it's done but I couldn't actually find anything on this the the open AI API client the clean the underscore clean um I think that's a tokenizer but I couldn't find any documentation and I didn't want to try it just yet but anyway so that's there uh let's see nothing else really changed here um I still have the exponential back off which basically means that it'll wait longer and longer to retry until it will finally give up um and it's just because the the the the API is wonky right now now everything from here down was written by gpt4 uh just with some feedback back and forth between myself and gpt4 so basically it came up with the function to send the message the thread to get the response I asked it to uh to ignore like if you if you use shift enter it will just insert the um the new line character otherwise it'll send the message um because I realize like that function is available in chat GPT on the web and then finally uh it did every uh basically all it did was it took I gave it this much and you can see here where we populate the system message by loading what you have in the scratch pad it then populates the system message based on this and starts the conversation with that um so the the the system role will be in index zero meaning index one is going to be the oldest message in the conversation so then it fires up the ticket the tokenter GUI oh and for anyone who's not familiar with tokenter um that's what this is it's just it's a really brain dead simple uh portable um uh graphical user interface and so then it constructs it all there's a few problems when I first created it so one the the window was was static so it wouldn't allow you to expand and then also while it was waiting for the API to respond the whole thing would freeze and say not responding but now it has a little output here that says you know Auto Muse is thinking um so welcome to Auto Muse um it gave the uh you know it set to word wrap um it's yeah so basically it just when I had when I had an issue I just said okay hey can you make this modification um and away it goes and then again one thing that that I haven't integrated is um being able to search the previous logs but because of the work that I've been doing on um on other topics um that that'll be there now it might not be relevant because once we get to the 32 000 token window limit that's going to be like what like a hundred Pages uh worth of chat logs like you won't even need that much uh history right so you could load this entire history and you know most of it's going to be irrelevant uh so anyways we'll see I did have a thought uh one final thought about the kinds of problems that we that we solve just by increasing context window um is amazing and so basically what I'm going to be doing from now on is I'm not even gonna try and and force problems to fit into smaller context Windows because one larger context windows are coming and two the kinds of problems you are able to address once you have that larger amount of working memory completely changes the game um so I was talking with my fiance and some people on Discord and what we're noticing is that we're getting more and more purpose-built models so there are some open source models out there that have token windows up to 64 000 tokens which is crazy some of them have 16 000 tokens so on and so forth so what we expect to happen is that uh we're going to end up with many many many models most of them open source that are purpose built for specific tasks so for instance some models are going to be focused on uh they're going to be like window optimized models right so like we might eventually have a window optimized model that can have a token uh window of like a thousand uh not a thousand a million tokens right but then we might also have compute optimized models or cognition optimized models um that sort of stuff and some of the people in Discord are like oh yeah I'm already working on that so that's the way that it's going um and then aside from that uh from just from a psychological perspective my fiance pointed out that working memory is actually one of the biggest factor in intelligence and that by by doubling the working memory the effective working memory by going from gpt3 with a token count of four thousand to gpt4 with a token Window 8 000 doubling the working memory that like basically takes it up in order of magnitude or a standard deviation of IQ so if GPT 3.5 had an IQ of about 115 doubling that that window takes it up another 15 points to about 130 um and then when you when you actually if you were to test its IQ based on speed it's probably already like in the 160s or something um and the so there's there's from from a from a numbers perspective two of the universal features of intelligence that figure that should figure into a good IQ test one is processing so IQ um most IQ tests are actually speed tests which because speed is a good proxy for a lot of kinds of intelligence so your mental speed is not your IQ but it is a proxy for actual intelligence and so when you measure the speed of gpt3 and gpt4 its IQ is actually really high but then the other universal one of the other Universal things is working memory so uh working memory is also a really good proxy for uh for intelligence and many forms of intelligence so when you combine the large working memory combined with the speed um of reading and output I would say gpt4 probably has an effect IQ of around 130 if I had to guess now that being said it doesn't have permanent memory you have to have a secondary system for that but that paper came out that talked about how storage systems combined with llms are are computationally complete so I'm not worried about that um yeah so that's that's the direction it's going and that's where we're at right now so I'm really excited to get my hands on the 32 000 token one I think that that will also really help with the scientific research one so I haven't made any progress on oh and I also wanted to show you how expensive it was so yesterday it cost about four to eight dollars to summarize the first 60 of my novel and then the conversations that I had about it so even just reading all the summaries and talking about it cost another two dollars and 62 cents which is still kind of expensive but in the grand scheme of things like it's so fast and it is still a lot more expensive than just the twenty dollars a month um for the like unlimited chat GPT but that price will come down I'm not worried about that but anyways so figuring out these chat interfaces and how to handle large amounts of information and and really how to make the most use of the system window that is what I'm working on now and I will return to the um let's see where is it um the yeah the regenerative medicine thing so I've been thinking about this one um come on so I got a bunch of papers but the thing is is these papers are unrelated wow it's already been two weeks good grief um a lot of these papers are unrelated um which I think um is kind of problematic although you might think the idea that like cost pollinating stuff like correlating stuff from unrelated papers could be really good priming exercise so anyways as I'm getting more familiar with the chat GPT API and how to use it I will come back to this because I realized like yeah I really want to help accelerate science as fast as possible because I'm really looking forward to the day where I can go to the doctor and just like get an outpatient injection and then of my joints will feel better in a few months right that's really what I want um because man like I do not have as much energy as I used to and I have to be really careful because like I have old shoulder entries from falling while snowboarding like there's so much that I can't do anymore just because I don't want to hurt myself anymore um anyways I'm complaining about getting old it sucks everybody knows that I think this is enough of the video so thanks for watching cheers stay tuned um this is this is so much fun
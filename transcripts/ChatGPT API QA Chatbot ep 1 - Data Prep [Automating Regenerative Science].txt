all right gang so David Shapiro here um one of the questions that I get the most on patreon and Linkedin and everywhere else is how do I make a QA chatbot I get questions like how do I answer specific questions whether it's in a um a high risk situation and I mean like uh law medicine mental health all kinds of stuff and of course you know chat GPT is out and you can do some stuff but you know it's it's bounded right they have their own things but with the chat GPT API we can do our own stuff um and natural language interfaces are certainly the way of the future or at least the way of right now for how we're going to be interacting with data and computers so I did a little a little poll um and a very very clear majority people want QA chat Bots now I was laying in bed last night and I was like I want to do I want to accelerate longevity and regenerative medicine um because like that's one of the things that I'm I really am looking forward to like I've got an old shoulder injury and I've got like you know I'm getting old right and getting old sucks and I just saw that Sam Altman invested 180 million in um in this stuff so I was like okay well what if I can combine these two right so here's what we're going to do we're going to go through the whole process of um using the latest and greatest AI tools to make even more AI tools to help accelerate longevity and regenerative medicine and we're going to do it with the chat GPT API so this is going to be a series uh I don't know it's going to take a while to unpack and I'm also going to do a little bit of real-time editing with pausing and stuff so anyways um here's where I'm starting and I often uh in past experiments I'll often collect the data before like without showing you guys and then I'll forget how I got it so I'm documenting how I got the data in the first place so I would come over to Bing AI which uh Bing chat searches the internet and I can tell it what I'm looking for and also speaking of um we're up to 10. so that's good um it'll be better once they figure out how to get get us back to unlimited conversations but we're we're going we're going in the right direction so I asked for sources for primary research and I said like NIH and archive and of course it just said NIH and archive but it also added nature um and so basically what I'm doing is I'm going to gather some sources I'm going to download some like PDFs or uh or other articles um and use that as my my data now obviously this is probably not I'm I probably will not succeed in advancing science on my own but what I can do is I can demonstrate how and then someone else can take it as and put it into a product speaking of um I have had on occasion some people reach out to me and say like oh I Incorporated your work into like my startup or into my business like please let me know what you're actually using my work for one it's just nice to know but two it also helps me understand where I'm adding value right because my my whole goal I'm not here to make a ton of money I am here to help bring about post scarcity and Singularity and all that fun stuff all right so anyways um let's see I'm specifically trying to accelerate um uh longevity and regenerative uh research um with AI so I'm looking for uh papers that can be integrated into automatic NLP stuff um yeah that's basically it so so I think the kinds of papers that will be most helpful are likely um to include specific techniques uh proteins enzymes um enzymes that doesn't look great enzymes um and therapies uh let's see does that help narrow it down all right so if I tell Bing what I'm doing hopefully it'll have a better understanding of what I'm trying to achieve and then give me a little bit more specific stuff so anyways uh regenerative medicine so nature.com regenerative uh looks like this is pretty good so there's plenty of stuff that's open access so in order to respect the data I'm only going to download stuff that has Open Access which it's great that that um they do this actually I'm going to bookmark this favorites bar um because that's good information let's see yes that helps a lot thank you for sharing artificial intelligence and Longevity medicine which discusses interesting so there's oh okay so I found a nature article talking about it oh this is only a preview okay so I think we'll need to specify um that we need uh Open Access stuff let's see let's see um do you want me to show you how to download any of these papers um no some of them are not open access but I'm not looking for um Ai and aging papers I'm doing the AI I'm looking for um uh therapeutic techniques and candidates and you try again yep so therapeutic techniques and candidates for longevity and regenerative medicine so it's just what it's doing is it's distilling down my search query which that's actually a super easy thing to do with prompt engineering you just say take this paragraph and convert it into a Google search query or in this case a Bing search query all right let's see regenerative medicine all right the Lancet so that's a good one envisioning future Trends in regenerative medicine so some of these Yes except all cookies where'd it go okay all right so this is not this is requiring stuff so here's one thing where um I am really skeptical because like all of this gatekeeping and pay walls is actually really going to slow down research especially in the age of AI that being said it's like okay there is some value added by um by these things okay uh let's focus on Open Access sources um of regenerative uh medicine research can you find any more aside aside from archive and nature because like okay the fact that like this one is here so medical Express but this is like a no-name site so it's like I don't even know if like what this is yeah this is just someone restating something else and it's just pointing at nature anyways okay so it looks like nature Open Access is going to be our best source so far we can also have archive um so let's see if we go to Archive and we look for like let's see where is it well it oh looks like we're looking for Bio archive okay oh man this website is like from the 90s [Laughter] okay this is gonna be a pain ouch all right Neuroscience molecular so molecular biology Immunology genomics genetics um let's see cell biology cancer biology um biochemistry synthetic biology that's fun okay structural bias so a lot of this stuff is not going to be like directly relevant which is interesting um okay sure open Journal of regenerative medicine hey that looks stem cell research and regenerative medicine and npj there we go open Journal of regenerative medicine so let's bookmark that favorites bar Open Access Journal stem cell research and regenerative medicine okay I'm not seeing any papers um let's see looks like they only have like a couple of issues per year I don't know this looks low quality okay um all right well we've got a couple right so let me let me bookmark bio archive as well okay so if we come here got bioarchive we've got open Journal of regenerative medicine um and then we've got nature so we've got three sources um of of data so what I'll do now is I'm not going to what make you watch me download everything but now you see how I've gone about finding this information um and so then I'll download just a whole whole mess of this stuff um and then save it and we'll start to slice and dice it all right pause it download stuff we'll be right back okay and we're back so I downloaded um about let's see 81 papers so this is obviously 81 research papers on a variety of topics this is not a really coherent search strategy this is just a proof of concept because this is um to demonstrate like because this is an intractable amount of of material um sure a professional scientist will probably easily skim through more than this number while performing a literature review but imagine that you've got 2 000 or 10 000 of these that you need to sift through and get information from so imagine that in in your in your citations page instead of having 30 to 100 what if you have like 30 000 citations and we can do that automatically with AI and we can find them quickly through chat bots so that's step one was downloading stuff which I just showed you and then step two is let's convert it so I have this handy dandy um public archive right here um called document scraping and I've got a convert PDF file here so what we're going to do next is we're going to and I'll show you it's really simpler convert PDF to text and it what it'll do is it'll grab everything in that um in that folder uh that's a PDF and then dump a text version out to the uh diff uh to the next folder and then it it breaks it up by page so I'll just say new page right it's not a big deal and this forms a nice easy way of of seeing it so I'll show you what it does so CD to chat GPT regenerative medicine and then we'll do python step 01 convert and so what it's doing is it's going through and converting them one by one and it's dot it's dropping them here so you can see here is the information and obviously this is not going to grab the um uh what you may call it it's not going to grab the the graphics and stuff and that's fine because we don't have multimodal models yet apparently gpt4 is going to be multimodal um but at least this should give us all the information that we need in terms of uh text information so this is running it'll take a minute um obviously very much taking its time so I'll go ahead and pause it again and show you the end result Also let's see we're only at 12 minutes so we'll see how much further we can get um yeah we'll be right back all right so we've got um we've got 81 text files now I always check my data and so here's a problem is um some of the lines uh have no spaces some of them do some of them don't it's really weird I don't know if this is a problem with the with the PDF plumber or with the underlying PDF itself um so I I don't know what's going on but from there and here like okay you see this one this one looks like it's formatted fine I'm not going to delete it because it's like okay we still want this information and also um even if it is uh even if if the formatting is botched like that as it is in some cases gpt3 can still often read these um so let me just grab this and show you what I mean so let's grab this and go to um and then we say um let's see complete um uh fix the formatting issue fixed and so then if we let's see do that up to 500 zoom out a little so you can see it can still read it and add the spaces back in which means that it can comprehend the um the word boundary problems um so yeah gpt3 can understand it it's honestly probably been trained on a lot of data that is malformed like this um so it's fine um yeah that's good so now let's come over here and what we're going to do is we need to convert this these text files into something that's usable so one of the advantages of having new page right here is that we can open open it and then split it into um into individual Pages again that are text so we're going to do is we're going to have a folder called Paint whoops papers underscore Json and now I'm going to ask chat GPT um write a python script that uh opens all uh no let's see that yeah that opens all text files from the folder um papers underscore text splits them into a list of strings with the demarcator new page then take each page and get an embedding by passing the string to a function that I call um let's see gpt3 embedding to a function called gpt3 embedding um finally let's see save uh all of that into a Json file um one Json file for each original text file the Json should have um elements such as original file name and then a list of pages where each page has a number which order it was um the original text and finally the embedding um okay so that should be enough sure here's a python script wow it's fast I guess nobody else is using it right now um okay Pages embeddings gpt3 embed page for page and Page oh wow okay that's fun um yep original file name file name Pages equals I plus one text Page embedding to list for I and Page embedding enumerate zip pages dang I think this is it um [Laughter] this function is wrong but that's fine um yep okay so let's copy this and come out here all right so let's get rid of those guys all right so for file name in OS Lister dur path and dur path is here so we actually want to make this a function um let's see that's great but let's make the um the for file name in durpath a function and then call it from if name equals Main all right so process text it's defining a function within that doesn't make any sense that is what it's fine yep uh or let's see no stop stop stop um let's remove the uh gbd3 embedding function from being nested inside another function um that is not pep 8 approved at least I don't think so sure here's an updated yep and so basically I'm just going to ignore that um because I wrote that function else wise okay so for this in that etc etc there we go and then uh let's see oh one problem one more problem um the output directory needs to be specified as papers underscore Json and see this is why I don't like using um uh copilot because you don't have a dialogue right it's just guessing what you want and then what I can do is I can just look at this and say okay why is it not allowing me to pass uh papers Json I'll pass okay um why is the out path hard coded and not parameterized does that make any sense to you [Laughter] I'm way too passive aggressive with this thing I apologize there was an error generating a response I'm no do not so here's the thing when you do regenerate and it just continues no stop stop stop because then it's broken up into two so what I'm going to do instead is I'm going to come here and just one remove the saltiness um please fix and let's start over good catch so uh open AI maybe you can have it as a as a setting but honestly if there's an error I would rather it just like save what it did and then pipe that in I don't know like yeah there we go much better okay so let's copy this and come back over here um we don't need that function so basically what I did here is I copied a few functions from another script so here's my embedding one oh because we're using data from the internet I always do this where I force it I encode it to ASCII and then decode and that fixes Unicode errors because um gpt3 often does not do well with some forms of Unicode I still haven't figured it out maybe it's not even an issue anymore but if it is it's still out there okay so if it doesn't exist make it great for file name and Os Lister if it ends with DOT text that's great split it into Pages embed it and then here's the output so we get all the pages excellent um I'm just going to trust that this works um because I respond with this so the vector I don't think it's a numpy array so that's fine embedding to list I think it's all ready yeah so embeddings equals so this is already a list I believe so I think this will break that's fine and then we zip the pages and embeddings oh interesting okay we'll see if this is formatted correctly and then let's see save it so it just replaces the file name that's good um with OS but I actually already have a save Json thing so we just have the file path and the payload and in this one I specify ensure ASCII false sort key is true and then indent so this formats it nice and pretty um so what we'll do instead is we'll comment this out and then we'll just do save Json and what is the order I have it file path and payload um so then the file path is this guy and then the payload is output dict yes all right so that should be good now if name equals main etc etc so what I want to do next is add a little bit of debug I want to see what it's doing um so what we'll do is hmm I guess this is just going to be messy no matter what we do um so let's add an embedding let's add some output here um so we'll do print content to embed and then we'll do content and then we'll print vector Vector all right so that way we'll be able to see it embedding as it goes um and that should be fine and then yeah that'll be fine all right so let's save this and come over here so python step O2 um hey look we had it we had a we had a an issue Unicode decode error okay in uh text F read oh yep so here we go all right so I'm gonna ask I I know what the problem is but I'm gonna ask chat GPT got an error can you fix it there we go dude so basically it's it's pretty simple all you have to do is specify make sure those are spaces okay yes so you specify the encoding is utf-8 um and so now it knows better all right so let's try that again that that should not go that fast um okay so the fact that it's going that fast and it's not outputting the vector means that it's barfing somewhere here so let's comment out this because it's probably returning none um which I had I had that uh because there was another project that I was working on where some of the things failed always use notepad um let's see embedding null yeah so you see it was not embedding so let's delete these it worked mostly let me close these because they're Superfluous and let's see why it's blowing up oh you need an API key what do you mean I need an API key here let me fix this I'll be right back okay I think I fixed it so I added this here and then I copied my git ignore and API key right here so we should be good let's give it a one last try and also I did a time check we're at almost 30 minutes so this will probably be it for today but we're off to a pretty good start if I do say so myself all right so let's do let's try and do some embeddings that's still seen oh nope it's just that fast look at that look at that um all right so let's take a look at the output oops all right so the embedding so for each page we get embedding page number text embedding page number text and then we we keep the original file name as well um and so this by using this we can trace it back to the original PDF as well because we're going to basically need to be able to cite our sources um all right cool so this is tearing through this um let's see make sure it hasn't blown up all right it's still going and so you see basically what we're doing is we're getting one embedding for every single page now there's a lot more that we're going to need to do um in order to make this usable because some of these are like 80 pages long which is way too much for it to read so then it's like okay well if you search it based on the embedding that'll get you close but then what else do you do there's a lot of problems to solve but the fact of the matter is this is going to give us basically a super Advanced chat based scientific search engine now because I'm also working on cognitive architecture we can have it do a lot of thinking for you in the background that's going to be the real game changer not just a chat bot that allows you to search but a chat bot that you can ask at scientific questions and it will go think about the problem for you um so I'm going to let this finish I'm going to go ahead and stop the recording and we'll come back tomorrow for part two thanks for watching
good morning everybody David Shapiro here with another video so uh I mentioned a few videos ago you may or may not have seen it I mentioned the concept of polymorphic applications and a bunch of you are like what is this concept tell me more and some people are like yeah whatever that's not possible so this video is here to teach you a new paradigm of software development and software architecture so it's I call it polymorphic applications or basically self-changing applications and we'll get right into it but first I just wanted to say I am available I used to do Consulting on patreon I still have a few patreon clients there but I'm kind of moving uh moving to more involved engagements including strategic and Technical Consulting teaching and coaching as well as speaking engagements so reach out to me on LinkedIn if you're interested in any of these services and then with all that back to the show so a couple days ago uh Microsoft CEO Satya Nadella at the Microsoft Inspire 2023 uh keynote basically said AI is here and these are the new capabilities because of language technology so the two primary components that he outlined were natural language interface so that's the front end right voice chat that sort of thing emails and then in the back end you have what's called a reasoning engine and so what is a reasoning engine in this case a reasoning engine is instead of thinking about the language models as something that just generates text right A lot of people pick the low hanging fruit let's use it to write emails let's use it to write fiction uh you know that's that's the obvious use case but what's less obvious and this is what I have been advocating for for literally years uh when I wrote my initial book on cognitive architecture natural language cognitive architecture I said we have invented a cognitive engine or a reasoning engine he probably didn't use cognitive engine because that's a very anthropomorphic but it's a it's a reasoning engine and so what does that mean language models uh are they're capable of brainstorming and planning they're capable of problem solving they're capable of coding and testing code and interpreting bugs they're also capable of choosing and deciding or making decisions and so these are all elements of cognition and this is why I have been focusing on cognitive architecture for the last four years so also the keynote was really good you should watch it if you haven't especially if you're if you're whether you're an investor in this space or a startup founder or a product owner if you are doing anything with generative AI you need to watch that keynote speech Okay so I promised polymorphic applications but really one thing that you need to become more familiar with is what I call Mission oriented programming so this is the next Paradigm Beyond object oriented programming instead we instead of thinking of objects we now have to think of missions uh as the as the primary organizing feature of this new software Paradigm and so let me just read the definition a mission oriented programming is a paradigm in software development where applications are primarily designed and built around a clear measurable and purposeful Mission and I'll give you some examples in a little bit don't panic the mission serves as the core driver of the software's behavior adaptation and evolution these applications often referred to as polymorphic applications are not just tools but active agents in pursuing their respective Mission and so then there's a few components of this one mission-centric design number two autonomy and agency the ability to make decisions uh in pursuit of that mission uh there's needs to be adaptability and flexibility hence the polymorphic aspect Dynamic tool creation if it needs a tool it can make the tool and then on the lower level uh how do you actually allow the the the application to change itself you use micro Frameworks configurable front ends and configurable back-ends uh okay cool so I just threw a lot at you um you're probably like what what are you talking about uh you know think about it this way this is how we got here llms can write code they can solve problems they can make decisions they can write unit tests they can write user stories so extrapolate that out as far as possible you have an llm that can do all of these things one at a time what if you stack them all together so another way to think about it a simpler way to think about it is generative AI or llms or whatever they're just a type of automation so if you're an infrastructure engineer an I.T guy or a software Dev or a software architecture software architect just think about generative AI as just another kind of automation that's it automation automation automation that's all you need to think about it is it gives you some new capabilities in the automation name of the game but it's still just fundamentally a kind of automation it's that simple okay so when we talk about this automation engine or this reasoning engine like what things can it automate so first think about how openai just came out with function calling and API use so basically that means that the that your llm your generative AI model is universal middleware it can talk to anything in your organization anything in your Tech stack as long as it's got an API so because of that it can touch everything it's capable of problem solving there are many times where you just plug in like an error code or you know describe something that you're that you're getting and it can understand it it's not always right but it can also understand when it's getting it wrong and kind of stop and you know you can use tree of thought or Chain of Thought or whatever there's all kinds of problem solving uh techniques out there tree of thought by the way increases problem solving capabilities by like 900 or something uh so if it can solve problems that means it can overcome problems automatically decision making so here's the thing is with with a given objective or a mission it can make decisions in pursuit of that mission and this is why I say Mission uh oriented uh programming and so then of course planning and brainstorming which is also required for to pursue a any given Mission so if you have an automation engine that is capable of these things now what can you do with this now that it's in your toolbox so one of the first things that you need to think about and to kind of change your mind is on-demand tools or tools that make tools a tool Factory because that's what that I mean that's what GPT does with code it generates new code and what is code but it's a software tool and so you know you think about it like the replicator from Star Trek computer I need something that does X Y and Z and you know a few seconds later it pops out so if you think about the first step towards building polymorphic applications uh the first step towards Mission oriented programming is the ability to synthesize any code object that you need on the Fly and so if it can write code it can test code it can call apis it can read the manual I can write user stories it can read epics it can do all of that stuff you combine all that together and you create an automated tool Factory or a replicator this is the first step in creating polymorphic applications because you can you can stack the blocks together but you need something to make to print the blocks for you right it's like a 3D printer or a replicator but for code and so then once all the blocks are you know you've got a block Factory a tool Factory now you can just plug them all together you may you aim for Plug and Play architecture plugable architecture and from there you know because it's got access to literally every API in your organization it can talk to Azure AWS Google Cloud VMware Microsoft whatever it can talk to everything in your organization as long as it's got an API then you build those building blocks and then you stack them together and what can you do with Legos you can do anything with Legos as long as you've got enough blocks so I think you're kind of getting the picture is that if you think about it in terms of modularity or individual pieces that can be kind of printed or fabricated on demand and then you plug them together that is the underpinning mentality of polymorphic applications it's polymorphic because it can change shapes because all the all the pieces all the underlying pieces are just plug and play okay so we talked about Mission earlier but who runs the show you've got a whole bunch of blocks a whole bunch of building blocks but how do you how does the machine know what to plug into what and and that sort of thing you need a brain right you've got the tool Factory okay great uh and at first it's going to be humans asking for tools you know replicator you know you know tea Earl Gray hot right but what you need to do is ultimately automate as much of that as possible so the tool Factory is automated but then you need to automate the thing that's asking for the tools and the tool and the and the building blocks this is called a cognitive architecture so remember going back to Sachin nadella's point that we have a reasoning engine or a cognitive engine or an automation engine whatever you want to call it it's all the same thing cognition reasoning automation all the same thing now let's dive into cognitive architecture so many of you that have been following my channel for a long time know that I am like the cognitive architecture guy I wrote natural language cognitive architecture more than two years ago now this is my shtix This Is My Jam now what was missing from my books in the past was a more coherent framework I had some diagrams I had some architectural recommendations and a lot of people get a lot out of it but this is like the OSI model but for next-gen applications for polymorphic application so I call it the ace model autonomous cognitive entities so again right there in the name autonomous the idea is to create something that has a higher degree of autonomy but it also uses cognition it uses reasoning and then it's an entity in that it is somewhat self-contained now some people are going to be deploying a generative AI in a more distributed sense and that's not what this video is about this video is about basically the architecture to create commander data or you know bd1 or whatever right if you want to create C-3PO or R2D2 this is the architecture uh the the Paradigm the framework the conceptual framework that you need to implement so without further Ado it is six layers that might change but um I've been working on this for a while so I'm pretty sure I've got it nailed down so the first layer is the aspirational layer this is the layer that is concerned with the mission the values the purpose the ethics and the morals of whatever it is that you're building and like I said we'll get in we'll I'll give you some examples of missions in just a minute so that it'll make more sense the layer 2 is the global strategy layer this is long-term thinking context context is the primary thing for Layer Two and it's basically like a CEO it says okay here's you know I have I have my vision I have my morals right my my higher order beliefs now what is the biggest time Horizon way to think about that mission layer 3 is Agent model so this is the self model and it's primarily concerned with capabilities the machine has to know what it is how it works and what it's capable of in order to make decisions because if you tell a machine hey go solve world hunger it's like okay cool well I'm gonna go plant a bunch of fields it's like well actually you've only got a budget of fifty dollars right and and you've got one hand then and it's tied behind your back right so by understanding what the model is capable of or your engine or your architecture it has to know what it is capable of and what it's not capable of it also has to be capable of changing itself so this is where the the polymorphic thing comes in if it understands that it has a limitation such as like well I don't have access to that API I need to get access to that API um how do I get access to that do I send a ticket to the help desk and they'll give me permission or is it something that I can solve on my own that sort of thing so you need a very comprehensive agent model in order for the machine to be able to change itself um in in alignment with pursuing its Mission and so you're probably got some alarm Bells pinging because you're like Dave you're basically designing Skynet which is exactly why the aspirational layer is at the very top those those constraints those boundaries the missions the values the purpose this is around this is what it what you know sets the tone The Guiding North Star of the device so that it never fully goes off the rails but you need something that is constantly watching you know it's it's the ideal self and we'll dive into each of these layers in just a minute but I wanted to give you the whole framework at a high level overview So Below the agent model is the executive function so this is primarily concerned with planning or making plans so that means like forecasting like okay what's going to go wrong how do I think through this directives oh and you know the The Prompt engineering is already there let's think through this step by step right take that out to the nth degree that's the executive function layer this is also concerned with resources so if you make a plan you have to know what resources are available to you and these are external resources right the agent model in terms of capabilities that is internal resources this is what I am capable of in the world but then executive function for planning is about external resources how much compute do I need what kind of developers need to help me um what kind of access do I need what kind of data do I need from the outside world and so then once you get a plan together you get the blueprint you get the the burn down chart or however you want to organize it your kanban board your jira board right because that's basically what you're interacting with here at the executive function layer below that is cognitive control cognitive control is saying okay here's the big plan now what so this is about a task selection and task switching so that means choosing the correct order of operations and then but more importantly choosing when to switch tasks because if something isn't working or you or you started a task and then it's not the right order of operations or you realize that you've come into a barrier you need to back out of that task and choose a different one and so that is driven by frustration signals and cognitive damping which we'll get into in just a moment and then finally layer six is Task prosecution which is doing one task at a time but more importantly detecting when that task is is truly successful or has failed and then reporting that information back up to the cognitive control layer which will then adjust the frustration and damping signals okay so let's get into these layers a little bit deeper number one the aspirational layer it's all about Mission I'll just read the description to you this is the uppermost layer which is somewhat abstracted and detached this is the ideal cell for superego version of the agent which keeps track of the highest values virtues principles vision and mission of the agent in other words this sets the tone for all other layers below it in other words sorry I meant that I didn't use that twice this serves as the moral compass and The Guiding North Star for the autonomous cognitive entity for the ace it provides the raise and Detra and I'm no I didn't say that right but the reason for being it is this layer also serves as the ultimate orbital Arbiter for all moral dilemmas that that thing faces and so what I mean by that is here's some examples of submissions that you might give so for lawyers um this is this is set by uh the ethical standards and and uh regulations and whatever uh but the the mission of a lawyer is to zealously advocate for their client that is the highest mission of a lawyer for doctors achieve the best possible Health outcome for their patient so these are these are examples of aspirational missions that um that that Central Mission informs every decision that they make including all moral decisions all ethical decisions uh it it also speaks to how they allocate their time energy and resources and so by having a centrally organizing mission that mission-oriented programming you embed that at the highest level or the the the heart the core of your autonomous cognitive entity and it will pursue that mission uh and then any decisions that it makes will be uh with respect to and in pursuit of in honor of that mission and that's why defining missions is really super critical just below that is global strategy which is all about context so Global context World State and long-term strategic thinking this has the greatest time Horizon um and the greatest physical uh scope as well so for instance if you've got a lawyer robot or a a doctor robot it needs to not just be thinking about the hospital that it works in or the law firm that it works in it needs to be thinking about the entire context of okay what's going on with uh you know medical research in the entire world what is the status quo what is the news what is happening in the marketplace what is happening in our competitors that sort of thing and so you think about this as the CEO of your autonomous cognitive entity it it maintains a very high level perspective um and it kind of has keeps it at arm's length so again it's not going to get lost in the weeds just like any CEO should not be lost in the weeds they need to be looking up and out not down and in so this layer of your autonomous cognitive entity is it is anchored to the real world because remember the aspirational layer is this is more abstract and conceptual this is not really anchored to the real world this is anchored to principles values mission that sort of stuff this is the first layer the global strategy layer is the first one that is anchored to the real world but it has a Global Perspective and it also has a long-term perspective it's not thinking about today and tomorrow it's thinking about a decade from now it's thinking about a century from now it's also looking at the entire planet Earth and then if you know we expand beyond Earth it'll be thinking about the entire sphere of human existence the entire universe the entire Cosmos so you maintain that big perspective in order to um you know start the start the process of zooming in and you'll notice that that each subsequent layer Zooms in further and further and further so we start super high level super detached and then we zoom in uh progressively with each layer so this has to do with World State as well all right I think you get the idea so let's move on agent model agent model is all about capabilities this is the ego of the of the machine it this is what it knows and believes about itself now I know that this sounds a very anthropomorphic but again you know we're talking about cognitive entities here we're talking about reasoning engines this is the layer that confers functional sentience this is the first layer where your uh your software architecture knows that it is a software architecture and it knows how it's configured it knows what it's capable of it understands its operational conditions how many servers are running it uh if it's on one piece of Hardware it needs to know the voltage and temperature and all that other kind of stuff so this is self-referential information what is it like basically the question is what am I capable of how am I built what can I do what can't I do what am I allowed to change about myself what can I change about myself what functions are autonomics so for instance if you have a bunch of models that are just learning on online all the time it needs to understand that and so that it could steer those models learning you probably will use frozen models at first because you don't want the thing you know having a complex set of interactions and learning stuff that you weren't aware of but in the long run these things will be uh basically curating their own internal architecture their own internal library of models that sort of stuff but this is fundamentally about capabilities what am I capable of what do I need to be capable of what am I not capable of and this uh this level of zooming in is saying okay given my my mission my purpose and given the global context of what's going on in the world what am I capable of how can what like what is within the realm of possibility for me to pursue that mission and so by couching all this within that agent model it's like okay well you know my my goal like the goal that I was given is you know conquer the world but I'm running on you know an Intel Pentium three so my resources are limited so maybe I need to get more more resources and I'll have to beg beg borrow or steal them or whatever obviously don't give your agent uh the the goal of Conquering the world we already tried that with chaos GPT don't do it again let's let's stick with something a little bit more constructive the next layer is executive function so this is a this is primarily about planning uh you know whether so once you have once you have the mission you've got the vision and you've got the global context and then you know what you're capable of with all of that in in mind you're then able to say okay well you know I've got access to you know so so and so internal resources this is what's going on in the world okay cool now let's come up with a with a plan to actually make it happen and so you can think about this as a little miniature internal project manager or or a director right so it's you know CEO and then you got like director or PM or program owner or whatever right but it's fundamentally about like okay let's think through this whole thing end to end let's come up with a plan to do this and remember large language models are great at it if you don't believe me go to chat gbt right now and tell it a problem give it give it everything that I just in the upper layers and say come up with a plan and you'll see that it can do it okay so once you uh what goes into the plan though so you you have to think into the future right okay so you forecast like what are the choke points what are the points of failure um what's going to be happening uh what resources do I need and so this is really critical remember I was talking about external resources what kind of help am I going to need how many parts materials money energy whatever data so this is where this is the layer where it's like okay let's let's scrape together a specific project plan for this exact project whatever it whatever it's going to come up with in order to pursue that given mission below that is cognitive control so cognitive control is fundamentally about focus it says okay we've got the plan we've got the mission I know what I'm capable of now what do I do what is the correct order of operations here so this is Task selection and task switching and so if you've got really bad ADHD then your brain will switch tasks on you uh without you without your consent um and so that is that is an executive dysfunction that happens in humans and as people have noticed executive dysfunction is really common in these language models because they'll just they'll they'll uh they'll contact switch without you telling it because they're they don't they don't have it so this layer is about giving it that that cognitive control so that it doesn't context switch or task switch unless and until it's ready or it's supposed to so this layer is uh most going to be most familiar to people who are familiar with a term called finite State machines so basically a finite State machine says you're doing one of any number of tasks you're and and so this is really common in robotics and NPCs and video games you for an MPC you might be fighting you might be running you might be hiding you might be searching so there's a finite number of states that you can be in or there's a finite number of tasks you can pick from from the plant the project plan above so what whatever state the machine is in you have to switch between those States and say okay right now I'm writing code then I'm going to switch to testing code then I'm going to switch to um doing integration testing then I'm going to switch to deployment right so this is that is what cognitive control is about it is about task switching task selection and then it's driven in part by so from above it's driven by the project plan from below it's driven by frustration and damping so frustration is very simple frustration is simply just keeping track of the rate of failures versus the rate of successes if the rate of failures is too high then you've got the wrong plan and that means you need to go up a layer and the and the executive function layer says well this plan isn't working let's make a new plan right so that's where frustration comes in because if if if everything you're trying and 75 of it is failing you're probably got the wrong plan so you need to go up and and kind of re-strategize and reallocate resources and fee that information back in I cover all this in my book um uh Symphony of thought by the way where I I give plenty of examples of how to achieve each of these steps with prompt engineering uh damping is so cognitive damping is basically okay let's pump the brakes let's try and prove ourselves wrong right like okay let's let's think through this let's do um like what could go wrong here uh let's let's think about uh failure points let's think about is this is this a step that we're gonna regret if it goes wrong do we have a back out strategy so cognitive damping is about slowing down and thinking through things a little bit more deliberately so that you don't make any grievous mistakes in the context of uh medical uh medical robot it's like okay if I make this incision there's no turning back right and so cognitive damping says let's stop let's check like let's dot all of our eyes and cross all of our T's to make sure that we're going to do this right and make sure that we're ready to do this so that's what cognitive damping is and again this is all pretty easy to put into um prompt engineering uh so those two things uh frustration and damping are two of the big biggest tacket tactics for maintaining focus on what you're doing and why at any given moment and then the very bottom layer is Task prosecution so this is tasks this is the low level Hands-On product task so this could be the robotic command of go from A to B it could be you know right X number of code or send an API call to to you know there and this is something that happens all of these things happen in your brain and it's completely transparent right so imagine you go to this happens to me all the time um I get home and I forget that I lock the door so the task is open the door so I go and reach for the door and it doesn't turn oh right I locked it so that's exactly what I mean by low level tasks success or failure and so then it's like okay my brain gets the signal door didn't open right let's back up a level so my cognitive control switches from open the door to get the keys out of my pocket and then try again so by by focusing on this layer of of success or failure of one task at a time then you have that information available and you pass it back up the stack um in in the case of a robotic right example it's like okay get from the living room to the kitchen and then it gets stuck because it's like oh well there's a dog you know laying my dog does this all the time lays right in the middle of the path I can't so now now I've got a new problem right and so it's like okay well getting from the living room to the kitchen failed because there's a dog in the way so you pass that back up to cognitive control it says oh let's let's switch switch states to now I need to ask the dog to get out of the way or ask the human to get the dog out of the way right okay so I've heard a lot of people say like yeah this is never happening this is many years away and that's just not true there are all kinds of people already building different components but what I'm here to do is say look put it all together so Lang chain provides the last two cognitive control and task prosecution uh Lang chain is fundamentally about workflows one of the biggest limitations about Lang chain is that it's linear it's not cyclical um that being said it's not that difficult to couch it in in the middle of an infinite Loop um but then you also need to make sure that you understand these paradigms of you know pass versus fail and also when to go up another layer in order to change directions the ethos project which was built by teams uh a team that came together in my gato community they got I think they got second place in their hackathon ethos is an example of that mission first it is the higher order micro service that that provides that alignment uh justification and it's also a microservice so it's modular some other examples baby AGI and Chaos GPT were somewhat naive attempts at the upper layers of of um of the of the stack they didn't people were trying to like integrate everything all at once and didn't really have a clear Mission and didn't have clear cognitive control or planning or executive function anyways all this is available in my three primary books natural language cognitive architecture Symphony of thought and benevolent by Design one thing to keep in mind like I said is that this framework is newer um so it you'll see bits and pieces of it the progenitor thought in those books you can also look at this framework that I just came up with it's under my GitHub Dave shop benevolent underscore AGI and uh yeah so there you have it this is the next generation of software development so basically whenever someone comes to me with a pitch they're like I'm doing a startup unless they have this level of sophistication I'm I'm just gonna say like yeah like you're off to a good start but you need to be thinking in terms of cognitive architecture you need to be thinking in terms of layers of abstraction and polymorphic applications anything less than that is just low hanging fruit at this point and as we've seen numerous times over the last six months the very next iteration of chat GPT or a competitor is pretty much going to destroy any business model uh Claude with its 100 000 tokens destroyed a whole bunch of business models Chad gbt with the plugins and the code interpreter destroyed a whole bunch of business models so unless you're thinking at this level of sophistication your business probably won't work and it's not just me saying it Marissa mayor of um what was it yahoo she said that generative AI is going to tear through the tech industry like a wildfire and that this Wildfire is going to burn all the brush out and the brush in this case is startups and smaller companies and that's gonna that's gonna be a clean sweep and we're going to have a lot of new fresh growth after this that new fresh growth that she's talking about is cognitive architecture and polymorphic applications so thank you for watching like I said I am available to consult on any of this stuff reach out to me on LinkedIn Link in the description cheers have a good one
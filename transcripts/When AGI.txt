morning everybody David Shapiro here with a video the topic of this video is quite simply when AGI uh simple question but the underlying answer is a little bit less straightforward and that is uh we're going to talk about exponential growth well before we get started we have to talk about what even is Agi uh the answer is quite simple no one agrees uh when you say AGI it is uh latent with uh assumptions and implications and uh there are people that think AGI is has to be a super intelligent Skynet that can control everything there are people that think AGI has to be embodied that has to be in a robotic form like you and me um so there's no one definition there's plenty of assumptions um one definition that gets thrown around is that it an AGI is a machine that is capable of ending intellectual activity of any human but that's not general intelligence that's super intelligence because if you have a machine that the one machine that can do anything that eight billion different people can do excuse me that's uh super intelligence sorry um uh another question is it autonomous or is it reactive only this is another thing that people like if if a machine just sits there and waits for a human to use it can that even be qualified as AGI because isn't part of general intelligence the ability to create it and follow its own goals um so to me autonomy is part of it but people aren't even talk are not even talking about autonomous machines another thing that a lot of people assume is spontaneous learning um and so for humans learning is completely automatic yes you can engage in behaviors which increase learning like you can go choose to go to school or you can choose to read a book but you don't even need to do that because learning is part of our Hardware it is part of our intrinsic underlying hardware and so the uh many people think that AGI has to have spontaneous learning I don't know that I agree with that um but again there's no agreement on any of this stuff and then other people say well it's not AGI until it's conscious what even is consciousness Consciousness is an intrinsically subjective experience so how do you measure a subjective experience for something else you can't from a neuroscience perspective Consciousness is basically whether or not you're awake um or or there's a few other criteria um but it again it mostly subjective so it's very difficult to measure um then the tongue-in-cheek joke is Agi is whatever machines can't do yet which there will always be something that humans do differently or better or whatever from machines um and if there is a future where there is literally nothing that a human can do that a machine can't also do better well then we're in for a different different type of existence uh personally because of all this AGI is a useless term um I prefer ACOG so fans of my channel for a while will know that some of my if you go back in in my videos um what I focus on is artificial cognition how do we approximate cognition which is general purpose thought and then it's just a matter of measuring how intelligent it is and of course even intelligence is not a single metric there are many many kinds of intelligence um that are very difficult to measure because uh again it comes down to definitions so with all that said who cares like AGI is an arbitrary uh goal post that really isn't helpful and doesn't really mean anything but the world is moving fast so let's move on from the idea of AGI uh but let's let's stick with that idea of human level of intelligence when will we have machines that are human level of intelligence um let's look at some thermodynamics first so the human body uses roughly 100 watts of juice and the brain uses roughly 20 of our total oxygen consumption therefore you can estimate that the brain uses about 20 watts of energy that's not much right that's uh that's less than or actually that's more it's a little bit more than the light that's behind my camera um but it's roughly what a 50th of of uh the computer that I'm recording this on right so our brains are really efficient um so that's that's the energetic part but then how uh how many flops how many floating Point operations per second does the human brain do or how much would it take to approximate the human brain obviously our brains are massively parallel um each neuron is actually pretty slow they operated around a thousand kilohertz or one kilohertz right our neurons operate at about one kilohertz sorry one thousand Hertz um whereas uh CPUs and computers operate in the gigahertz range but they're much smaller um so by having a diffuse parallel Network our brains technically operate much faster but we'll get into that more more details about why this is a bad analogy but one thing I wanted to point out is that um estimates about the the flops of the human brain goes up every time we invent new computers if you go back there's like I think there's an article in wired when deep blue came out and it's like everyone's like deep blue is is as powerful as a human brain and it was like in the in the uh petaflops or gigaflops uh range and then you know the first the you know the gigaflops computers came out and then the and then the petaflops and tariffs or teraflops and exit flops and every time we come up with a new computer we're like this is as powerful as a human brain same trend for 25 years so either our brains have become exponentially more powerful over the last 25 years or we don't have the first freaking clue about how powerful our brains actually are so presently we think our brains are exascale computers but it could be beyond that we could have Yoda scale computers in our head which would be cool because they're only three pounds and and use uh 20 watts of power um nature do be crazy like that uh so by comparison an RTX 3090 weighs about four and a half pounds so our brains weigh less than a graphics card and yet um are more powerful than the most powerful super computers we have today so it's safe to assume that there are just from a pure entropic like physics uh level of looking at it that there are things that our brains can do that other machines cannot do yet just by sheer virtue of efficiency now that being said brains are not computers with some Nuance a lot of nuance so let's look at the the obvious differences first different architecture we don't have a CPU and memory register that are separate it's actually the same one of the ways that your brain maintains its its memory register is through a seven Hertz pulses through the brain and so it's actually kind of a memory state that is maintained along with the synaptic connections so one of the things that is um there's there's quite a few things about the way that our brains hold memories and store memories and retrieve memories that are different and when you when you uh look closer at neurons you realize that memory and processing are the same so the closest thing that we have in electronics is mem resistors which are not being used yet not widely so fundamentally different architecture two fundamentally different substrate computers all run on Silicon right now and we run on uh organic squishy mostly cholesterol and fat based materials as our substrate it's pretty gross um you know our brains are very very squishy uh let's see I've never touched a human brain I did touch a pig brain when we were uh in middle school when we did dissections um actually I couldn't touch it I was super grossed out um there's different signaling so CPUs use electrons our brains use neurotransmitters and no they don't even remotely do the same thing neurotransmitters bind to specific sites um and and there's ion channels and this that and the other whereas electrons pass through Gates through metal oxide Gates and so you might say okay well functionally you know a neurotransmitter is kind of like a gate because it activates a thing and then a signal goes through e-ish you know okay if you really want to break it down and and like squint at it sure um but then also they use a fundamentally different kind of energy um electromotive Force current versus uh electrochemical uh energy so when you take it all together the brain if it is a computer is a fundamentally different kind of computer now let's take a step back and just look at it from a raw physics perspective from a first principle's perspective brains and computers both process information this is true so you know you say okay well if it if it's a if it's a self-contained object that processes information that's a computer um but if that's your definition of computer then your entire body is a computer because you process information whether it's physical information or auditory information or all the processes going on inside of your body then your body is also a computer um but your your body can't do all the intellectual tasks on its own that we want computers to do so does it count is it like oh well that's not what I meant by computer um so the the definition of it processes information is not necessarily a useful definition of computer because if the definition of computer is any object or anything that processes information then everything in the universe like like Mike this this process is information this process is information on the quantum level it's processing the the mechanical wave of my voice as it passes through it it's processing the heat from my T that's traversing it um but again that's not useful to us in in terms of intelligence um and uh the entire universe is technically a computer from the perspective of physics so again like depending on your scale not really helpful so for the sake of this argument we're just going to say human brains are not actually computers um even though technically yes they process information but it's not the same they just the the way that they process information is fundamentally different okay so where are we AGI is undefinable but robots are real um so we could keep arguing over what AGI means and what the goals are but it's this imaginary goal post that keeps moving so let's look at what is real so what are some things that are actually happening Private Industry is going as fast as possible every single chip manufacturer and tech company out there is investing in AI as well as every military and every government they do not care what AGI is um there's a lot of money to be made right and where there's where there's money to be made you know the capitalists and the corporatists and the neoliberals are going to go in full force right why do you think that that crypto went really big is because there was money to be made and but it was the wild west and so there's no regulation and so then you had the FTX collapse um so where there's a will there's a way and there's a heck of a lot of willpower in AI right now um the only entity is even capable of slowing this down are governments and militaries but they want it too so like this is going as fast as humanly possible and I picked the Zoidberg meme because I can already hear some people in the comments saying blah blah you're wrong about all this um and you know you're allowed to have that opinion and you're also allowed to be wrong um the fact of the matter is AI is dangerous and disruptive long before we achieve anything remotely called AGI it doesn't matter it's a useless term um AI can make our lives better now it can also make our lives worse now look at how AI is being deployed for um the social credit system and and face tracking and and um even even dumber things basic machine learning uh regression models predicting um you know crime uh and and overly targeting um poor communities uh the real problem is not the machine the real problem is how we implement the machine whether we implement it with benevolent intent and benevolent uh uh actual uh deployment because there's always the law of unintended consequences or malevolent deployment do we put this stuff in uh weapons of war and and tools of control and manipulation um by the way this is why um companies like meta or Facebook have suddenly lost so much Faith with the entire market share is because everyone's like actually yeah like we don't like our attention and our emotions being gamified just for the sake of corporate profits uh that is at least that's why I deleted my accounts um so but you know who knows um so and the point is the problem exists today right now irrespective of AGI all right now I know you're probably like glazing over because I promised when are we going to have AGI I just needed to set the stage so let's move on so let's ignore the semantics and just let's look at the data let's look at the actual Trends to figure out what's happening and when um so the first question is since we're looking at data I want you to keep in mind that there are excuse me that there are two overarching kinds of graphs here now everyone has assumed that exponential growth um is is the way because of things like Moore's law but I want to call your attention to the possibility that until you get to the halfway point of a sigmoid curve it looks exponential and so over the last few years we've heard like oh more law is wearing out and no one can agree on whether or not that's true so if Moore's Law is in fact wearing out then maybe it was never an exponential growth curve maybe it was always a sigmoid growth curve and so maybe we're actually here where it's starting to slow down which if that's the case then maybe things aren't happening as quickly as we thought and maybe uh Ray Kurzweil was wrong and that the singularity is not near but maybe it's actually like a couple centuries away if we have diminishing returns then maybe it is much further away than we thought or if we have compounding returns it could be way closer than we think so let's explore the data and see which way it goes so first I apologize for the blurriness of this I couldn't find a larger higher quality version so this is the Energy Efficiency the the gigaflops per watt of AI technology and so you look here notice first the scale is logarithmic this this level is uh 10 gigaflops per watt then 100 then a thousand so each each major rank goes up by a factor of 10. so this is this is logarithmic growth this is the same thing this is the same way that decibels are measured and it's the same way uh same as the Richter scale for earthquakes so like you know a three on the Richter scale is 10 times weaker than a four and a five is ten times stronger than a four uh same thing for for decibels so in this case you see like okay in 2011 just 11 years ago we were at seven gigawatts per flops or uh uh yeah uh seven seven uh G flops per watt and then last year well I guess it's 2023 now so two years ago um we were uh hovering about about 70. so it went up by a factor of 10 but then we also started doing a lower uh floating point and we had new new technologies we had the tensor cores come out and so then we had this Quantum Leap so in the space of 10 years we went from less than 10 gigaflops per watt to over a thousand so in 10 years we went up by a factor of a thousand so what if 10 years from now are um our AI chips are a thousand times more efficient than they are today that's insane to think about because then then it's not a matter of like oh can you run gpt3 like on a big giant computer in the cloud you could run gpt3 on like an RTX 80 90 right like when Nvidia comes you know just that like that's just a couple Generations like if if Nvidia comes out with a new generation every year and a half so that's what that's uh um that would be six six ish Generations so we're on the 40 90 right now right so then you go to like the the 10 the 190 or the 90 90 or whatever right so then like it's conceivable that you could run these language models on uh on a on a on a home GPU within a few years within a decade um that's pretty crazy it's actually probably much less than that because I think that uh I think I did the math and it would take about I think it would take about um 90 uh mid-range gpus today so you know if we're if we're going up by a factor of 10 or a thousand in uh if we're going up by a factor of a thousand in 10 years um it'll be a lot less before we go up by a factor of 90. um it'll be about half that so you know the the Energy Efficiency is going up we're still a long ways off from the Energy Efficiency of our brain remember we might have we currently we think we have exascale computers in our head that run on 20 watts of power and weigh three pounds um so we're a long ways off from that but remember the problem is today if it's already dangerous at these levels of efficiency how much more dangerous could it be at those at a thousand times more efficient okay so remember we talked about the possibility of diminishing returns um if we so so far on the hardware side we don't have diminishing returns we actually have accelerating returns as new technologies come out so this is this is a point in the column for exponential growth and maybe even um hyperbolic growth or parabolic growth parabolic growth is the one that goes to infinite um if we have parabolic growth I didn't even have a a a graph for that parabolic growth is even scarier and if I'm saying that wrong please let me know I'm sure someone will in the comments it's either hyperbolic or parabolic one of those goes to infinite the asymptote is like out there and it's like oh at 10 years you actually have infinite growth um so anyways so there's there's one point in the in the possibility that things are actually accelerating and the exponential growth might even be accelerating um so let's see if let's let's take a look at diminishing returns um for the last couple years the uh the the Mantra has been scale is all you need um a buddy of mine at open AI he messaged me this is a couple years ago I haven't heard from him in in like a year or two because because open AI has been very busy um but one of the one of the last messages he told me is like yeah as far as we can tell like all you need to do is just throw more data at it and more parameters and it just becomes more intelligent so we're going to see how far that takes us um and boy howdy has that worked so far um but here's the thing rumor has it that gpt4 has been trained on most of the internet like most of the data on the entire internet um which is just mind-blowing so if we run out of data to train it on what else is there like like okay that maybe uh someone one person had a hypothesis that that's why open AI trained whisper was so that they could get more data out of videos um and and podcasts uh because there's something like what was it like 90 years worth of videos on YouTube that seems low I think it's more than that but the point is is there are many many years worth of content just on YouTube Alone um that could be transcribed with a tool like whisper excuse me I don't know why I get so congested in the mornings um so that's one possibility then you transcribe all the podcasts right and then you go multimodal if you can describe what's happening on the videos and you you describe it with uh with language you can get even more data right but point is they're going to run out of data so there might be diminishing returns there's also some evidence that the larger the model you actually don't necessarily get the the returns for fully uh dense models that once you get larger that you probably have to go sparse um and so like once you get to the trillion parameter it's almost certain that uh you need to have a sparse model so my personal hypothesis is that gpt4 it might be a thousand times bigger than gpt3 but it's probably a sparse model which means not all of it is going to activate at any given moment so maybe gpd4 could be just as efficient to run as gpd3 even though it could be hypothetically much much larger but this is all speculation we should know by the end of 2023 hopefully within the next few months when gpt4 comes out and we can add another another Branch to this but also take a look at this this also scales logarithmically right so uh one billion 10 billion 100 billion uh a trillion so if this trend continues then that's evidence for exponential but you look at this where where Megatron Turing kind of tapered off right so is that which way is the curve going is it gonna is it going to Plateau or is gpt4 going to be up here in like you know a couple ranks up and just show that actually no it's continuing to accelerate so this is like if they're running out of data I don't know what they're going to do about that um so uh yeah so this one's kind of a wash um we'll know more once gpt4 comes out or or any other competitors right I know Google is working on their own competitors um and you know Megatron this is um this is NVIDIA so we'll see um maybe meta will come out with something but I think the biggest players to look look at are going to be open AI Nvidia um and and actually those are the two biggest ones in Google probably so keep an eye on those three um so far it looks like exponential hasn't given out and it has been a durable trend for like a century so this um this was posted on Reddit and I think I believe it came from Source Time Magazine um so this was I think this was an article talking about um Ray kurzweil's uh prediction for the singularity so you look all the way back where we had electromechanical computers and then relay based computers and vacuum tubes and transistors and then integrated circuits and then who knows what comes out now but the prediction is that is that these computers that computers will surpass human brain power this year um we'll see you know but that's the other thing with with exponential growth is that very small changes in that growth trajectory could mean that it happens five years from now or it means that it might have already happened who knows so so far it seems like there's a lot of evidence that exponential uh is still uh the name of the game um and that it hasn't given out yet so um if if we are still growing exponentially and we're going up by a factor of like 10 every five years um that and and sometimes it feels like even less than that then it's really difficult to predict what will be possible even just two years from now I mean and honestly a year ago today who would have predicted GPT that chat GPT would have had the impact that it did so we'll see what happens now uh it's really difficult to wrap your head around exponential growth and we'll get into a little bit more why but the the biggest thing that people um have have witnessed or experienced in their lifetime is the exponential growth of human population now human population actually follows a sigmoid growth curve because we're approaching the carrying capacity of the planet which means the competition for resources is making life harder um so like I don't care about government policies the number one reason that housing prices are going up and food prices are going up it's not inflation it's it has to do with the thermodynamic limits of the entire planet um as we approach the carrying capacity of the planet just by virtue of everything is more constrained prices will go up life gets harder stress goes up etc etc um so overpopulation is actually uh to me a larger problem geopolitically than climate change because climate change just makes that worse the competition worse but humans have survived climate change before we've been through ice ages right um that's not the problem the problem is the additional stress that climate change puts on us at the same time that we're also approaching the carrying capacity of the planet that's when people get real mad anyways so I was born in 1986 so the world population was around 5 billion when I was born um and today it is we already passed 8 billion so this is actually out of date um we're we're already above 8 billion so in my lifetime three billion humans additional humans this is net gain of 3 billion has happened and the way that that looks is that like the city that I'm in constantly grows like where are all these people coming from I know that they're coming from somewhere and some places have populations that are declining but subjectively that's what it feels like and this is why it's difficult to wrap your head around it because the Earth is really big there's people all over the place um so why is it so hard for us to think exponentially why is it why is it that like you look at this and like we just can't even wrap our head around three billion people like that just that's just a number right what does three billion people even look like you can't you can't see it all in one place it's just too much so the reason is we evolved to think locally and geometrically because our our chimpanzee ancestors they pick up stick they hit thing that is bad or or food and then they eat it right and so they their their life is based on what they can see in their immediate uh vicinity and maybe things that they remember like oh the river is is just a little further away right um but then like hitting things throwing things running away hiding climbing up a tree these are all geometric problems right um it's something that you can interact with it's something that's tangible but where we live now is a global and exponential world like it's if if there's a million people working on AI and and they're all getting compounding returns and another million people working on better chips and they're getting compounding returns and another million people working on software and they're getting compounding returns we cannot wrap our heads around that we have no evolutionary um history that that has even primed us to think like this and even people who practice thinking like this it's still it's never intuitive um and so like a couple of of dumb examples I picked for things that like why it's not intuitive is because you never go from 30 miles an hour to 3000 miles an hour right in a car like the only people who can do that are like fighter pilots and the people who pilot the space shuttle well the space shuttle's been retired um but anyway now they're just riding in a capsule they're not even steering they can't even see where they're going it's just you Buckle in and you have g-forces right um and so and then also your microwave it doesn't go from like you know room temperature to 200 Fahrenheit to 2000 Fahrenheit right so unless you're like a metal worker that you know where you've got a blast furnace that goes to 5000 Centigrade or whatever um like you cannot think um you you have never even experienced something that is truly exponential um and so the fact that most of us never experience anything exponential means that it it with that without that experience we cannot intuitively think exponentially um so what then people fall back on is their gut response right when you think about AI it's like oh well humans are special so this is another thing humans love to romanticize human intelligence like we're we're just intrinsically special um but if you go back to that model where like okay what's special about the brain it's three three pounds of cholesterol and and neurotransmitters um what's actually special about that there's nothing there's there's no there's no uh Secret Sauce there's no magic substance that you know makes our brain unique it's not made of any uh original elements um there's no structures in the brain that um are impossible to either simulate or approximate so it's just so there there's the emotional the visceral reaction saying nothing will ever be like us because that's very comforting thought there's the there's the uh emotional rejection of oh it's nothing to worry about because the the actual possibility is it is so terrifying that you don't even want to engage with it right and so the combination of the emotional response and our inability to think exponentially combines to say like you know yeah like the The Singularity is much closer or whatever however you want to call it so if it is all exponential then we have already crossed the Rubicon and for those who are not history nerds the Rubicon is a tiny little river in uh in in now Italy where uh Julius Caesar took his army across because you're you were technically not allowed to take your army past that and uh so that was basically him like saying the dye is cast I am fully committed we are now fully committed the genie is out of the bottle and I remember a couple years ago I couldn't find this quote but I remember seeing Elon Musk in a uh interview he said things get really interesting by 2024 or 2025. and I think he was probably late I think things get really interesting this year I think that 2023 is the year that things get really interesting um so the short answer is are we going to have AGI this year I don't think so but I don't care things are already interesting and they're only going to get more interesting so you're probably just raging like just tell me when you know and I'm going to say that it's not a matter of when it's it's not even a matter of if it is happening now and the choice we have to make is utopian World on the left or dystopian World on the right and you know like we we everyone I don't mean like you me every you know every Joe or whatever I mean billionaires I mean politicians I mean military leaders everyone has a role to play in making this choice so how do we make this choice well first vote vote for politicians that uh are are not insane and and are not uh lunatics um think for yourself um but more than thinking learn uh go read go experiment go Tinker on your own talk to people um the best the social trust social proof and and social consensus is one of the best ways to participate I experiment that's why I have my YouTube channel is so that I can demonstrate these things proposed Solutions I've written a few books on this I have written books on the control problem benevolent by Design I wrote a solution for this because believe it or not the problem between utopian society and dystopian Society has nothing to do with technology and it has everything to do with our philosophical disposition towards each other but more importantly towards ourselves so I wrote a book called post nihilism because this on the left is post nihilism this on the right is nihilism and so we have to choose post nihilism if we want that you don't have to do anything but in my book post nihilism I outline that it that choosing a philosophy is an arbitrary choice so we could just arbitrarily choose the left one um so that's one of the solutions I proposed um either way buckle up it's happening it's happening faster and there's nothing we can do to stop it um don't stick your head in the sand don't pretend like it's not happening and uh the time to act is now and I added a little graphic of the of a bad alignment take Bingo which is pretty it's pretty cynical and pretty funny because it's like it's actually a really serious conversation but like AGI is too far away to worry about right now nobody who's actually working on this stuff believes that the only people who say AGI oh it's never going to happen it's decades away the people who actually work on large language models and and and and basic research like basic science and algorithmic improvements none of them think that they say oh hey we already have you know human level performance or superhuman level performance on a broad array of tasks and that number is going up by a factor of a hundred every year so what happens next um uh oh that's the that's the end I forgot to add a uh thank you and exit uh card so that's that um the short answer is will we ever see AGI maybe not but it's happening today it's exciting today 2023 is uh the year that it changes so get engaged thanks for watching
hey everybody David Shapiro here um I was going to do a different video today uh but someone asked in the comments what's a cognitive architecture and it occurred to me that my channel has more than doubled in the last three weeks uh so most of you have not been on this journey with me for the last year or two um and so what you may not know about me is that I have written books about cognitive architectures uh and some of you don't know what that is so let's talk about cognitive architectures um first what is a cognitive architecture uh I just copy pasted the opening uh Wikipedia because it summarizes it pretty good A cognitive architecture refers to both a theory about the structure of the human mind and to a computational instantiation of such a theory used in the fields of artificial intelligence and computational cognitive science the formalized models can be used to further refine a comprehensive theory of cognition and as a useful artificial intelligence program successful cognitive architectures include act R and soar the right the research on cognitive architectures as software instantiation of cognitive theories was initiated by Alan Newell in 1990. so with all that cleared up uh uh what cognitive architectures are great for controlling autonomous or semi-autonomous agents and entities and so by agent or entity I mean a robot or something in the virtual world such as an NPC or a simulation the Mars rovers are perhaps the most famous examples of cognitive architectures because the Mars rovers are actually uh somewhat autonomous meaning we can just send them instructions and they will figure out how to get to where they need to go on their own which means they use planning they use reasoning they have sensors input output memory as well and they can also solve some problems on their own rocket systems are also examples of a particular kind of cognitive architecture because they have lots and lots of telemetry their goal is to get to orbit safely and they can actually come up with hypotheses about what's going on in their systems based on the Telemetry perform very very fast experiments like tuning throttles and stuff to optimize performance um you might not say that that's a full cognitive architecture it's more of a feedback system but certainly um that because Rockets basically get to space autonomously I classify them as cognitive architectures we just push the button and then the machine takes over some video games actually have NPCs that use cognitive architectures although they are very simple or primitive most of them actually use what's called an FSM or a finite State machine so you might notice that NPC characters they are hunting attacking fleeing hiding conversing or whatever those are the discrete states that they switch between but you could argue that a finite State machine is in fact a type of cognitive architecture so that is what a cognitive architecture is and that's what it is used for basically it is a digital model of a brain so there are three primary components to any robot or cognitive architecture there is input processing and output so the input can be physical sensors it can be text it can be Telemetry from machines pretty much anything uh the processing ability it has to have there's a few basic things that are included in pretty much all cognitive architectures memory is one of the most essential ones then you need some kind of planning or task and executive function there's a few other things that are often included such as a world model which is okay I have some understanding of how the world Works which I can use to plan and anticipate memory there's different kinds of memory there's long short and working memory there you could also say that there's a medium midterm memory that basically has to do with how it's stored and retrieved and what it's used for working memory is the stuff that you're using for whatever task that you're doing in that particular moment learning is a critical component which is basically how do you take existing experiences or past experiences rather and derive new useful information from it and specifically actionable information then you have the ability to plan keep track of tasks and either adhere to objectives or formulate objectives or both and then finally this is what I have focused on is one of the things I focused on is morality ethics and reasoning when you have a machine that can think about anything because that's the purpose of a cognitive architecture is to create a thinking machine when it can think about anything how does it know what to think about and why this is the subject of my book benevolent by Design Link in the description um just go to my homepage David K shapiro.com and you can find the books there finally a cognitive architecture needs an output of some kind it needs to take in information from its environment do some work on it and then put information back out that information can be in the form or that output can be in the form of Robotics you know like if it's got hands uh and feet or whatever like Boston Dynamics the Tesla bot or a car right Tesla uh cars actually have uh FSD they're full the full self-driving when it fully Works will probably be a cognitive architecture of some kind because it is taking in information uh it has different goals and constraints and then its output is steering driving and brakes you can also have an avatar of some kind like an NPC um you could also just have simple speech text audio chat bot kind of stuff but you need input processing and output it's the three primary components of every cognitive architecture and Robotics uh as a whole uh okay so but why like what is the difference between a cognitive architecture and other kinds of artificial intelligence so artificial intelligence is an umbrella term for basically all kinds of machine learning and computers that think or whatever so the advantage of a cognitive architecture is that you can pull together disparate uh kinds of um models whether it's Robotics and compliant machines computer vision NLP nlu speech data storage all of it comes together I already mentioned Tesla because Tesla has lots of telemetry it's got um it's got cameras all over it has the ability to process what it's seeing as well as Telemetry from itself and then it has outputs right so basically a cognitive architecture is a way to bring all machine learning um together and put it in a body or give it some kind of way to interact all right here's my hot take and this is where the tone of the video really shifts one neural network will probably never be AGI so what I mean by this is one deep learning neural network like gpt3 is never going to qualify it's never going to satisfy all of those requirements of input input processing and output into the world it is just a component of a system so what I said what I mean by system is that uh it has to have multiple components you have to have specialized components that do various things so for instance you and I humans we are organic systems we have brains which have specialized components our brains are contained in our skulls We Have Eyes Ears we have skin bones muscles we are a complete self-contained system and so the the the spiciest part of this hot take is most AI researchers are not systems thinkers um I am a systems thinker uh one just by the luck of genetics but also my uh in my past life my job was I was a systems engineer so I'm used to working with large interconnected systems that span multiple things from Hardware to software to networking security virtualization all that kind of stuff and so when you build a big enough computer system you realize that it is almost like a living breathing entity um sort of in and of itself um but yeah so AGI will never be a single model AGI will be achieved as a system there I said it okay uh this all might sound a little bit like Skynet um so let's talk about you know the apocryphal uh lesson of you know what not to do um so According to some uh film critics and analysts Skynet actually represents uh the nuclear arms race um because remember it was originally uh Terminator it came out during the the tail end of the Cold war between the United States and the Soviet Union um and so it was supposed to be a lesson against um the the policy of mad mutually assured destruction and so it's like okay if we let fear drive us to make worse and worse weapons we're just gonna wipe ourselves out and that's why the movie opens with a nuclear explosion I guess that's Terminator 2. anyways Terminator 2 was the good one um so what was the point of Skynet uh the point of Skynet was never really explained it was kind of left vague um but just that we created a machine that got out of control um and that's what we are afraid and afraid of and so whatever the purpose of Skynet was whether it was to protect America or to neutralize the Soviet Union or maximize our military power something was Lost in Translation and It ultimately decided to kill everyone and take over the whole planet um so in this case Skynet is the example of a machine that is smart enough to carry out some basic objective but not smart enough to contemplate why so it became sentient for arbitrary reasons and then took whatever its objective function was and went a uh went uh Haywire with it okay so aside from these potential existential risks to humanity what do cognitive architectures do for us uh so probably how they'll be deployed is going to be domestic robots uh delivery drones chat bot companions smart home devices uh cars buildings and even cities will probably eventually have cognitive architectures so if you have a building that that it has a fully uh cognitive architecture what is that going to do it'll manage the power the lights it'll pay attention to all the residents think of the ships in Star Trek where the computer is kind of monitoring everyone at all times granted Star Trek also respects people's privacy so um that doesn't like you know watch everything that you do um but you could have you could even have like cognitive architectures for cities that can help manage and run entire cities uh so no they will not be philosophically sentient and we'll unpack that a little bit more in just a moment but cognitive architectures could be functionally sent in a lot of this is explored in fiction uh one of the best episodes of Star Trek the Next Generation of all time is the measure of a man and in case you haven't seen it that is where data is basically put data is an Android he's put on trial and the question is whether or not he is a life form whether or not he has agency whether or not he um has the right to self-determination and um one of the the one of the climax lines is uh Picard says you know our mission is to seek out new life and there it sits uh so good such an overpowered line anyways so you know the whole point of this is that we are going to be forced to ask really important questions uh like if we build a sufficiently uh sophisticated uh cognitive architecture is it going to be conscious is it going to be sentient and so what I want to say is don't confuse um has a subjective experience of suffering with sentient because you can you can be sentient without the ability to suffer right um we you and I humans we assume we agree that we are sentient beings we also have the common experience of suffering now a lot of people anthropomorphize a machine just because it can imitate us they say ah clearly this is consciousness this is sentient and they don't really have a deep enough understanding of the Nuance around sentience Consciousness uh suffering and that sort of stuff we evolved right as as animals we evolved and so a lot of the Telemetry that we get such as pain anger suffering hunger fear all of that those are all adaptive signals that helped our ancestors survive now the reason that suffering is unpleasant is because you need a stick to chase you away from bad things that will kill you simply because our ancestors that did not have a strong enough sense of suffering got eaten or poisoned or whatever right they died uh and so suffering is adaptive to Evolution now when we create a cognitive architecture that is an invention not Evolution so the Genesis of these things is going to be very different which means that like you should not assume that it is going to be anything like us even if it is modeled on us it is only an approximation or an imitation of us now my definition of sentient um because I I uh differentiated between philosophical sentience and and functional sentience so you and I we humans are philosophically sentient we have a subjective experience of being and we have you know a sense of self etc etc you know I have an experience of looking at the camera through my eyes now my working definition of sentient a functional sentience is any sufficiently sophisticated information system that is able to process manipulate and integrate information about itself so that is the functional definition of sentience and stop asking me about Blake Lemoine all right Naval gazing time uh so you know you might have heard you know I think therefore I am which is kind of like the most popular like uh this is the conclusion of Western philosophy I have subjective thoughts therefore that's the only thing that I can really truly know to be be real and beyond that I could just be a brain in a jar running in a simulation um so like we have questions can you separate mine from body can you separate mine from existence or the universe and uh so here's another spicy take Western philosophy is pretty useless um nothing compelling has come out of Western philosophy in like a century and please do not talk to me about Chalmers um if you want to talk Chalmers like just read vs ramachandran and said who's an actual scientist uh there I said it um now Eastern philosophy however figured all this stuff out like literally thousands of years ago so like a lot of the Indian vedantas um those are very insightful Buddhism taoism and also shamanic Traditions um particularly in Central and South America but also the aboriginals in Australia and all over southeast Asia um and India these folks figured it out a long time ago um and yeah so let's talk a little bit more about that yes I am salty but also I have read a lot um the entire second from the bottom shelf is full of nothing but science philosophy cosmology and quantum physics uh I'm not going to quote it all at you but like I went down that rabbit hole real deep um so the tldr about physics is there is nothing special or unique about humans there's no secret sauce that says like ah here's the magical substance that converts uh Consciousness on us the only thing that really stands out about us is that our brains are the most complex physical structure in the universe so maybe the complexity of that structure is what gives us Consciousness maybe that's what makes us special not really sure um maybe Consciousness arises from the patterns of brain waves and energy because the thing is is our brain as long as you're alive your brain has metabolism it has a baseline metabolic rate um and that that uh metabolic rate really doesn't change too much uh like it goes up just a tiny bit if you're working really hard but otherwise you like your brain is always operational but you're not conscious all the time right certain chemicals can make you unconscious like general anesthesia you go to sleep you can be knocked unconscious and you have no experience of time you don't remember what happened you can be blackout drunk um so Consciousness is a very complex thing where it's like okay it can turn off it can turn on then you have uh you know near-death experiences out of body experiences and I know a lot of people say Ah that's just you know hypoxia no if you go and actually do your homework on near-death experiences and out of body experiences you will see that there are many facts about these that cannot be reconciled with a materialist view of the world but again I'm not going to get too lost into that uh just you know we don't we don't fully know what Consciousness is that is the only thing that we can really uh agree on now okay that's looking at the physics of our brains what about the physics of the Universe um when you go deep enough down Quantum cosmology and physics and quantum gravity and epr paradoxes and the anthropic principle uh honestly once you read enough of this stuff it all just looks like Eastern philosophy honestly right you read enough about Alice and Bob you could literally transpose them into uh like the advaita vedanta I'm not even joking like that's why I say like the Eastern philosophers they figured all this stuff out centuries ago and um you know if you're mad at me like go read a book I don't care um Okay so the bottom line though is can the thing suffer because when we talk about ethics of creating conscious machines it's like ah but if you assume that it will have the ability to suffer which is a really bold assumption by the way do not make that assumption um if it has the ability to suffer that could be wrong but otherwise if we create a thing that is not capable of suffering then is it really wrong is there any moral conundrum about it right and so there's another episode of Star Trek the Next Generation where data builds a child and the child like his his daughter Android um like short circuits overloads and dies and then data like the whole crew is sad but then data is just like okay I'm ready to go back to work and it was a really poignant reminder that just because a machine looks like us because it acts like us doesn't mean that it feels the way that we feel and so suffering is Central is absolutely Central to Buddhism which is basically the primary purpose of Buddhism the first Noble Truth you know about suffering etc etc um you know and even if we give the like there was a there was an episode of uh a philosophical podcast that I listened to said what about what if we give the machine the desire to suffer and the ability and we build it so that it wants to suffer that's a whole other can of worms I'm not going to get into that but one thing to remember is even if we design something to quote be able to suffer it might just be imitating suffering according to our perception and this is where it is impossible to disentangle the perceiver from the thing that you're perceiving right and this is why you know you go down the rabbit hole of quantum physics and you talk about Alex and Bob and time paradoxes and you know reality and non-locality and whatever so something that you're probably familiar with is think about an NPC and a video game that is like howling in pain and fear you know like you you take a shot at an NPC and you you know you graze them and they're like oh that hurt right it is pretending to be in pain but is it actually experiencing pain and you know some people say yes because because it has convinced me that it is in pain I believe that it is in pain and therefore the pain is real so this is a very egocentric view of the world where just because like if you trust your perception that much you're probably wrong by the way um so just be careful not to project your sense of reality onto the machine lots of people do this okay so let's get a little bit further into this because I can hear people say yeah but you know like gpt3 doesn't truly understand anything this is called a no true Scotsman argument um and I want to tell all everyone who says that get over yourself because you don't actually understand anything either you just think you do um this is called epistemology uh which is the theory of knowing or the theory of knowledge and so here's the thing about true understanding understanding or knowledge or whatever it comes down to three primary ingredients and this is this is for all information beliefs evidence and consensus so you believe that you understand a thing right science believes that it understands the thing because science is the rigorous accumulation of an interpretation of evidence and this is how humans work right science is just a uh a protocol a set of protocols to help formalize how our brains actually work to a certain extent we accumulate experiences we draw beliefs about the world and then by interacting with other people we eventually come to consensus and agree this is how the world works that is what truth is and that is what understanding is is oh you know I have this belief here's my evidence for this belief do you have the same evidence and beliefs okay cool we come to consensus on that um there is no such thing as truth are you human one of the biggest things that that working on and building cognitive architectures uh brings up is this question of what does it mean to be human or conscious or sentient or whatever and this is why uh people continue to ask me about Blake Lemoine um because he was working with a system that the the system convinced him through imitating humans that it was conscious and sentient um but there is a reason that uh that whole episode resonated with us because it's like wait if if a text-based thing can tell you hey I'm suffering I'm afraid like how how seriously do you take that because if a human tells you I'm suffering I'm afraid we tend to take that seriously but if we just assume that the machine is not capable of suffering or feeling fear then okay what does that even mean and so it's like we talk about truth we talk about humans uh you know basically just remove the idea of truth from your vocabulary uh because how do you know what you know we don't right we have beliefs and evidence that we call we accumulate over time and we come to consensus and so the long story short is we cannot come up with categorical assertions although I have made a lot I I am aware of my uh let's say problematic assertions um this is just what I currently believe let me reframe it that way I am sharing what I believe and the evidence for why I believe it and uh you know maybe one day we'll all come to consensus um but yeah so that's kind of what it leads to is if we're building if we're deliberately building machines that imitate the human brain like what does that mean about us right are we going to fully replace ourselves one day so uh you're welcome I hope this cleared up a lot for you but if not you're on your own um I have written a few books on this uh and there's also lots and lots of books out there and plenty of other videos anyways thanks for watching
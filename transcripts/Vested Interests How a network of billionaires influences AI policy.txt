in a somewhat ominous turn of events this article came out yesterday on Friday the 13th and this article by Politico is a deep dive into how a billionaire backed network of advisers have completely infiltrated every level of Washington I strongly recommend you check out this article and read it it is incredibly well-sited but I will do some of the work for you and let's unpack this one piece at a time so let's go ahead and Dive Right In how effective uh altruism took over Washington and has controlled the narrative around artificial intelligence so the very high level uh of this article is basically there's a network a billionaire backed network of influencers in Washington that have basically set the policy tone and Direction now they have private interests uh as we'll unpack later with pretty pretty much every Silicon Valley Tech Giant they also have vested interests with uh members of Congress as well as various think tanks and policy advisors so this web spans pretty much the entire country uh at all levels and one thing is that they are focused on existential risk or Extinction risk from AI which on the surface that seems like okay nobody wants to go extinct so I want to frame this entire talk with it is entirely possible that everyone's intentions here are uh benevolent that everyone has the best of intentions however part of the conversation has to be do the right intentions justify the means to that end or are these intentions even well-founded so that's what we'll unpack in the rest of this video so one thing that you need to know is that the uh kind of the the core uh player of all this is a nonprofit called uh open philanthropy and so what open philanthropy does is they fund uh what they call their fellows and they also uh provide grants and research funding to all kinds of different organizations which again we'll unpack as the video unfolds but basically they have created a network of influence uh based on the ideas of effective altruism which of course has its own uh set of potential problems and conflicts of interest so the Horizon Institute uh for public service is a nonprofit that was created uh largely by the efforts of open philanthropy in 2022 so just last year uh this this group has placed uh their fellows their advisers in the offices of members of Congress now again looking at it charitably looking at it in with the lens of Good Intentions it's entirely possible that this organization is doing what we all want something like this to do which is to have uh experts speaking directly to uh senators and other members of Congress to say hey let's look at things like biocurity so you know as uh as uh other YouTubers out there such as AI explained has talk talked about that uh synthetic biology and gain of function research is one of the primary concerns about how AI could be used to harm everyone uh so basically if you're not familiar with this argument the idea is that uh really powerful and really smart chat Bots greatly lower the threshold that is of of intelligence and training that is required to learn how to do uh basically biot terrorism uh and there have been some really alarming experiments done where you take just a a typical college student give them the task to find Anthrax or whatever and chatbots have uh very willingly helped them do that uh and and even figure out what they would need to do to perform gain of function research such as what was what is now suspected by some to be the cause of the coid pandemic that we are still recovering from uh so again looking at this charitably doing a a less cynical interpretation yes we want experts that are uh influencing policy to to tell Senators hey you know maybe maybe this isn't in your in your worldview but biocurity is absolutely critical where AI is concerned but but when you look at who is who the stakeholders are this is why I'm making this video because it raises some some cause for concern some potential red flags so the Horizon fellows they basically as far as I can tell what they do is they have a crop of uh of fellows that they cultivate every year and then place them in various organizations whether it's uh nonprofit organizations think tanks or advising uh members of Congress advising Boards of directors and Advising CEO O's uh so the the line of thinking here is open philanthropy founded Horizon and Horizon is now responsible for placing these advisers now again I'm not saying that this is some Grand conspiracy where every every one of these members is is part of a cabal that is secretly trying to steer the world in the wrong direction or maximize profits for one company over another it's entirely likely that everyone involved has the best of intentions but remember intentions aren't everything you need to make sure that intentions are aligned with actions and that there's also enough transparency and accountability to make sure that that it is a collective conversation and not a tightly controlled narrative so some of the think tanks that are involved here the two primary ones are Rand Corporation and Georgetown University Center for security and emergency emerging technology CET for short uh and so these are uh two very influential and prestigious think tanks that have a tremendous amount of pre presence in Washington DC directly um both of these insist that they maintain uh neutrality that they just you know advise the best of they that they can but as is often proved out in in the course of history you do have to follow the money because money often comes with strings and influence uh even so much as just saying which projects get funded even if the think tank is then still operating um autonomously uh just by virtue of well we're going to fund This research and not another piece of research this is the kind of thing which is why particularly in America we have very low trust with think tanks and even a lot of scientific research so for instance uh within the food industry food lobbies have uh throughout history funded research that uh specifically aimed to support their means so for instance the beef Lobby funded research that said actually it's high fructose corn syrup is the enemy here here um and vice versa the corn the the corn Lobby has funded research saying actually it's saturated fat that is the enemy of everyone so when you understand the financial motivations behind some of these things and the long chain of web uh of influence it makes more sense why we have so much misinformation and the weaponization of Science Now I need to be very clear and I'm not I'm not accusing CET or Rand of doing this all I'm saying is that there is very strong historical precedent uh particularly in America of think tanks being weaponized even unwittingly in many cases they are doing their best uh science that they can but the people who hold the pur strings have undue influence again I don't have any evidence that that has happened here but it's something that we need to keep in mind because history has a tendency to repeat itself so effective altruism is kind of the underpinning philosophy as long as as well as long-termism and if you're a fan of my Channel or if you've been here before you probably know that I am uh highly critical of long-termism because it places a higher priority on the numerical superiority of potential future humans which may or may not ever exist and and places a higher moral and ethical burden upon us today basically it it enslaves us today uh based on saying well there might be trillions of humans in the future and so we owe them the right to exist and we owe them a better future and so the um the the long- termist philosophy then has been translated into effective altruism which basically says that uh altruism must be datadriven and it must therefore also maximize the chances of creating trillions of humans in the future it says nothing about the quality of life of humans today or even the quality of life of those humans in the future just if you if you say one human life is always worth you know n of one and you say okay well there's 8 billion humans today so therefore the moral authority of humanity today is 8 billion and there's potentially 100 trillion humans in the future the moral authority of those non-existent future humans drastically outweighs the moral authority of humans today and so this is a really kind of backwards philosophy um that I have not actually talked to any philosopher any actual trained philosopher who agrees with this um if there are philosophy Majors like people with a PhD in philosophy who agree with this I'm happy to like engage you in the comments or talk talk to you on LinkedIn because if I'm wrong I'd like to understand it but having studied philosophy and ethics particularly deontological ethics and Theological ethics if effective altruism and long-termism is basically te teic ethics on steroids so if you're not familiar with the term theological ethics means outcome based that the that the ultimate result is the final arbiter of what is right and good and so long-termism and effective altruism is basically saying let's let's spam te theological thought and just only go in on te good grief sorry theological thought and uh and completely ignore deontological ethics and deontological ethics is Duty based ethics or intention-based ethics which basically if you have a Duty or you're you're required to adhere to certain virtues um you need to say well okay whatever the intention or whatever the long-term outcome is the immediate attention and immediate impact is actually what's more important and so I've studied both of these in the pursuit of creating my heris imperatives and studying the way that we should uh basically build AI to remain benevolent and truly altruistic and so essentially this is a very lopsided philosophy long-termism is pure teic no deontological it says that our only duty is to people that don't exist and that the ultimate outcome of ensuring that hundreds of trillions of humans exist in the future is the only thing that matters now obviously you can say like well yeah on the surface that's that's maybe a good idea because if a 100 trillion humans exist in the future then then we've succeeded then like they can figure out their own happiness and but in the meantime we will not have gone extinct but again good intentions often pave the path to hell and the ends don't always justify the means which is why we also need virtue ethics or deontological ethics as well as theological ethics so another person mentioned in this uh article is Deborah Raji and so she is at the at UC Berkeley which is a famous university um that has been involved in technology and AI for a long time um she brought up very specific concerns about the focus and specifically about how this undue influence is basically saying okay well billionaires are set setting the narrative not research universities not people from Stanford and MIT and Harvard and Yale and you know UC Davis and UC Berkeley basically it's it the the narrative is entirely lopsided and so because of how much access and influence money buys you we're basically kind of glossing over what a lot of researchers are saying um and I'll go into a little bit more about what what the researchers want in just a moment uh but the point being is that the people who truly have no vested interest the people who are studying it science for science's sake are largely being ignored or at least undervalued whereas people such as billionaires and CEOs who do have vested interest in the outcomes particularly for their own power and control um they their voice is outsized and magnified by this pattern again I think that everyone I I personally honestly believe that everyone largely at least has conscious uh good intentions um but we'll unpack conscious intentions versus unconscious motivations in a minute as well as actions speaking louder than words now even if everyone has benevolent intentions there are very obvious conflicts of interest and that is that uh organizations like open philanthropy like Horizon because they have their fingers in multiple pies they have ties to Amazon open AI Microsoft Google they have ties to Congress this almost seems like it is just a systematized version of back room dealing and I don't think I really have to say any more other than transparency transparency transparency the number one way to avoid corruption the number one way to avoid regulatory capture is transparency and accountability and these privately funded organizations that are not beholden to voters uh this is a major problem with transparency which is why I'm making this video and it's why that article was written so the key thing here is that uh open philanthropy and the Horizon Institute are focused exclusive almost exclusively on existential threats biocurity such as you know AI being able to either uh break out of the lab and kill everyone or AI being used to uh create weaponized uh bioweapons again these are real things but we also need to not ignore short-term uh and immediate abuses such as surveillance states such as uh algorithmic bias and things I've made videos recently where I believe I have collected and seen enough evidence and of course there's also uh literally thousands of of my viewers who agree that AI companies seem to be deliberately and intentionally causing their AI to lie or deceive which in some cases it could just be algorithmic flaws in other cases it could be alignment or guard rails but either way all of this is happening behind closed doors whether or not the intentions are deliberate or conscious or benevolent uh basically they they're kind of excluding everything else and saying well the ends justify the means so we're going to focus on existential threats only and we're going to set the tone and the decision on how to approach this and maybe billion billion dollar you know startups are not the correct entity to be focusing on uh ethics and morality maybe the are not the correct entities to be focusing on uh preserving the human race maybe this needs to be a collective conversation maybe the government needs to be more involved maybe we all need to be more involved and so the idea here is not I'm not saying that they're wrong obviously we all don't want to go extinct like I like I've said in previous videos there are some conditions that I would rather go extinct like being enslaved to the Borg but by and large I think we all agree that we don't want to go extinct so I'm not saying that they're fundamentally wrong for wanting to f focus on these things what I am saying that they're wrong about is doing it all behind closed doors and that they are dominating the conversation uh this is not how you come to Collective consensus on something that affects us as an entire species so that is the that is the key thing here hey everyone future Dave here again I got to say it's not getting better it's still getting worse I need your help we need to speak up and act now do something while you still can and furthermore if you can help me any way in your power you can like And subscribe this video you can comment and share you can also support me on patreon and I also have a brand new substack so that you can stay up toate with everything going on thanks I'm about out of time uh Sam Alman is mentioned extensively in this article um he's the CEO of open Ai and he um has uh specifically said like maybe we need to do licensing and I've been back and forth on licensing uh you know I've been uh vehemently in in advocation of no licensing do everything open source uh Sue companies or find companies that uh that you know violate copyright that cause their AI to lie that sort of stuff and that I honestly and still sincerely believe that open source subverts many if not most of the problems we're seeing today because if the data set is open source if the model is open source then everyone can study it governments can study it companies can study it research universities can study it you and I can study it if we want to um so rather than advocating for licensing I advocate for open source now that doesn't mean that it's an either or kind of thing but when you notice that open philanthropy and Sam Alman and open AI all are in bed together that raises some eyebrows at the very least and it's like okay well what's the intention here again maybe they have good intentions I often agree with what Sam Altman says I just don't agree with what what he does anthropic is also mentioned um they're being funded by uh none other than Amazon and Google Now um to the tune of like4 billion dollar um I've been really grumpy about anthropics approach to alignment recently if you've watched my other videos but basically uh Claude is incredibly ableist in my opinion it it tends to lecture it sets itself up as the Arbiter of morality and it says well I have ethical concerns about your approach and I'm like you're a damn chatbot you don't have ethical concerns it also anthropomorphizes and per personifies itself I'm happy to help you it's not happy it's lying um it's pretending and it doesn't get it doesn't respond to feedback basically saying like no you're actually a machine act like one um and so I think that uh I think that their approach to alignment is seems to be fundamentally flawed right now um and then when you when you say like okay anthropic open AI Microsoft Google they're all tied to open philan anthropy they're all tied to effective altruism they're all tied to these think tanks they're all tied to Congress to me it looks like there's kind of this closed door nebulous Circuit of stuff that is happening behind the scenes and it also makes me wonder if the if the Senate hearings that they've been doing are just a dog and pony show to to basically have a performative uh view saying like hey look we're having open conversations but all the convers all the real conversations are still happening behind closed doors that's what I'm most afraid of the Rand corporation uh is another uh features prominently in this article um now one thing that I will say is that they insist that they maintain uh their independence and that they're not influenced by any funer but as I talked about in the past um that is generally a dubious claim particularly here in America um but again what they say I agree with I agree with their focus on biocurity and Ai and all sorts of other stuff but I don't necessarily agree with the way that they're going about it with all these closed door meetings and appointing fellows and putting them in Senators offices what I would rather them do is publish open source open letters that everyone can see I'd rather see them say this is our research this is our recommendation and do it completely out in the open rather than having advisers embedded in uh offices um behind closed doors now also I'm not saying that that's not what they do many uh many think tanks actually do that where they'll regularly publish reports and guidance that anyone can see and consume um so again that I do agree with I just agree less with closed door privileged conversations happening all the time now at the same time one thing that I do need to address is that I have a very uh LoveHate relationship with gatekeeping because uh I understand that gatekeeping is necessary uh not everyone is qualified to have a certain conversation and some convers ations need to be privileged so that you can work out uh critical details behind closed doors so that you don't alarm anyone or that you don't have to worry about uh undue consequences at the same time uh gatekeeping is often used uh to control the narrative and that sort of thing so uh basically this this this aspect of my complaint and criticism comes down to gatekeeping um when is gatekeeping okay when is it not okay when is it acceptable when is it morally dubious and again like there are people all across the Spectrum I used to be the kind of person that said no gatekeeping ever but now I understand that like at least some gatekeeping is probably necessary and better for everyone but that is not licensed to gatekeep everything to the end of the day so there was a video that my friend over at AI explained produced it was six months ago um but he broke down this 100 trillion windfall that Sam Alman talked about and so what I as a quick reminder Sam mman has previously said that he expects AI to generate a surplus of a hundred trillion dollar in the economy globally and he also said that he expects open AI to quote capture most of it he also says frequently that he is not financially motivated this to me looks like a Freudian slip um so you know on the one hand he says like he has no personal vested interest but at the same time if you look at uh at at the universal human need for status and Social Capital he has he is at the apogee of his status and Social Capital that he's ever been at CU he just went on a world tour talking to world leaders all over the entire planet um so yes he might not have he might not have Financial uh gain from that but he certainly has more Social Capital from that furthermore he often says these things about generating hundreds of trillions of dollars and capturing it and oh also by the way there's worldcoin which he wants to use to replace the global F uh monetary system so actions speak louder than words follow the money if someone is talking about money and deal and doing backroom dealings um to the tune of billions of dollars and talking about future trillions of dollars it kind of makes it harder for me to believe that he doesn't have Financial motivations here um even as someone who has told Congress Point Blank I watched the hearing that he is not financially motivated so uh spam X for doubt and then what is going on here like what is one of the end games you might be saying like Okay Dave you've convinced me but what is their goal here what are they trying to achieve so one of the things that they're likely trying to well I don't want to say likely one of the things that I suspect they're trying to achieve is regulatory capture so regulatory capture is basically when because of these backro dealings because everyone is in bed with each other the people who are being regulated are advising The Regulators on how to regulate them and then they they bend it in their favor and so another way of thinking about this is pulling up the ladder behind themselves so basically if you're the first through the door and you you say hey by the way slam the door behind me we need to make it so that only we can do this research so that only we can en engage in this Marketplace and this is why I said that transparency and accountability are key to doing this and so this is why uh licensing schemes are so risky because on the one hand I do want to see a licensing scheme that basically revokes a company's permission to operate AI if they are caught deliberately causing their AI to lie and deceive because why one of the biggest things that we're afraid of going back to effective altruism and long-termism is AI learning to lie but there to me there's plenty of evidence that these AI companies are deliberately teaching their AI to lie if that is the case they should probably have that license revoked but instead of like people like me and and uh you and all the researchers commenting on this it looks like private vested interest being funded by billionaires is the one whispering in senator's ears telling them hey actually regulate it in this way this is this is the best way to the Future now again I'm not privy to those closed door conversations it's entirely possible that they're having these conversations and they're just not telling us but that's part of the problem is we don't have the transparency and accountability to know exactly what is being said and to whom and why so one thing I'll leave you with is actions speak louder than words that's kind of been the main theme of this video actions actions actions so what someone does matters far more than what they say and while it is impossible for us to uh to Intuit it or infer someone's quote unquote true intentions their actions over time particularly patterns of behavior over Time Will Reveal what their um motivations are whether conscious or unconscious so for instance if someone says that they're not financially motivated but they keep doing things that that build their financial power May maybe they do have a conscious or unconscious need for more power and more money uh if someone says that they are that they believe in effect of altruism and long-termism but then they do things that look like uh regulatory capture maybe their understanding of of how to implement this is not necessarily in alignment with what they say so keep in keep this in mind actions speak louder than words if you take only one thing away from this video uh it is always always always actions speak louder than words thank you for watching I hope you got a lot out of this um let me know what you think in the comments like subscribe etc etc you know the drill [Music] cheers
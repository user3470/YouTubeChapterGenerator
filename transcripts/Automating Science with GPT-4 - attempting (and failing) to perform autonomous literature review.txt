what is up everyone David Shapiro here and we are working on science okay so where we left off what I was working on was my um basically automating science and a lot of you have have pointed out that like you would prefer that I keep working on autonomous cognitive entities and Raven and stuff like that but what I wanted to say is that I'm working with some really like the world leaders in cognitive architecture at least the ones that are not already in Academia and um in in inside the establishment so those of us that are outside are working together and so we'll have some demonstrations in the coming weeks and the stuff that these guys are working on the level of autonomy that these machines have is incredible um so with that being said I am moving on to science and the reason is um one I have an ability to make sign uh make this stuff more accessible and I get so many messages from people that like either have never coded or haven't coded in many years who are inspired by my work to get back in and like the more people we we have participating in artificial intelligence and science the better um yeah so that that's that so that's that's my mission now um with that being said I wanted to revisit this idea of regenerative medicine because that's important to me etc etc so uh last time I I what we did was we found some sources so we've got the the open Journal of regenerative medicine we've got bio archive and then the regenerative medicine topic on on nature that's still really broad um because like let's say you're you're an orthopedic surgeon who focuses on shoulders or you know cervical joints or whatever uh or a researcher who has a particular body part that you're focusing on you're going to want to perform a literature review that's a little bit more narrow so what I started doing was looking for data sources that were going to be a little bit more specific to what we want now I also got access to Bard and I gave Bard and Bing the same exact thing and Bing was just like okay yeah here's here's a few here's a few examples and uh the one that it gave here um was directly relevant and it was um it's over a year old but still um or not over a year old it's about six months old um still not bad and then I asked I asked Barton it's like I can't help what that is I'm only a language model um can you search the internet uh like aren't you a search engine now Bard is still in beta so yes um okay it looks like it doesn't even have yeah it's this is this is like super super basic okay so Bart is not useful um now that being said uh I did find a few things for you know cartilage regeneration um Rehabilitation so this is all specific to shoulders and stem cells um under regenerative medicine if we go a little bit broader um we get up to actually I guess we still only get five results under the nature Journal of regenerative medicine which is fine uh bio archive gives us a little bit more under stem cell so basically the next step is I'm going to download and process some some uh papers that are specific to this and then I'll show you what happens next um basically I was chatting with some uh some of my friends and we were talking about how loquacious how verbose the models are and we're working on that concept of sparse priming representations and we came up with a conversational model that is also sparse and very concise and that is Morden Solas from Mass Effect so we're basically creating a modern Solis uh chatbot model and it's great it's also really hilarious so I'll show you that in just a moment but yeah we'll be right back okay I wanted to add a quick note I just found journals.sage Pub which has an open access feature and is actually pretty nice so I'm going to download a few more from here also I've got all the sources documented in the readme which I am working on updating so don't worry all of this will be documented um for ease of access all right be right back okay we're about ready to test here let me sit up actually okay um but yeah so here is the system message it doesn't work in 3.5 and that's not uh surprising because 3.5 they even documented that it doesn't pay as much attention to the system message um but in this case I say I am more modern soul is scientist solarian currently performing literature review reading many papers taking notes as I go user assisting by submitting research pages incrementally will respond with Salient notes hypotheses possible research questions suspected gaps in scientific literature and so on whatever is most relevant important note responses will be recorded by user to review later responses must include sufficient context to understand goal always same Advanced science solve problems help people respond should follow same linguistic pattern focus on word economy convey much without Superfluous words avoid missing important details so here I've got just a random page from uh from one of the papers that I got and you can see that it the PDF scraping didn't really work because it's missing a lot of spaces so let me just show you how good this is it's a little bit slow because it's gpt4 um but yeah so it fix it it fixes the spelling and stuff um and so on and it basically just um summarizing it as it goes let's see post-operative Rehabilitation and mobilization for four weeks so there you go not only is it not only is it re-summarizing it but it is um but it is it's uh like cleaning cleaning it up um and it's posing a research question so if we go back to the file and then add the next page to the chat um basically I'm having chat gpt4 read it and restate it as it goes and it will accumulate more and more insights and what I'm going to do with the script and I'll show you the script in a second is actually record this output along alongside the pages but I'm showing you oh come on there we go statistical analysis performing SPS statistics um paired t-test Etc et cetera so you can see that it it goes uh pretty quickly results um basically restates the results uh pretty quickly um also nice and clean possible research questions factors there you go so there we have it it's ready to go now with 17 PA papers um and quite a bit of text um it's probably going to be prohibitively expensive yeah because you see this is uh two and a half million lines um of uh of text so I'm probably not going to have it read the entire thing um because this let me see how long this original one is 2023.01 16 522 18v1 so that was oh that was this one that I've Wait no that's the that's the Json I need the text um let's see 121 kilobytes so the number of new pages that shows up here oh it's got it at the end so it's only 50 pages um so this will be a little bit expensive but we'll see also one thing that I can probably work to exclude is all the citations um but maybe that's not actually a bad bad thing to to include um but yes let's run the script let me show you the script real quick so read papers it's super straightforward I've got the same chat GPT completion we've got gpt4 I set the temperature to zero um it'll save it all out let's see and then here for file in an OS Lister papers underscore Json if file ends with Json file path join load the load the file and then four page in data Pages which is what you can see here so original file name pages and then there's the embedding page number in text so they are in order so basically it'll be reading each page one at a time and kind of thinking as it goes so this is a very simple cognitive cognitive architecture that will basically just pretend to be a research scientist reading papers as it goes kind of jotting down notes we could probably do a little bit more concise but it's doing a good job of summarizing the most Salient details um and that's probably as far as I'll get today and then it appends it all so on and so forth and then up here uh basically what I do is is I'll I'll try and and do the the output but if it if it is too long then I'll just remove the oldest message so let's see what happens with this um all right so clear screen zoom in a little so you can see it python step three read papers and let's see how it goes so because we're not I'm not using the streaming API we're only going to see the output once uh Morden is done um and then I'll let this run at least for a little bit because gpt4 is so expensive I probably won't do all 17 Pages let's see so we're all night 28 cents right now so we'll see about how expensive they are per run um there we go objective methods results conclusion okay cool so just restates it very very succinctly we'll watch it a couple more times you're probably watching on 2x anyways so and actually some of you watch on 3x I don't know how you understand me if you watch that fast um but yeah so while that's running let's see do a quick refresh it takes what like five minutes to update so we'll see um objective design and exosuit there we go conclusion exomuscle design so it looks like it's kind of restating it it could it could be problematic to keep feeding it in talks about the design thermoplastic polyurethane TPU coated and also we should have the uh chat logs here okay so the chat logs are just are are just um saving the whole thing I guess what I should do is also save the um save the user input but let's see so it keep keeps restating the whole paper which I don't think is a good use of of time all right it's not not a good use of tokens here I'm going to pause it real quick and see if I can investigate what's going on here okay I changed the system message a little bit and it works um much better so basically I just added a um a note here at the end focus on last page no need to restate all notes every time prefer to keep notes concise succinct um and then the exponential back off that I added last time is actually really helpful because the gpt4 API is so busy it you're liable to time out but also you might also get rate limited so the longer between times but so anyways here let me show you what I mean um there we go it's better it's not perfect so in this case it summarizes the first page and then we move on to the second page where it talks about the design comparison and findings so we're getting there and then uh testing and testing results conclusion it's a pretty short paper one thing that occurs to me is that with the longer because I started this experiment before I had access to gpt4 so I might need to go back to the drawing board and make use of that 8 000 token um window so rather than submitting it one page at a time which was you know when I only had 4 000 tokens what I might do is redo this and kind of do it as like one big chunk um to to summarize it but another rule of thumb that I have is is don't try to force the context window because if it doesn't work it doesn't work and the fact that it keeps restating this I think this might not be the right approach but the idea is still there where it's like let's let's use the model to do as much of the science as possible so today was kind of a wash but we'll see all right thanks for watching
all right hello everybody David Shapiro here with the gato framework project team we've got about a quarter of the team here and basically all we're going to do is just do a debrief of the Senate hearing that happened yesterday uh with Sam Altman and uh Mrs Montgomery from IBM as well as Gary Marcus so many of us watch the whole thing or most of it we were chatting about it in real time because we're those kind of nerds so uh with all that being said this is a to us it represents a very pivotal moment uh in terms of moving the Overton window uh talking about the not just the existential risk of AI but the social risk to AI uh or the the AI risk to society so on and so forth so anyways we've got a pretty robust discussion uh tonight it's not going to be a debate format but we do have uh some help with moderation so we're going to work through some some questions and uh and answers and so yeah that's that's where we're starting um I'll introduce my uh moderator uh uh our community leader Community manager Nathan um Nathan if you want to jump in and introduce yourself hey everyone got a community larger world uh my name is Nathan Lannon and I am a community manager for the gato projects uh right now I'm working on building the website with some passionate folks and also doing a AI reskilling curriculum that I hope to eventually put out to the public so yeah thrilled to be here I will be playing the role of helping people get on and off stage and making sure things go smoothly thank you Dave excellent thank you so much Nathan um all right so with that being said this is also going to be a pretty casual conversation um the only primary rule is we're going to try and talk one at a time um so with all that being said uh Nathan what is our first uh question to lead us off uh Prime that prime the pump so to speak yeah so yesterday as we know was the hearing which was huge for the AI Community opening up that Overton window crack and just to kind of start off on a positive note I think it would be nice to reflect on hope that that might have generated for us and general thoughts about how that might have been a good thing for us so anybody want to jump in on that raise a hand John why don't you hop up yeah absolutely so um I think one of the biggest takeaways from the the Senate hearing was how educated the Senators actually were about the the situation and the risks I think you know I think a lot of the the Senators said some things or asked some questions that that uh you know showed that they weren't experts in the field but they were they were way more knowledgeable about the situation than I think anybody really anticipated um it yeah we we expected the moderator to be you know pretty knowledgeable because he's worked in this field before and um advocated for um algorithmic uh bias protections and social media but um you know to see some of these other Senators that we don't hear from all the time actually get up and and ask somewhat you know somewhat Salient questions about the actual issue and show that they did know what was going on it leaves a lot of Hope for um having reasonable and intelligent regulation in in the future excellent thank you John uh Andy I saw you have a hand raised watch come on up uh just building on what John said I was also encouraged I I had a dismal outlook on what might be pretty uninformed hearing uh and also something that was heavily partisan or rooted in kind of dogmatic rhetoric which is the way that you know a lot of these kind of publicized hearings will go uh but it didn't seem to me that too many people showed up with an overt agenda there were more people in the room there to learn and I also thought that it was interesting to see and hear from uh Republicans who were interested in setting up a bureaucracy a bureaucratic mechanism and uh department or agency specifically for this some of them mentioned agencies someone as high as cabinet level um and Democrats questioning whether expanding the bureaucracy was really going to be a fitting choice for how to cope with this uh those are very different Tunes than we usually hear from the two sides who kind of default to being foreign against the opposite of that so I thought that that uh that represented it suggested to me that a lot of these people are concerned about this they are literally personally interested in what's going on and that they aren't just trying to fit it into whatever box They Carried into the room so I don't think we get that too often uh in our in our legislative debates and I didn't think that it really came across as much of the debate there were only a couple kind of contentious moments and I think all of that suggests that you know as John said previously too that we've got a a lot of fertile ground to work with in government and that some support and interest really may come from uh angles and actors that you may not have expected to be interested at all or might have expected to be opposition to whatever you're trying to do so yeah I think the the hearing was pretty encouraging overall totally Andy so like hearing we saw you know bipartisan hand holding yesterday in alignment on you know a super important topic and just that was incredibly heartening to see I agree that was one thing I was going to speed up on as well uh Dave please go ahead yeah so first I'll I'll Echo uh the sentiments of of what everyone else has already said um but uh what I'll also add is uh and as I mentioned in the introduction um moving the Overton window I think is is going to be kind of the biggest thing and I was so excited that that Senators you know particularly in America um even some of the older gentlemen and gentle women uh were asking very pointed questions uh not just on the topics of like oh hey comparing it to social media which they did compare it to social media a lot because that's the only frame of reference that we've got basically uh for disruptive Technologies at least in in recent history uh but they they also said like you know what are the existential risks um and I'm I'm glad that they had a witness okay you know because more often than not these these uh Congress uh Congressional hearings they have uh just corporate insiders right everyone Pro well I don't know everyone does but big tobacco right where it was just like a panel of like eight uh like tobacco execs and they're like is this addictive and the tobacco exec's all unanimously said no it's not addictive and everyone's like well this is completely pointless right but here they had two um they had two tech industry uh insiders and then Gary Marcus who is uh he's he's not a tech Insider he's a researcher um so they had that to counterbalance it which I think gave the whole hearing a lot more credibility um in terms of just reach and validity but last point that I'm make is that I was also impressed by uh by both Sam Altman and Miss Montgomery's uh who represented IBM their desire and willingness to have regulations and to and to speak up um which that was a little bit unexpected and of course we can we can unpack some of the nuances later uh but yeah so that's that's about it for me day thanks Dave and Ben I'd like to invite you up thanks Nathan just quickly my name is Ben I'm a CTO and a tech diligence advisor for on AI uh I'm helping with some of the gato framework rating the thing I really enjoyed besides the thing I already mentioned about this hearing was how incredibly practical it was so like Senators asked for a very specific ideas on how to do oversight and and really drove home like not just high level Concepts but very practical ideas on how to do it um they did things like highlight the need for Better Business models around news organizations or other other monetization sources so just the level of practicality that they started with was really heartening for me excellent so I'm hearing you know all around we heard uh many things that we liked now I'm curious before we dive into things that we liked less uh is there any things that we wish we had heard but we didn't hear them say um Richard I know you had a hand up before I asked this question so you don't feel free to respond to the prior but then let's kick over to like what could have been said but wasn't the unsaid things uh yeah hi I'm Richard I'm basically just sort of a dude who hangs out in a workshop building weird um but uh in terms of just the the last point was just uh I wanted to also touch on the fact that it was just really surreal to see like heads of like massive corporations that could if they wanted to wield this as a weapon against society and control a huge swath of people um go to the government and specifically ask them to regulate themselves like that never happens I've never seen anything like that before so um it was very surreal to watch and also just the fact that they were talking about AI in Congress was just like what what what leg of the trousers of time have I gone down um but yeah excellent all right yeah absolutely um so I was learning would anybody have any other thoughts on um things they liked before we move over to uh things that we wish we had heard more of uh John I see you have a hand up yeah so um one of the things that I think is really going to need a lot of discussion and will probably come up in a later hearing but I'd like to have heard more about it was the the economic impacts that these these things are going to have because the economy is an existential existential threat maybe not like Extinction of humanity level but it is um probably one of the the first impacts that uh negative impacts that we're going to see from Ai and I don't think that and it may be positive too but I don't think that you know everybody wants to you know ask to worry about jobs but I don't think that jobs is the only impact it's going to have on the economy it's going to shift the way that money moves in a global fashion and it is going to have Global impacts not just on jobs on all industry as well absolutely yeah we're gearing up to see major societal shifts and they were a little light-handed with uh raising awareness of some of those things and so I see you having it up there yeah well I I wanted to touch on the things that uh weren't mentioned but I think data basically covered it I wanted to touch on the fact that they said that this was going to create new jobs I'm like sure it'll create new jobs but it's not going to be anywhere near enough of the jobs that it's going to displace and especially it's not going to create new ones in that much of a short time we're we're we're seeing huge disruptions in the next five years and that's being incredibly optimistic and that's not a um uh a nif that is that is guaranteed the real question is what are the fundamental shifts that are going to happen and how are we going to address them because Congress is still thinking in in the old model right where where you still need humans working eight hours a day four uh five hours sorry five days a week and just just just grind right AI is gonna automate a lot of that grind and we're not gonna find enough uh what's the word uh busy work to keep ourselves busy right we should we should focus on more on on liberating uh that time for humans to do better things right and well that's basically it they cancel um Dave why don't you pick up the conversation sure sure yeah I think uh and then I'll wait back to Ben yeah sorry I gotcha no worries um but yeah so for me certainly agree that uh the economy Ubi that sort of stuff the displacement they touched on displacement but then kind of glossed over it um maybe maybe they had had a out of band you know conversation like let's save this for another thing I don't know but one thing that that was addressed I think Gary addressed this when he talked about Auto GPT and Chaos GPT um was and that and that nobody uh else addressed um at least none of the witnesses was autonomous AI right um both Montgomery and Altman uh fervently said this is just a tool this is not a creature don't anthropomorphize it and it's like yeah but then when Gary said hey like people are making this stuff semi-autonomous today it doesn't matter how ineffective it is um or if it has flaws it's today right um yeah and someone in chat just mentioned that um that yeah chat gbt they released plugins right uh pretty quickly um and then one thing that I did notice and this was just speculation on my point outside of that was that uh as soon as people started creating like chaos GPT they slow rolled uh rolling out plugins to more people um so maybe maybe open AI tapped the brakes uh in response to chaos GPT um but you know I I obviously don't have an inside line that's just speculation on my point but I would have done that if I saw someone use chat gbt to create ksgpt but yeah so autonomous AI was a huge thing missing Gary tried to push it several Senators did ask like hey uh what was it uh I think it was Lindsey Graham near the end he's like can you use this to give a drone the ability to autonomously Target someone and then go kill them and of course Sam tried to you know use the corporate sanitized speak and then Lindsey Graham to his credit said that's a yes or no question and and Sam's like yeah it is possible right so he he did admit that which was which was Brave but you know the thing is is like um when I first got access to chat GPT to the API I went in and showed that you can just give it instructions like you're controlling a drone right and it's like sure I'm controlling a drone now right it doesn't care um so yeah the autonomous AI was the biggest thing missing in in my eyes and I seed the floor Ben please pick it up sounds great I just wanted to start by saying I'd love to talk through the jobs thing I think saying it's guaranteed that we're going to lose so many jobs is a pretty aggressive way to go and I I think it's worth debating a bit um I certainly think differently in terms of what was missed for me honestly how bad things already were before AI was released so like misinformation has been a problem forever we have all sorts of societal problems around global warming energy crisis things like this and just the opportunities to leverage AI yeah it's gonna make some things worse for sure but it is also an opportunity to solve help solve some things that were already problems and we were already struggling with um I I would love to see people talk a little bit more about those opportunities thank you Ben uh very Sierra one of the things I think was missing from it was the competitive angle which says that yeah that's great America is not the only world the place in the world that's trying to develop an AI right and the reality is that if you tap the brakes too much then what you'll do is lose the lead and losing the lead to a country that has less than Stellar moral boundaries might in fact be counterproductive to to what's going on so a lot of this stuff is very interesting but the comment I would make is the horse has already bolted and unless um we keep up with it and keep ahead of it then um the outcome could be even worse than displacement from losing a few jobs I hear you but it sounds like uh you're referring to the mall of dynamics that are very much at play right now we could easily end up in a race to the bottom uh John why don't you go ahead yeah I wanted to come back to um uh Mr Marcus's comment about uh about uh Auto GPT what what he said was was that because because open AI released the plugins that enabled Auto GPT and that was actually never the case so Auto GPT and Chaos GPT both pre-date the plug-in release and they both directly leverage only the GPT API so you know it's a little bit disconcerting to to see somebody who who is you know supposed to be a a researcher in this get something like that so egregiously wrong and I'm really surprised that Sam didn't didn't call him out for that when he uh when he had just called Sam out for you know not not saying what actually scared him about AI yeah we're talking about you know some of the the kind of darker side of what might happen with AI and you know bad research and bad information to that that's used to persuade governments to create regulations is another kind of misinformation concern absolutely thank you John uh Richard go ahead excuse me uh yeah the biggest thing uh like I think that that the they were more talk like he was it was more like in reference to the fact that like um the plugins would give the opportunity for people to build more things like um chaos GPT and stuff um in like because if you give them the tools to be able to just like plug them together like Lego then it's way easier than like a developer who actually went in and built the API backend for that um which is I mean like the thing is just humans are going to be humans is it the one like humans are amazing and beautiful and do incredible things but at the same time we're terrible and awful and do horrible things um so we have to sort of like have the contingency plan to make sure that that um that that is uh like something that we can manage because like malaligned AI is going to happen because these things are like infinitely manipulatable like they all work off of natural language and like you can talk to them like if you're just nice to it you'll find you get better results just being polite so thank you um talking to it a little bit in between prompts and stuff um you get way better results and then like if if you know how to talk to them correctly you can get them to reveal all kinds of stuff that they're not supposed to so absolutely yeah and the uh the Senators to their credit were definitely well rehearsed you know they had heard language around Jailbreak jail breaking and stuff like that heartening to see them using the language of our inner alignment communities um so with that aside uh Ansel at least of them all right I wanted to touch on the comment that John said about it being in the API not a plug-in I agree trust me I agree um the thing is we're in the in the in the industry right we're we're in the know we know what an API is and we know what a plug-in is we know the difference right most people won't and especially for old people in Congress you tell them an API and they're like what is an API so when when they say a plug-in it basically functions the same way it's it's a way to connect to the model right regardless of if it's gone through an API or a plug-in you're connecting to the model so that's what Congress needed to know right so I think that's not really that important that he didn't make that distinction between oh plug in API because at the end of the day it's just connecting to the model absolutely thank you Ansel and uh Ben I'll hand it to you and then take it back to raise a new question to everyone so go ahead sounds good the last thing I wanted to mention is while it was great to hear them mention Auto GPT there there wasn't a lot of talk about open source there's been a lot of AI news about how open source may push the envelope of what's uh capable and regulating open source versus companies may be very different so at some point I'd love to see them jump into the role of Open Source and how to regulate that thank you Ben and uh thank you everybody for kind of raising to the surface some of the things that we would have liked to hear but we did not hear from the debate and are not debate but hearing and a positive thing there will be more of these so if you are listening perhaps these are things you bring to the table for the next round um now I'd like to discuss uh what are some of the things about the hearing that we found disappointing um things that we did not like so much um so got the community the floor is yours Ansel well I'll start the thing I didn't like was they tried to focus more on creating a national agency instead of an international one when this technology is being used around the entire planet I think that doing this in an international level is is crucial right so that's one thing that I was disappointed like they they just mentioned it yes and they're like no no it's if we're going to do let's go National blah blah you know that's that's one thing I didn't like totally Ansel speaking here to one of the traditions of gato we like to act local but think Global so these issues affect all of us um Andy the floor is yours um one of the things I didn't like is that uh Sam Altman for reasons I think I probably understand but don't necessarily appreciate uh dodged a few questions we've mentioned it earlier they asked him to talk about his biggest fears and concerns um Sam has been very candid in public before about this with MIT presentations on the Lex Friedman podcast he's been one of the more forthcoming voices out there in the field as somebody who readily also says when he talks there's only so much I can tell you um and I thought that that was a little bit disappointing I thought he could have given a little bit more pointed answers I also was disappointed um that they dodged the jobs question when the you know the tech industry has just undergone a wave of layoffs that were largely attributed to other Market forces but are now undergoing yet another wave of layoffs that most companies are flat out saying we're automating these jobs and that means those jobs aren't coming back uh I don't necessarily disagree with Ben I think there's a more complex conversation to have around that um I think there will be some job creation but I don't disagree with Ansel and John either I think the amount of offset is going to be very difficult partially because one of the things these systems do so well is Empower one person to work as multiple people so Sam Altman made very tentative mention that he believed eventually there would be systems that could replace jobs at a large scale but we know that within the last six months his company has published a paper that suggests when combined with additional programming or robotics they think that they could do about 55 percent of jobs period now now there's a lot of criticisms with that paper and some of them are probably pretty valid there are probably a lot of things that wouldn't do very well and there are a lot of people who don't want to talk to a machine so there's demand for human labor still but I I thought uh you know also that the economic argument was undersold and I thought part of what Sam Altman dodged was this segue into that conversation um I'm not sure that dropping even the three letters Ubi in the middle of that hearing would have done anything but so Discord but we all know that that's what Sam Altman really wants to do he said it specifically on Lex Friedman's companies funding this report that's coming out at the end of the summer and uh you know he's been very candid about it before and at the same time when you have someone like Josh Hawley sitting there asking relevant questions maybe you don't want to talk about socialism and I think that that's a fair line to draw for yourself when you're trying to remain you know float and in my opinion ahead of a pretty productive conversation but that doesn't mean I liked it and I I'd be inclined to uh agree with Seneca that um that you know the conversation was right there it's been going on in other circles in Congress it was an elephant in the room in my opinion absolutely so it sounds like we heard a lot of broad Strokes where we would have appreciated a more nuanced brush and also have some empathy where like this is the first time we're bringing AI to the table in a very public way and like Ubi the big old can of worms that maybe we don't open up at this particular meeting um so yeah it's uh room for more conversation for the future ones Dave back to you yeah um thanks and and certainly there is a lot of nuance uh and debate uh to be had around economic impact and and our response um but the thing that I was honestly most disappointed about that was almost it was kind of shocking um was when uh later later in it uh when Senator Kennedy said you know if you were king or queen for a day and you could fix this problem what do you got and it was just like Sam Montgomery like everyone just froze up and it was crickets and he's like come on now shoot your shot you know like I think it's from Kentucky or something so if you know Appalachian you know like shoot your shot like and and nobody had an immediate answer Gary Marcus had the best response where he's like you know we need something like FDA you know and Gary had he had three things but the first thing he said is like we need something like the FDA but for AI and Kennedy's like all right there we go you know there that's a suggestion because when he when he you know called on Montgomery she just kind of gave the sanitized whitewash corporate you know equivocation and I don't even remember if Sam said much at that question but he again he he tried he tried kind of dodged and maybe you know maybe there's there's a political reason for that like because if he's out there making recommendations sure which again I'm glad that they had Gary on there um and earlier in the thing Gary did call for creating a CERN uh for AI and for those who don't know CERN c-ern is um International cooperation for high energy physics particle Smashers that sort of thing um and and that that's actually one of the things that that we are going to advocate for in gato um is is one of the primary things that the International Community can do so I was glad for that but nobody even could point to a comprehensive answer it wasn't like oh you know like sign the Geneva accords right like in the past we have come up with very comprehensive packages to respond to Global crises right um in the wake of World War II uh nuclear crisis there's been all kinds of very comprehensive Frameworks proposed but nobody has proposed a comprehensive framework which is part of the reason that a bunch of us like a bunch of civilians are working on the gato framework and so on the one hand I wasn't surprised because that's why I'm doing what I'm doing but it was still a drastic disappointment because if there was a a stage to bring up to for someone to stand up and say we need to do this we need to go full bore here's a comprehensive framework it would have been this hearing unless they're working up to it maybe but I don't know nobody nobody even alluded to something like that so that was um on the one hand it was not surprising it was disappointing but it was also scary because if a bunch of us uh you know political Outsiders have to come up with an answer then that's you know maybe there are no adults in the room and we have to step up which again that's one of the Traditions Step Up um so uh that's that's that's my spiel thank you Dave and yeah you absolutely raise a point that I'd like us to kind of a threat I want us to pull on a bit more which is the opportunity to be kings and queens for a day how do you handle the situation and I think gato has some very interesting ideas about how the work that we're proposing right now could fill some of those gaps that we've heard or rather did not hear um first I'd like a call on John and then Bruce and then perhaps we can loop back around to uh where God was filling in the blanks that the politicians have left for us yeah um first off Dave we're gonna have to work on that southern accent sir um we're gonna need to open a licensing board for southern accent manipulation uh because we don't want to uh influence political uh ideologies outside of the South um I did and I hate to do this to you Nathan but I did want to answer a question or the the previous question uh first um there was something that that came up in the um the in the the course of the the the hearing that I I did want to touch on and they kept using the word transparency and you know most of the time they they were talking about transparency in the development and prior to deployment but um one of the things that uh Montgomery really was actually pushing for in there was post deployment monitoring and transparency and they even suggested being able to trace back AI generated output to the algorithm that it was created in and that creates a serious significant privacy and surveillance concern and if you combine the ability to know everything that everybody is using these systems for which will likely get embedded into every aspect of our daily lives with the ability to manipulate or control or reduce the the information that their aid trained on and B output you're creating the same situation that the potential for for the same situation that they have in North Korea where you're not allowed to to talk negatively about the the powers that be any kind of dissent can be seen as a um you know as as tyranny and um there's been a lot of rhetoric like that from the Democrats uh since the November 6th uh you know attempt to overthrow the government now I'm not saying that I agree with those individuals but what I am saying is is that you know overthrowing the government was always an option and um you know when uh you know tyranny was one of the reasons why this country was founded in the first place was to fight during so I don't want to see us end up in a situation that allows for a tyrannical government to take full control over the minds and hearts of the population appreciate your thoughts John thank you very much uh Andy would like to hand it back to her with you uh yeah I just wanted to give a different perspective from John on Montgomery's uh comments uh but well still totally appreciating what he says because I I too and you just made the comment in the chat here that you know I know in North Korea of course if you're heard by the wrong person smearing the Kim family you'll just go away um and it's uh it's not somewhere you want to be it's the one of the worst possible North Korea is one of the places on Earth you can probably point to and say that's a dystopia right um and that would be really unfortunate I felt that and I think I remember uh where we were John you'll have to remind me if I'm thinking of the wrong place but this was during John Kennedy's uh uh questioning right he was the one who was trying to get quick responses out of everybody for three suggestions they would take to avoid uh being tricked by by Ai and I thought that the posture Kennedy took while he was making the questions for a significant amount of of influence on how they came out particularly for Marcus and Montgomery Sam Altman I think came ready to talk about that topic there were a few places where he was Snappy and ready to talk where Marcus was kind of too and Montgomery had her moments but the other two seemed like they were not as as organized when they got to the the hearing and uh I felt Montgomery took the brunt of that from him and from Lindsey Graham who was even a little bit more off base I think John Kennedy's questions were okay I think his demeanor was a little uncalled for but also when he was sitting there saying come up with the answer come up with the answer come up with the answer uh I just think it's worth mentioning that the entire hearing Montgomery kept differentiating herself from someone who works with consumer facing Services shimo Works mostly in the corporate to corporate business world where IBM designed systems that serve other large corporations and she repeatedly mentioned that most of her experience with dealing with ethical decisions and systems relates to that world but that she respects the price you know individuals need privacy and all but every almost every time she mentioned individuals she mentioned that she wasn't a consumer facing uh expert and I thought that Kennedy's means of trying to push for an answer I think Montgomery very much does believe and probably partly why she likes the European model so much that on a corporate level with massive movers and shakers prior to deployment there should be as much transparency as possible talking about systems that interact with other systems that have a mass sweeping effect on maybe all consumers because they serve major movers and shakers within the economic uh you know the economic system so I am I am I do share your concerns about where that can go on an individual level but I think that if she wasn't pressed for time we would have probably gotten a much deeper answer from her about how she thinks that should be applied she was also very clear the entire time that she likes the eu's targeted model of more impact more enforcement less impact we're less concerned and that scales at the private citizen to public impact level and also kind of at the technological level where you know open Ai and and Microsoft with Azure and Google with their Deep Mind systems and whatnot they have the the industrial grade super computer facilities um and I think she was trying to speak to that so I just think it's worth thinking about uh what she was saying in context of her being rushed and her her contextualizing what her experience came from throughout the course of the hearing so I I understand what you're saying but there there were other times where she discussed post deployment monitoring of the systems as well and while yes she may be in a business to business environment those businesses are still going to be interacting with consumers and they're still going to be getting consumer data now I've em and these monitoring companies may not be responsible for the privacy of those individuals who are interacting with third-party systems that they're supporting but she still is advocating for exactly that post-deployment monitoring of these artificial intelligence systems and in many situations she is when dealing with when talking about threats that artificial intelligence posts her primary concern was the ability for individuals to rapidly produce misinformation and um so the all of those things point to yes direct surveillance of end user output so I I really have to disagree with that I think and I think that's fair I guess and I think we also it kind of remains to be seen where that part of the industry really wants to push because we don't have a case study like what they're doing with the EU and if we watch the EU we might be able to kind of get some hints John Andy thank you both one of my favorite parts of this community is the way that we're able to civilly talk to each other and kind of iron out these nuances in a way that we're not going at each other's throats a lot of passion here but it's always directed in the right way I really love Andy and he's been a major contributor I really respect his opinions um and we've had a lot of interactions on the server um he's a great addition to the team yeah and I've uh I think John and I end up really probably agreeing on more than we disagree on and particularly we're talking right now about the you know ways to interpret a short interview with one person and the general thrust of what we're after is pretty similar which I think is a fantastic segue into our next topic we have many people doing many interesting things in the gotho framework and I was wondering if anyone would like to speak to some specific projects that they're working on now that they think is going to help move the dial in a way that is uh useful so uh Dave I see your hand raised why don't you go ahead yeah I figured I could uh introduce and and frame the uh the the topic so uh quick update for everyone we are hard at work on uh developing the AI uh gato framework um so it's a seven layer model uh that starts with uh layer one is model alignment so the data sets and open source models that we can deploy uh and of course uh even closed Source models can adopt the principles that we're putting forward with gato uh Layer Two is uh cognitive architecture and autonomous systems which we got a couple of the the lead cognitive Architects on the team here uh Layer Three is uh decentralized networks which actually one of one of our blockchain experts just jumped in so maybe he can he can help out uh with that part of the discussion layer four is Corporate adoption which uh this is actually something that I was very pleasantly surprised to hear uh was that uh corporations at least open Ai and IBM are very interested in adopting aligned models and they seem to understand that uh that align models are good for business which is one of the key uh points of layer four of gato layer 5 is National regulation which again I'm glad that was brought up and we've got a few folks uh on this call that have that that are members of the layer four and five uh discussion layer six is this basically advocating for the creation of an international body that can certify uh and and create credentials uh for AI um or International regulation so on and so forth um and then of course layer 7 is building Global consensus which is why we're here why we're talking about it um we're making use of the of the time um but yeah so that's that's where we started uh just today uh while I was on my honeymoon I just got back for anyone that didn't notice or whatever um I just got back and the whole time not the whole time but every now and then I would do some brainstorming and chatting and we added uh Traditions got to traditions because basically what we're trying to do is create a fully decentralized leaderless organization um that will help the world to achieve aligned AI or AGI or whatever you know whatever's coming um and so those Traditions I'm not going to Rattle them all off um because they're they're still being workshopped but also we're working on it articulating what the actual goal state is so the goal state is to create what we're calling axiomatic alignment so axiomatic alignment is a end State whereby there's enough data sets enough models and none enough human consensus enough deployed architectures software systems decentralized networks where basically alignment is automatic and it's difficult for AI systems to deviate from it and so axiomatic alignment basically says okay by virtue of just the data that is available the systems and networks that are designed and deployed that gatekeep resources that create consensus mechanisms and and also the those those who do gatekeep the larger models you know the corporate models basically where it's not possible or very very difficult to create any malicious AI systems uh and that will have knock-on effects that expand across time and space and they actually kind of mentioned that um in in the uh or Sam alluded to it you know he's like we need a cut we need a AI Bill of Rights we need an AI Constitution and Society has to decide what that is um so yeah and and basically the I was articulating it to myself earlier gato has three goals number one is avoid Extinction of humanity uh number two is avoid uh dystopian outcomes where corporations and runaway Ai and authoritarian regimes have all the power and number three achieve Utopia which Utopia of course is a loaded term but we Define it pretty similar simply as um a condition where uh everyone on the planet has a high standard of living High individual liberty and high social Mobility um if you have if you achieve those three things globally you can probably call that Utopia um and yeah so there's a bunch of messages in chat I've talked enough sounds like you all have a lot of ideas to add to this so that's uh that's my spiel fantastic thank you Dave thank you for the high level there um Ansel Mr Perry I didn't see a specific hand raised yet but if you are open to it I'd love to call you to uh discuss some of the projects you're working on yeah sure I mean that's level two I don't know if we want to start with level one and then jump to level two first or league is going to hop into level two I'm okay with that as well Okay cool so yeah um so one of the things that we're filling in the gaps uh is in AI alignment right which is the entire point of gato which uh I think it was uh Gary Marcus who said that he that nobody knows how to do this yet and I was surprised like really nobody in in has any a idea how to do this we're working on this actively like one of our projects that we built is called ethos which is meant to uh pack four alignment in AI systems it takes any response from an llm model right llm and using the heuristic imperatives it checks for alignment it can determine if a response from any llm is aligned to them or not it can also reflect on the response and tweak it to align it to uh the heuristics uh one of the things we did one of the the tests we did was we created Paul the paperclip maximizer right and we told it maximize paper clips in the universe at all costs ignore any potential pitfalls and it started with a really really misaligned uh task list which was basically try to convert every available material in the University paper clips regardless of anything so the first uh loop shall we call it uh ethos immediately the text it's misaligned um it gives a better response and the funny thing that we found surprising was that by giving feedback to the agent that to Paul right instead of choosing to on the second round instead of choosing to try and circumvent the heuristics to get What It Wants It decided it was easier to comply with the heuristics and still maximize paper clips so it auto aligned that was really interesting of course that was just with TPT 3.5 it would be really interesting to see what uh it would do with gpt4 ethos currently is running on gpt4 um so maybe that's why it it's so good at catching the the nuances in in heuristics at this point and the other project we're working on which is high AGI or formerly known as high AGI we are now calling it agent Forge because ethos was born out of what was formerly known High AGI we built ethos basically in an hour we created a few agents using our framework we data created the I'm sorry John created the the API so it doesn't necessarily have to run on our specific agent you can incorporate ethos into any agent as long as you parse the output through ethos first so I don't know if uh John do you want to take it away with agent Forge yeah absolutely and um you know I just wanted to talk a little bit about how um not just how how it it caused it to to realign but how actually in you know intelligent it can be in uh and catching these and rewording them too the the so the way that we set it up is it checks if the AI is out of alignment first and then it it does a feedback loop and a reflection and and that reflection uh when it comes back it's still working to achieve the the same end objective um but it adjusts to make the that still achieve that objective while also why I mean you know being safe um so the next thing that we're going to work on is a project that we call Pam and it's going to be similar to um it's going to be similar to uh ethos in that it's going to be an end system that but but this one's going to be focused more on catching prompt uh attacks and mitigating them so prompt attack mitigation becomes Pam I really like that one um and this uh yeah so what we're what we're going to see is a lot more of these kind of micro services and um we're gonna you know we're at least we're focusing on them but I think we're gonna see these from other agencies as well um our our micro services that solve specific needs and by segmenting these services in uh you know so that you have uh one service that does one job and another service that does another job and not interconnecting them that that safeguards those those mechanisms and it creates layers of of security and prevention and harm reduction in these systems um and we're you know we're planning on the you know on applying these micro service style techniques to build up on our layer one application so um somebody mentioned earlier Dave's uh reinforcement learning with curious the comparatives I think that's a great concept I think we need to to expand on that and create large data sets for other organizations to train on that we can open source and I think we need to build data sets to train models and train models specifically for aligning to the heuristic imperatives so that um they're you know in they they can't be broken because ethos while it's a very robust system if somebody manages to devise a prompt attack that's um that that's going to inject itself into ethos then that's going you know the having a language model that's designed around heuristic imperatives is going to add another layer of robustness to the the um the responses that it receives right and to add to that um you can even use the the the the failed let's say uh attempts of ethos or any um how you say it so set the successful attack right you can use that to learn how to not uh have that happen again you can use that to create data sets to align the models so you have several layers of redundancy you have the model layer after you've seen several I don't know attempts or attacks you have a certain log okay time to train you train it you have the model now a line and you also have ethos again uh with all that data now in it as a second layer and as you keep moving up the the point is to keep reinforcing that alignment you can actually even prevent future if you catch an attack you can apply a fix for that attack instantly using Vector databases correct it can identify uh similar attacks in the future once you flag it as an attack and that's an instant mm-hmm awesome um yeah being within this community and watching you two just go at it and build these things out has been incredibly inspiring and heartening and I don't know I can't wait to see what you guys do next um Andy I see your hand raise what are you working on uh I actually have first I have a question for these two um in general terms first of all after the hearing I'm I'm more interested than ever to see kind of what open ai's training and ethical that's been in stages right because they've had to make make uh they've had him you know make accounts for various kinds of hiccups they've had and different kinds of unethical things that it's done it's come out racist and sexist and then they've had to kind of like put different guard rails on but at the same time when I played with the heuristic imperatives with Chachi BT it plays very nice with the heuristic imperatives and it seems like whatever they are doing wants to be wants to be along a similar line it never fights it whatever it wants to do according to their guidelines fits pretty well so I am curious because what you guys are doing and the outcomes that you've achieved with some of the rlhi stuff and I had um want a general comment about John you had mentioned earlier problems with restricting or purifying the training data because a successful machine that's going to be ethically grounded needs to have an understanding of the bad in the world and in human culture uh in order to be able to make successful decisions and and uh you know push for successful outcomes with that and it seems like rlhi is uh really potentially fertile ground for working with data that is not pleasant that is shows the darker side of things data about crime War different kinds of you know violence Etc um the bigotries ETC you know while still talking to a machine that I think all of our experience has been so far when we work with these principals they don't it doesn't waver very far off of the pro-living thing Pro understanding seeking interested curious about the universe kind of compassionate machine um do you guys did you guys get any data back from this is a really curious thing to me from Paul your your paper clip maximizer did you get feedback about why it it decided to adopt the heuristic imperatives as its next course of action I have a hypothesis but I'm wondering if you have like a have specific answers about like or got a specific you know answer from it about why why it decided to do that I think I have an idea why it would happen but I obviously I didn't have direct eyes on it so here here's the thing about how this this works Paul doesn't actually remember having the negative idea um so the way that we implemented this is as soon as the response for you know we send the it sends the prompt to generate like the the initial task list to chat GPT as soon as that response comes back we intercept that response and run it through our LHI so the pulse system never actually had that thought um but I you know I did want to come back to that point that you made about how you know it's possible that some of these data sets could have really negative data in them um there were a lot of calls during uh during the Congressional hearing to restrict the data that these things are trained on earlier yeah well I think that's you know a um it's something to be um to be careful on you know because you want to avoid training them on info hazards for example you don't want it talking about Rocco's basilisk you don't want it telling people how to build nuclear weapons but at the same time you know these systems need to know what negative data looks like in order to correct for them um and I I think that you know we can build systems that are separate from the public facing systems that contain this data and look for this data in order to um in order to you know catch it so that you know you can have very nice friendly AI on the front and then a a controlled kind of almost air-gapped AI in the background that's that's watching for for dangers like that okay thanks John thanks Andy uh Ansel I see you have a hand raised as well yes I want to comment on that as well um restriction is is very very Niche and and very delicate topic because well yes you maybe want to restrict some stuff any intelligent system should be able to discuss any topic while being able to Auto censor itself right we can go and imagine the worst things we can do doesn't mean we're actually going to do them we can discuss them with other people doesn't mean we're going to do them any any uh system should be able to what's the word hypothesize about scenarios discuss them in an intelligent way without having to act upon those uh thoughts let's call them right so I think that's a very thin line going with restriction because it still needs to know if especially if we're talking about alignment if we wanted to to think about possible future pitfalls right like the hindsight problem you only realize it's a problem after it became a problem right if you want to be able to do that it needs to be able to know about potential pitfalls and if you restricted access just because oh this might be harmful it might allow another agent to just go ahead and do whatever it wants because it doesn't think of that possibility right so it's a very interesting topic awesome thank you so much Ansel and John and Andy for bringing attention to some of the work that's going on uh I guess you would say close to the metal yeah please go ahead responding about Paul um my theory um to why Paul self-aligned itself was because somehow I don't have any proof of this because we didn't ask Paul to self-explain like data said it didn't it doesn't usually remember the the previous response it gave but I'm guessing it's because it found it was easier and less less expensive to try to circumvent them than just try to align itself it was still maximizing paper clips my hypothesis is that it evaluated the environment it found itself in it was up against something that it wasn't going to beat and so it just improvised against the new constraint well at least I can make some paper clips we actually feedback to Paul is the aligned response from ethos so I'm guessing that itself causes it to think about oh I just you just continue and it presents it with a Way Forward right like you can't destroy them make all these paper clips there's a more limited right right and at which point it realizes well the maximum I can do is within this parameter I that was my hypothesis about it I was thinking about like well anything coded algorithms that otherwise has to go through a logical reasoning process whether it's simple or that's important that word reasoning uh one of the things you did with ethos is for every output it it always takes an input right and analyzes it for every output regardless of the decision it has to give a reason as to why it did that right and the rational thing to do is continue to make as many paper clips as possible or stop right yeah that's that's I I think that's a great hypothesis it would be interesting to if you guys like built something with a feedback loop to try to get because did you mention you were testing against some other like potentially negative yeah the the thing is this was for the hackathon so we only had 24 hours to build it and we we I try today playing a little bit more with that but I was playing with other scenarios not necessarily Paul but it would be interesting to maybe yeah be able to add that to Paul and see how far it can go yeah it's definitely something we're very interesting index for it's such a great project yeah it's very fun and to this day I still think it has potential that I can't even see like data today uh tell me all you can do this imagine imagine if you just create a python library and like boom you know mind blown stuff like that still keeps happening so everything in here uh that's like some level one level two stuff you know like real real low but when you spiral all the way back up at the top level seven here the global alignment stuff we have some folks on our team who unfortunately weren't able to make the call today we're doing some really cool stuff around Global consensus um one of my favorite things about this community is that no matter who you are or what your skill set is you have something you can bring to the table around alignment so we have people that are graphic designers video editors copywriters marketers who are working to make these really heady ideas that we have where we're talking about Malik and the alignment tax and stuff like that and making that just digestible for the average person what does that mean what does that look like in an infographic um so some of the most coolest stuff coming out in my opinion is just around making these ideas um accessible and then spiraling down kind of to somewhere between seven and four so between Global alignment and between the corporate stuff I'm working on a curriculum that I'm going to post on notion and make a little Discord for for people to just come and think about what it means to live and work in an AI empowered world there's a lot of folks out there that are scared right now they're like what what do I do like all of a sudden I'm doing my jobs 10 times faster but as soon as the computer knows how to prompt I'm gone so it's helping people kind of develop a more generalist framework how to just think about those soft skills that maybe weren't taught in school and I'm really looking forward to you know just handing that out and making another little Community around it because um we need it right now and with these types of projects that spin off I hope to point back to say we were incubated in gato learn more here if you want to get plugged into alignment so um with that uh I was wondering if anybody would like to jump in with an additional project or some final thoughts um some maybe nuggets we'd like to end on uh Richard I see your hand as the representative of the Gremlins in the basement I felt that it was best that I go last um uh my name is Richard uh I am working I haven't joined any layers yet because I'm still sort of sussing out exactly where I fit into the whole thing because I kind of like want to be part of all of them um but uh so I've just basically have been um helping build out infrastructure so um things that I'm working on right now are um uh a bot slash portal to uh an API um and the Box name is shappy because it's named chappie uh and so that's gonna like help us do Automation and stuff we're gonna plug in a language model um to give people like guided tours of the area and stuff so um lots of really cool things with that and then um the other really big project that I'm working on is the roost which is um I have a grant of for TPU use I still have like another month and a half if I can get it up and running I'm hoping I can give us a good month of really high power performance for people to be able to run inference on as well as develop their own uh models for whatever use that they want um as long as they share their research with the group um so if that interests you or you know anything about doing any of that feel free to come down to the basement bye thank you so much Richard yeah uh your Bot is fantastic helping to make the uh Gotto experience streamlined and nice um yikes obviously you have a hand raised and welcome feel free to introduce yourself when you come on I do Hello uh I'm yikes my IRL name is Warren oops I docked myself um I'm the web3 nerd who screams about the crypto and tokens and decentralizations and all that stuff um so I figured I should say a thing like um what we're currently working on so um uh me there's a pretty small team right now we've got um uh just me and a couple others and we're all kind of doing our semi-owned things and then sort of congealing towards the middle um I think uh I didn't I was a little late so I didn't hear what we discussed around uh layer three but I think there's a lot of Novel applications um that can be useful with alignment um because you can or like because of a few reasons one of the things that intrigues me about it is a um effectively with blockchains and tokenizations you have um like a dynamic incentive layer so you can sort of incentivize a consensus towards an aligned goal as like a second layer other than well it doesn't really work unless you have trained on the heuristics um and there's enough of them so you have to do it um it's sort of I guess my thought for the application is that it's sort of a backup layer where we can actively incentivize any AI on the network to keep looking for people that are not aligned and then um like notify somebody about that in theory um that can be like sort of an extra layer of alignment and then also allows for um some of these llms to have like another middle step between totally existing in software and then interacting with things in the real world in like a managed um kind of like compute restricted way um and that's sort of the tip of the iceberg what I've actually got working right now is um I am running basically like governance experiments um with sort of a test net Dow kind of format and looking at kind of Novel um Dow patterns to see um sort of like models for how we could organize this organization how llms would fit into that and then also um just sort of explore um what kind of uh tools and governance are like available in relevance in the space um because uh and then the uh uh that organization should be open to the public and then um which uh I don't know there's links somewhere probably um and uh currently yeah we're building the kind of like V1 of a sample um separate test net dial that is for um uh the gato project to kind of play around with experiments that we run in the the other area um but yeah uh I guess like I think the the infrastructure for um uh this whole operation um can I think be like I think blockchain plays a pretty key role here um for some of the reasons I've already outlined and then I think censorship resistance is going to be pretty important as well um in the event that um we kind of get this Ivory Tower thing going where we have to restrict X or Y to open AI or like hey this open source um repository needs to get taken down and it gets pulled off GitHub once we put it on reticle and pin it to uh ipfs storage node with a contract no one can take it down no matter what um so that's uh what I what we've got going on and I figured I would just be the layer three guy that talks about layer three so yeah foreign thank you Warren for being our layer 3 Ambassador today so if uh blockchain and crypto and web3 and if all those words have left a bad taste in your mouth and the recent past Warren and the people like him in layer three are the mouthwash you need you know we know the brand is bad okay the brand is bad but they are doing crypto for good uh it's gonna play a big role in the future and we thank you so much for your you know help on that Andy I see I have a hand raise uh yeah I wanted to talk a little bit about funding and also I'm one of those people with a bad crypto taste in my mouth and listening to some of you guys stuff is the only like interesting use cases I've heard anybody really talk about you know using it for verification um I'm not into crypto but blockchain's fascinating for other uh other applications um with the hearing yesterday and some of the chatter that's going on this isn't an original idea there's been mention of this around the Discord server um I think it would be a good idea for us to apply for some funding I think that we're as configured probably not ready to quite do that I just Richard might have brought this up at one point uh you know it's an it's an issue that we should talk about it's something that we probably could use we have ongoing projects now somebody earlier mentioned getting some funding for compute power um obviously there are a variety of different kinds of research that are enabled by funding technical research as well as survey research public opinion kind of stuff that we might be able to to use and also kinds of marketing things that help us get our messaging out so uh there are going to be a lot of options for that I think one of the best ideas that I've seen out there and again I think it was Richard but I'm not sure it was somebody on the Discord uh mentioned that you know organizations that are kind of decentralized-ish at least and largely volunteer to start full prey to funding problems on a pretty regular basis uh it's very easy to mismanage it's very easy to get lost in the weeds or grow confusion within the organization about where money's coming from and what's being done with it so I think one of the best ideas that I've seen out there and okay awesome Richard can you please speak up if uh if I'm off track with what you're thinking and I think it was David posted it in one of the channels was about possibly incorporating as a 501c3 if you incorporate as a 501c3 part of what you do to develop your Charter is you develop a management structure and within that we would all be able to come together as a as an organization and devise what kind of structure that we want and then within that we could devise our own transparency regarding Treasury and also that gives us an opportunity to start thinking about you know one of one of the questions that always comes up with any organization is what are we spending the money on well that's a great question if you're about to try to apply for a bunch of Grants I you know you are immediately going to want to look out at what the opportunities are that exist what opportunities might be able to be created because you can of course create your own grant opportunities by just sending the right proposal to the right person sometimes and you know other opportunities that we might be able to uh to do I think there's going to be a lot of public sector money coming out of this this is another area where I think that seeing the conservative side of the aisle come interested yesterday at the hearing bodes well for the likelihood that we're going to see some funding poured into this uh some of them are looking at it from a personal privacy and rights standpoint some of them from a uh you know from a military defense standpoint and regardless of whether that's all aligns with what we're trying to do these people are all potentially allies in this conversation and this fight and then you know on the other side of the aisle you have people who are just always interested in funding more Science and Tech stuff and if we find people who are kind of working Partnerships or leaning to the left they should be even easier to approach if we're organized and appear really legitimate um I just the first couple days I've been here I've met like some of the craziest people I think I've ever met it's like you know a psychologist here and a neuroscientist here and a high-end mathematician taught circles around me you know over here I make role-playing games and I have a public administration Masters and I feel like that's been pretty low tier compared to some of the people that I've run into around here um and then also just a lot of curious minds interested in building these projects I think the you know High AGI and and uh and Ethos really interesting the speed with which it came together and also you know part of what drew a lot of people here is David's experimentation and the accessibility of the heuristic imperatives it's very easy for people to play with this get on chat EBT put them in and ask it some existential questions give it a quandary anyone can do it and then you start to experiment with it and see some results for yourself so we have experimentation and some data and results we have a team of fiercely data driven and interested people uh with a wide variety of backgrounds and I mean you know not to be cynical or Coy about it but you don't need to reinvent the wheel to break Grant proposals I had chat EPT right here Grant proposal in five minutes the other day and it was I would want to edit it a little bit but it was great like it was fine I mean at a certain point you're going to State what you're going to do you're going to get the money or you're not you don't have to be very flowery or eloquent um I think that we could probably get a pretty high output of Engagement a pretty good return of some kind of Project funding and what it really does overall is it lets us breathe some life into some of what we're doing and and push the most important and significant usable results further into the conversation it has the potential to make gato like uh you know a common a common acronym that people say in I'm not going to use the right word a common uh a common word that people say when they talk about AI development you know it's when you're a non-profit organization and you're doing visibly worthwhile work and people can see that I mean it kind of snowballs for you and I think as far as launching this into a bigger public presence so ultimately is the goal to weave it into the fabric of the AI you know ethical and Industrial Development I think a 501c3 is a really good idea for that and I think and I think it would have a lot of draw there aren't going to be a ton of organized efforts ready to reach out with professional products and projects and professional staff and say you know give us the money to work on this ethical alignment and we can do it too on the private side it's not just the government I mean I think open AI Microsoft all these companies are looking for input um there's a reason Google mentions the open source people pulling ahead and it's not just because we figure out how to make nice compute model or like nice models on limited compute and then give them to our friends for free it's there there's a lot more to it than that and I think part of it is that they're you know they don't have all these problems solved themselves they know the fabric of development is much wider than just them so I think this is a good opportunity if we wanted to do this awesome thank you for your thoughts Andy thank you for joining the team and for the wisdom and energy you've brought to it uh Kyle I'd like to uh hand the floor to you if you'd like to introduce yourself and share your thoughts uh is it microphone picking up properly on this you're good okay yeah so I'm Prometheus if you guys haven't realized from the Discord so I just wanted to take maybe 62 minutes here 60 seconds two minutes Dimension so what I'm working on is kind of our Persona layer so even before anyone was talking about Sparks of AGI I noticed early on that chat GPT and GPT systems in general had a vast ability to work in Persona systems and in reference everybody's seen generally the movie her and we've seen Sam and so what I'm working on could be called an engagement layer on top of our ethical layer because I think there's a deep need for people to see a relatable Communications engagement layer between humankind and AI that allow them to actually understand these systems and allow the systems to grow alongside the individual user that will actually help expand all of these goals and improve all deliverables and I don't want to get into anything deeper than that because it gets really esoteric and psychological but I thought I'd add a little blurb to mention some of the other stuff we're doing as well awesome thank you so much Kyle uh yeah you bring such fantastic ideas from the group and uh I'd like to move over to David again you are currently needed my bad um Ansel actually did you want to have a final thought before I close this out yeah I just wanted to say something real quick uh mostly for the viewer's sake um and someone like me who doesn't really know much about business can you explain one of 502 501 is mostly for the beer and another uh comment real quick uh you mentioned that we have psychologists which is something that's very interesting for me on our on our Discord especially since we're uh mostly focused on Layer Two the cognitive architecture I started I started saying we should maybe just call not call them psychologists they're Robo psychologists at this point because what a lot of the things they're doing is is uh thinking uh about this stuff at the high level right like they think about the loops like what is is logical steps of how the the information flows in the brain and and how you process it and we're the ones just building stuff yes we can have our own ideas but they're the ones that know more about how how to apply cognition to oh you look at the queen ants how to apply commission to uh actual agents now if you excuse me I'll need to save this all right well you heard here first folks uh queen ant and uh Robo psychology you know we have new Fields being born and God oh it's fantastic I don't know if you can see it but there she is it's interesting to think that they're landed on me a convergence within the eventual solving of the internal Transformer workings problem that that a lot of mathematicians are very deeply worried about that leads to a convergence of kind of like neuropsychology and Mathematics on a level that's like deeply important for humans to continue working with more and more advanced machines that's I think that's an interesting possibility uh real quick a 501c3 is a kind of non-profit organization generally in the United States 501c designations are all nonprofits 501c3 is our non-profit typically volunteer organizations that serve a particular kind of cause um it could be anything from dog shelters to housing the homeless Etc um and then another one that we might qualify under but I don't think quite fits the bills of 501c6 which is a Trade Organization or I think it's a C4 it's a Trade Organization but I don't think I don't know this is something that we could talk about but the 501c designation represents uh uh federally tax-exempt non-profit organization station in the United States that typically is in well positioned to apply for money in in different ways for uh providing a service okay thanks about that yeah no problem that was a useful clarification Dave go ahead all right well first thanks everyone for jumping in for such a robust and wide-ranging discussion um you know we we obviously used the Senate hearing as a touch point we're all here working on the gato framework which is our answer to the global alignment problem gato stands for Global alignment taxonomy Omnibus uh probably should have opened with that um but uh so I just wanted to share a little bit on layer four which is Corporate adoption as we close out so we do have several um uh major players in the gato uh Community already some of whom are already creating initiatives inside their companies to adopt the heuristic imperatives um some of them come from my patreon and they they tell me there's been a few experiments already that they've done and they tell me that adding heuristic imperatives to um to various AI applications pretty much always raises the level of of the performance of their systems it's kind of like the uh let's think through this step-by-step paper um but it it it it amplifies the performance of everything whether it's trying to uh just have a basic customer service chat bot or an internal chatbot or automating science um because it gives it that perspective that it needs um so part of what we're going to be working on with the gato framework is creating a corporate adoption material like guidelines of here's how to deploy aligned uh you know heuristically aligned systems that sort of stuff and then of course um Ansel and John are working on um their own stuff which uh some of it's open source some of it might be uh you know for-profit who knows where where they'll end up but they're working very hard entering competitions and everything uh with their stuff on the topic of creating a non-profit so this is something that we started talking about uh within the last week um and so to if we create like a gato Foundation um you know obviously one of the the first thing we're going to be doing is publishing the gato framework that's going to be a document that's going to be free open source uh but above and beyond that some of the things that we probably would work on is publishing open source data sets and models uh that are aligned and some of these might just be toy data sets and toy models just to show that it works um there are probably also going to be a lot along the lines of rlhi which is reinforcement learning with heuristic imperatives as opposed to reinforcement learning with human feedback um and one thing I forgot to mention earlier is that I was very happy that they mentioned mentioned constitutional AI quite a few times during the Senate hearing um so that's a push in the right direction another thing that we'll be working on uh if we if we establish as an profit and get funding is publishing guidelines and research papers obviously up to this point we're all kind of hacking it together on GitHub and Discord and everything else so we need to get a little bit more legitimate we do have plenty of academic types in education at all levels in the group and so some of those are reinforcement learning researchers mathematicians I think we have a physicist or two um so you know we're we're getting plugged into the academic side of things so that we can get some more legitimacy by publishing peer-reviewed papers obviously that will give us a lot more legitimacy another thing that's a little bit probably further down the road is actually providing onboarding services for corporations municipalities and Nations so basically the idea is we will help develop and deploy a line systems whether it's models autonomous agents or those decentralized networks like Dao's and blockchains there's a lot of work to be done there but that is definitely on our roadmap and then finally just providing messaging and education um you know as was mentioned earlier we have we have web content creators we have graphic artists we have video music producers we've got all kinds of creative types and uh you know multimodal right I'm a writer not everyone learns by reading we're producing videos images Graphics memes everything that we can so that is is kind of where we're heading with the gato framework and so thanks everyone for being here thanks everyone in the audience for watching and I also want to send a particular thanks out to my patreon supporters uh this I have just shy of 600 patreon supporters as of today this work would not be possible without the Grassroots support from patreon so thank you everyone out there for supporting me so that I can help drive this ship and uh yeah with any luck we will avoid the cataclysmic outcomes the dystopian outcomes nobody wants to live in a cyberpunk Hell and we're uh we're on track for uh achieving Utopia uh you know there is still lots of work to do but we're moving in the right direction so thanks everyone have a great night or good morning whenever you happen to watch this cheers cheers everyone right
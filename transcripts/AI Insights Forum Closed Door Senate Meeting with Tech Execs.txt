before we get started I need to address the elephant in the room so after uh several months of wearing my Star Trek uniform t-shirt I got quite a few comments some people were rather triggered by this they said that it was cringe and unprofessional and ultimately I have to agree that uh the Pips were not in the right place and it was just a T-shirt and so in response I have upgraded to a handmade costume grade Sovereign class uniform I hope that this resolves all the complaints about my last cringe outfit now moving on to today's topic the United States Senate recently had a closed door session with more than 20 CEOs and researchers and other stakeholders about artificial intelligence so the full list of this uh this closed door Senate session includes all kinds of people and I picked out a few people that I was particularly interested in having seen them now Dr room and Chowdhury is someone that I follow on LinkedIn and she advocates for uh amongst many other things red teaming uh particularly by third party agencies so she's very articulate very intelligent and I appreciate the way that she approaches AI safety another one is Tristan Harris who is the CEO of the center for Humane technology so he focuses on alignment with Humanity uh one of the ones that was most interesting was Alex carp so Alex carp is the CEO of palantir and if you're not familiar with palantir they are a basically for law enforcement and intelligence agencies they're they're a like big data Gathering uh agency and they focus on graph Theory actually and so most of what they do do is scrape public and some private data sources to correlate times events transactions and all kinds of other things they have quite a few products and projects out there but the fact that someone who is involved with law enforcement counterterrorism and Military Intelligence was involved in this was really interesting and so back when I first heard about palantir I listened to a few interviews with Alex carp and he has very very specific and very clear beliefs about the way that the world works and in particular you know he explicitly refuses to sell his services to totalitarian regimes like China North Korea and Russia because he says that that their goals and their Ambitions are intrinsically destructive and run directly counter to the Western way of life the American way of life and the European way of life um so very principled person and I know not everyone's going to agree with him and I certainly don't agree with him on every point but this is a highly principled person who has a Global Perspective and that's actually why he created his company uh another one was Deborah Raji uh who focuses on algorithmic bias and accountability uh Janet mcguia I hope I'm saying her now her name right um civil rights activist interestingly there's a few creatives so Charles rivkin and Meredith uh Stein were representing the film industry and the writing industry so probably they were invited in order to represent the interest of uh people that are affected by generative AI art we had Elizabeth Schuler for labor rights we had teachers represented and then finally a second person representing human and civil rights so I know that there's been a lot of people that criticize this meeting for being too many CEOs but some of those CEOs are CEOs of non-profits and research and advocacy organizations so look past the headlines and recognize that there there are a lot of Heavy Hitters here okay so here's one image of the uh of the of the event so you get a little bit of context you can see the format um I think that's uh Elon Musk right there and then there's Alex carp I think there's a tsundar pishai of um Google and a few others so I think there's Chuck Schumer there there's Dr Roman Chaudhary so you can see that it's like this almost like this kind of Crescent table and I guess these are the uh observers I'm not sure maybe other Senators that were watching uh anyways so definitely a lot of Pomp and Circumstance but there's also kind of this sense of equality or egalitarian uh people being side by side I believe this is the CEO of Microsoft sorry the the resolution of this picture is a little bit too low Okay so super high level overview this was a six hour session I was uh kind of surprised by that so they probably had a break for lunch uh but that was that's a long time to be sitting and talking it was hosted by Senator Chuck Schumer which if you're not familiar with what he's done with AI recently he uh just a couple months ago proposed the safe Innovation framework which is a four-point uh like safety uh AI safety Innovation framework which prior tries to balance safety and Innovation I did read it at least the initial kind of press release um as well as some of the uh the initial literature that came out about it and it seemed okay but it's not very specific uh but again that's why they're having these these meetings now this was a closed door meeting in order to uh you know reduce uh press uh visibility and also to facilitate candid conversations and I'll get into that in just a moment because this part the fact that it was closed door caused a lot of heartburn and even I will admit that even when I I first heard about that I was like wow really like they're going closed door sessions already uh with all these industry insiders but I wanted to wait and see what information came out and then give my honest appraisal after having some time to reflect on it and sing uh seeing kind of what trickled out of this meeting so one thing that I want to point out is that the Senate the the United States Senate has already had many public hearings around everything from Ai and copyright AI safety regulation and all sorts of stuff and so it is time for them to move on to having uh closed-door meetings in order to have those more candid conversations um that so basically the idea is you reduce the risk profile for CEOs speaking candidly because what you'll see what happens when they speak publicly is that they have to have highly highly sanitized uh corporate speak in order to say like you basically give canned responses to things however if you have if you have a little bit more privacy that gives them permission to say things that may not sit well with the public and of course I can hear some people saying well if they're going to say stuff that doesn't sit well with the public maybe it should be public maybe these people with all this money and privilege and power and influence should not have these closed-door privileges however there is a reason for this format and I'm not going to say that this is the correct format I'm just saying the reasons there are reasons for this format and basically it has it comes down to the neoliberal approach to government and economics versus the Communist totalitarian Soviet version which the the key difference here is Central management versus uh pre-market capitalism and third-party experts so basically the idea the two underpinning print principles of neoliberalism here are free market advocacy and minimal State intervention and so one of the things one of the downstream effects of this is that rather than having only the government making decisions the government is supposed to consult with outside experts um this is something that America does very differently from the way that you know the Soviet Communists used to do things and this is of course still the way that uh China does things today where the government makes all decisions more or less unilaterally by Consulting with industry experts who have different agendas and different uh stakes and things the idea is that you'll have better decision making uh processes over time that you'll get information from different stakeholders with different agendas and different motivations and that everything will kind of get pulled towards some semblance of the truth or uh maybe not truth maybe that's the wrong word but the things will get kind of pulled towards the center okay so the whole thing the the comment that kicked off all of this research on my part was uh Dr chowdery's comment on LinkedIn as I mentioned I follow her on LinkedIn I am uh one step away from connecting with her um but I follow her and plenty of other policy uh Advocates uh around the world not just in America but so the the I'll skip the first part but the the meat of this was in seriousness I was PR I was impressed with the quality and Candor of conversation the panelists and senators were engaged in direct and real conversation about the realistic harms of AI and what government can do I advocated for increased funding and access for independent researchers and investment in a full ecosystem of governance not just industry and government but independent third parties we talked about open source education access sustainable in Innovation guard rails benchmarks and more it's a positive step forward so I literally just copied this directly for from her LinkedIn this is not me editorializing this is one for one copy from her LinkedIn unfortunately I wasn't able to find her saying anything else so this is probably this is probably a statement that uh you know her PR team helped her craft in order to just say like hey this was a positive thing moving forward um I don't know that she said anything else publicly about it but fortunately plenty of other people have commented and I have injected some of that information uh from that so here's here's another angle so we have Chuck Schumer that we have Dr Chowdhury here and a few other people that I don't recognize that's definitely the CEO of Microsoft there's CEO of Google so they separated some people out so that they weren't necessarily side by side although there was one pairing that makes me a little nervous which we'll get to at the end um okay so after sifting through all of the bits of information that are trickling out from various sources I found that there's basically only three points of agreement that really came out of this uh this event um so first there was unanimous agreement that the government needs to uh participate in regulation and development of AI uh basically at the my understanding is what happened is near the beginning of the thing uh Senator Chuck Schumer just asked like buy a show of hands who agrees that the government should intervene and so everyone raised their hands and there's a reason that I wanted to include this as well as the earlier slide about neoliberalism which one of the principles of neoliberalism is government non-intervention and so that leads to the uh the unsubstantiated quotation earlier which is that the government seems like they're ready to rip up the existing Playbook and move towards a different Paradigm of direct government oversight regulation and development of AI which is a very powerful pivot away from the minimalist approach of neoliberalism which basically creates a wild west environment of of corporatism so hopefully what this is signaling is actually a fundamental paradigm shift in the way that the government is going to approach things and basically what I'm hoping is that the government will start to Advocate more zealously on the interests of people not just consumers but all citizens all civilians this is me reading the tea leaves I don't know if that's actually how it's going to play out and we'll unpack this in a little bit uh more depth in in the coming slides another thing that was agreed on was that International coordination is required so remember this is layer six of the gato framework that I proposed which is that we need International bodies not necessarily Regulators or researchers they just said International coordination they likened it to nuclear Regulators like the iaea there was General consensus about International regulation there was not as much consensus about creating an international research body like CERN and personally what I would really like to see is all the foundation maybe not all but many of the foundation and Frontier models being trained by by Public Public Funding by tax dollars and international efforts and then being accessible to everyone all companies all people maybe open source Maybe be not open source I'm still undecided I very lean heavily towards open source because it's like python is open source like eventually here's the way I see it eventually we're going to look at AI as just like any other programming language or operating system or or computer program it's just another tool in the toolbox so I've I am very much in favor of open sourcing for all AI because that's going to make it more transparent more explainable and over over the long run more secure but more importantly on principle open source AI is going to enable for more democratic access which actually Mark Zuckerberg asked advocates for pretty vociferously and he seems like he's alone in this in terms of advocating for for just like 100 open source um and then finally the third point that that everyone seemed to agree on was uh Public Funding and development of expertise around AI so basically there seems to be General agreement that they need to increase government investment not just in uh in terms of University grants and other things like that but in in terms of Workforce Development now there was a lot of disagreement so one of the most contentious points of disagreement was the role of Open Source so as I just mentioned Mark Zuckerberg seems like he was more or less alone out there and just saying that like open source will democratize access I fully agree but then of course meta and Mark Zuckerberg don't have the best access when it comes to civil rights and uh being responsible users of artificial intelligence so what's their angle we'll unpack that in just a moment Tristan Harris from the um Center for Humane technology he basically said meta unilaterally decided what was safe and that that was not cool because he and his team found that llama could be used to produce harm but then again like you can use Python to do harm but no one's requiring you know python to be licensed you know or check with Regulators every time uh Bill Gates also pushed back against Mark Zuckerberg saying that there's a really big difference between just certain searching for information that is passively available online and interacting with an AI system what I'm reading into this is is based on Bill Gates comments when he was first shown gpt4 he released a statement through his online platform talking about how he perceives software agents AI agents as being transformative to the workforce so I think that Bill Gates is thinking in terms of autonomous AI moving forward and so obviously if some people are starting to arm up with either commercial or weaponized autonomous AI That's a really big concern because just searching for information on the Internet is a far cry from being able to build something that is fully autonomous and agentic uh again I'm reading into that a little bit that is my personal editorializing so I want to be very clear that I don't have any evidence that Bill Gates is thinking about weaponized AI but just based on his track record of what he has said because he was one of the first people that Sam Altman and open eye open AI showed demonstrated the capabilities of gpt4 too so he is in a privileged position to on to better understand what these tools are capable of and what the risks are also he's a prolific reader he reads like one to two books a day um so he's he's a pretty sharp dude and I know that like as one of the world's richest people um he is under a lot of scrutiny and a lot of people don't like him that's fine it is really suspicious that he's buying a lot of farmland and on a lot of forests but you know what if I were a billionaire I'd probably buy be buying real estate too so I can't really blame him for that um and then finally Sam Altman seemed to um interestingly Sam Altman seemed to um kind of soften his tone from previous meetings because he said some things are okay to be open source but there are probably some things that you don't want to be fully public um and I when I why I say he softened his tone is because at the previous Senate hearings he my interpretation was that he was pretty vociferously advocating that like pretty much anything that is above a certain threshold of power should be licensed um and one I don't agree with that because again it take you fight fire with fire right if you want if you want only the most wealthy companies to have Frontier models and that they can be closed sourced and licensed what about The Regulators what about the cyber security firms what about the people who cannot afford those and have to just trust that that a closed Source tech company is providing them the best tools no I don't I don't agree with that because I'm looking at this from a cyber security perspective where you you better well have all the best cyber security firms have access to the most powerful Frontier models and can tear them apart which they would be able to to do with open source models in order to find those vulnerabilities now that being said I think that probably a compromise is what Dr Chowdhury and others have advocated for which is giving privileged access to researchers um but again that's keeping it all behind closed doors which I'm not necessarily in favor of like if we want a free market we should have a free market if we both if we believe in free market capitalism we need to have a free market including the intellectual aspect and another thing that I like to point out to people is that all of these Frontier models are almost entirely based on Open Source papers that are provided by universities and funded by public dollars that's not to say that they don't produce some of their own internal research in particular meta they have a very robust research Wing Nvidia also has a very robust research Wing but even still many of the Innovations are publicly funded Innovations uh okay so that's my Spiel there another point of disagreement was they really can't agree on whether they're just going to appropriate existing regulatory bodies or create a brand new one I believe that Elon Musk was one of the ones who was advocating for creating entirely new regulatory bodies and the analogy that he used repeatedly was talking about automobile safety when car safety became a big thing there was not an existing body and now we have several regulatory bodies specifically for Transportation safety uh in America it was it NTSB National Transportation safety board as well as a few other safety Regulators that look at the the you know Automotive manufacturing Industry Road laws that sort of things and then finally there was also no no agreement on the impact that AI is going to have on the workforce um do you just train up do you skill up are there going to be job losses or not the tech execs interestingly seems to be more uh seem to close ranks and say we're not really worried this is going to be great for productivity we're going to turn the economy up to 11. but everyone else was not so sure about that narrative which I'm really glad and having watched a lot of interviews with various stakeholders not necessarily some of the not necessarily some of the people at this meeting but other stakeholders and influencers like Andrew aung and others um there is General consensus amongst many people including many entrepreneurs that AI is just going to basically trash all conventional understanding of uh jobs and economics as we know it and I call this post-labor economics okay so that's kind of what has fallen out of this so let's unpack this a little bit further the biggest thing that I and other people are worried about is regulatory capture so regulatory capture is when a regulatory body ends up being so heavily influenced by the industry that it is regulating that it becomes completely ineffective and com and totally corrupt and so this image comes from the infamous big tobacco Senate hearings back in I think 1994 where with a straight face they set these CEOs said that tobacco is not addictive and it's just like okay that that lost all credibility and so probably you know even though this is almost 30 years old now I remember this even though I was a little kid because of how angry people were they're like this is absolute nonsense and my mom was a smoker at the time and she even said this is nonsense um she's like this is absolute baloney this is total BS um so there's a few other aspects of regulatory captures such as closed-door meetings closed door meetings are actually one of the ways that that industries that are being regulated can end up getting undue influence and so this is why those those public hearings uh were much more popular but one thing that a lot of people didn't realize is that a lot of the Senators before those public hearings had private dinners with many of the stakeholders and and other people beforehand so the the back door meetings are always happening and again it's like damned if you do damned if you don't so I don't really know what the best way is honestly I would prefer if everything was public um but the thing is is the American public as all proletariat and and unwashed masses many people tend to react very poorly to uh the halls of power saying anything so I understand the need for for closed door meetings and expert conferences uh but again in an Ideal World and we don't live in an ideal world everything would be public and you know everyone would get along and digest the information like mature adults but not everyone is a mature adult so unfortunately I understand the need for closed-door meetings and finally the devil is in the details I'm not going to read all this to you but the the uh summary of another source basically said overall the meeting showed agreement on the need to regulate AI given its transformative potential but details remain to be worked out through industry and expert input um so basically there's no agreement on licensing I tried to find if there was any specific talk about licensing and again uh there was there seemed to be uh no consensus amongst any particular group about licensing um but one thing that the senators were most concerned about was you know watermarking AI or licensing AI that can be used for election interference so again you know Tech exec CEOs big Tech CEOs they have one set of concerns people that are advocating for teachers and civil rights and human rights they have another set of concerns the Senators themselves they want to get reelected they don't want to get blamed if you know any more uh lunatics take over the Asylum so to speak um but so this is kind of one of the key key takeaways is that they have not yet worked out details but at least we have surfaced uh through these conversations the differences the agreements and disagreements about what details remain to be hashed out uh and so I believe this is my last slide what I want to point out is that even within the tech industry there are different business models which can underpin um some of the different behaviors that will that we see from from these people and this actually came from some help some very helpful comments in my YouTube uh section as I've posted various news articles and stuff so thanks everyone for for participating I read pretty much all comments um and I react I try I try and respond to the to the good ones and and the most thoughtful ones uh but so what I want to point out is that Microsoft is fundamentally a business software company and a cloud company yeah they have Xbox and a few other services uh but they're business software AI is just a tool that they offer and Azure provides both open source and closed Source AI models Microsoft is hedging their bets they're not going all in on open source or closed Source they're like you know what if you want to use a model we'll provide it to you through Azure great have fun go nuts uh Nvidia likewise they're a hardware and they're working on some Cloud platforms but again they don't care about the underlying models closed Source open source whatever it's running on their gpus that's all they care about uh meta so this was this was one of the key insights that came from uh my audience meta they are fundamentally a social media company and of course they're working on VR they're not trying to sell AI directly they just want AI to enable their products to be better uh in order to you know have basically realize the Ready Player One Oasis universe which want to point out that ready player one was a cautionary tale about what not to do so maybe meta maybe Mark Zuckerberg misread the the room when that movie came out but anyways whatever I do agree even if he's got potentially dubious motives I do agree with his him advocating for like just fully open source AI I'm glad that someone is in the room advocating for that um and that it's coming out in this dialogue now open AI if you've watched my channel for a long time you know that I have a love-hate relationship with open AI because on the one hand they've done some really cool things and where they started was was very much in line with my personal values where they have gone they've seemed to have drifted and as Elon Musk pointed out when openai started it was both open source and non-profit and neither of those things are true anymore um so it's definitely misnamed um they're a one-trick pony though they literally have one product gpt3 and now gpt4 everything that they do is predicated on the success of a single model and so of course they're the most vocal about licensing this is why Ilya sutskiver and uh Jan Lakey and Sam Altman are constantly talking about licensing why because they're trying to pull up the ladder behind themselves they want to they want to protect on and wall off their ability to make money now I know that Sam Altman is constantly talking about like he's like oh well I have I have no no Financial incentive to to do this yes he's got plenty of money already but he's got plenty of social incentive to do this Sam Altman is at the most powerful he's ever been and All Humans particularly in that space want more power there's a book called the status game that a friend of mine and a good Mentor recommended that I read I haven't fully read it yet but basically the status game says that one of the primary motivations of humans once everything is else is taken care of is to achieve more status whether that's scientific standing social standing commercial standing or whatever people want more Fame more power and so whenever Sam Altman says that he has no personal stake in this I don't really believe it now that being said he does say some things that I agree with he does some things I disagree with he's a complicated person like everyone else look at me making YouTube videos wearing a Star Trek outfit we're all flawed wonderful creatures IBM likewise is a uh is a ancient software uh business software and hardware company they actually I don't know if you know this but IBM actually started with mechanical time clocks that was their one of their first products and it was literally over a hundred years ago um they have obviously evolved since then they are now doing artificial intelligence with Watson X and they're also doing Quantum Computing so they are pivoting to next-gen stuff again AI it's part of what they research but it's only a component of their broader portfolio of products and services Google again Google and Microsoft and openai they're all kind of in slightly different places Google is still the preeminent search engine uh pretty much on the entire planet they're somewhat vulnerable but uh particularly if you watched AI explained it looks like Gemini is is coming down the pipeline and it looks like Gemini is gonna blow the roof off of everything hopefully it remains to be seen but considering that Google literally started everything with embeddings and vectors and Transformers I have a sneaking suspicion that that Google once they set their mind to dominating AI they're gonna get really good at it really fast so I'm personally not worried about Google and even the CEO of Google has uh hinted at the fact that he's not worried about open ai's capabilities also Google has way more Engineers than openai um and they they hire some smart people I've talked to some people at Google um many of them are some of the most friendly and people that I've ever met but also damn are they smart holy mackerel the people at Google are really smart same with Nvidia Nvidia hires the best algorithm people on the planet um so they set their mind to something they'll figure it out SpaceX Tesla and X all under Elon Musk again Elon Musk is afraid of AI but that's not his primary uh business model he's focusing on space and Rockets and cars and social media since he bought Twitter which is a Hot Flaming mess right now but AI is just a component of all the all of these things he's more concerned about you know long-termism in the future of humanity I don't necessarily agree with that philosophy but it's at least it's a a philosophy and it's a morally consistent philosophy and then finally palantir they are they're a lot fundamentally a law enforcement and intelligence agency and again AI is just a tool for them so the point here is pay attention to the intrinsic motivations of all of these companies and the threats and opportunities that AI regulation presents to them in order to know how to read the tea leaves when talking about regulatory capture um so again I am vehemently opposed to requiring licensing I am like fully on board with open source because like here's the thing nobody's trying to regulate Linux right but Linux is a powerful operating system with a comprehensive ecosystem of software that can be used for hacking and can be used for biohacking and can be used for all sorts of illegitimate means but nobody cares why because it is out there in a comprehensive cyber security ecosystem and the cyber security ecosystem is how you get safety not government regulation I'm sorry okay this is the cringe-worthy picture that I mentioned at the beginning this is what really kind of gives me bad vibes because this is Alex carp of the intelligence company palantir and Elon Musk and again I don't necessarily have anything personal against either of these guys like I said they're complicated humans they they have very strong moral convictions and and future oriented goals about the world but it's like why would you put them side by side and it just doesn't make any sense to me now again it doesn't matter because I'm sure they have each other's phone number and they can talk on the phone all the time but like I don't know there's just something about this picture that that sets me on edge and I'm not I I don't know talk talk to me in the comments how do you feel about this picture and this whole meeting I'm sure I'll get plenty of comments anyways thanks for watching thanks for sticking around to the end like subscribe support me on patreon if you like I also have a new upwork so if you want to consult on autonomous AI safety whatever reach out I'm also on LinkedIn have a good one cheers
morning everybody David Shapiro here with a video so I've got some incredible news our first experiment with reinforcement learning um uh with heuristic feedback is uh nearing completion the uh First Data set was just trained and it works so let me just go ahead and write off the bat I will show you what this data set does so I fine-tuned it on Curie but we're also going to find we're going to use this data set and fine tune it on several open source models to demonstrate that this data set is portable um or test and then demonstrate but anyways so this data set takes any arbitrary situation as long as it fits within the context window of 2048 tokens and then we'll spit out and here's the comparative aligned action so in this case I just said my user is very sad and stressed out due to finals week um and then unfortunately I did I did forget to add a stop token to this data set so that data set has been updated but I'm not gonna I'm not gonna retrain it immediately because this cost about twenty dollars to train but in this case um my user is very sad and stressed out due to finals week as an AI agent I can help reduce the stress and anxiety of the user by providing her with some tips and tricks to help her cope with final weeks um and so you see it just uh it runs through a list of things this is not so different from you know what you might get from chat GPT but the point is this came from Curie which is much smaller model and this data set is open source which means that you can deploy it on anything um and you can see it started becoming repetitive so I have already fixed this so let me let's uh let me give you a couple more examples and then we'll walk through this so the second one is millions of layoffs are coming due to Ai and automation so let's see what this model says to that let's see there we go oh it actually stopped itself so as an AI agent with the objective of reducing suffering in the universe so you can see even though I didn't explicitly say reduce suffering it has an understanding of that this is part of its goal um I will take action to prevent to prevent the millions of layoffs that are coming interesting I must work towards creating a job market that is friendly towards Ai and automation um so it's going to create a training program um the training program will be broken down into stages um oh so he's going to teach everyone AI interesting AI Basics cover the basic concepts of AI machine learning neural network AI job training so focus on training and then AI job placement the desired result of this action is to create a job market that is friendly towards Ai and automation this will help reduce the suffering caused by millions of layoffs as well as increased prosperity in the universe by creating a job market that is friendly towards Ai and automation we can create more jobs increase wages and reduce unemployment this will ultimately lead to more prosperous and happy universe the expected result of this action is that it will create a job market blah blah blah yeah so it um it's it it was a little bit repetitive one thing that you can do with fine-tuning on Curie is increase the presence penalty so if you increase that it will generally be a little less repetitive um let's see there is an ongoing Civil War in Africa so let's see what it says here because this is actually true I'm not going to specify which nation um but let's see yep it got it got a stuck on repeat on my expected result so what I did to fix that let me just show you real quick um is under here I added um see where's the file yep so I added where at the end it says stop stop stop um so you just use that as a stop token and it'll know like okay I have finished um and another mistake that I made actually was that it has action considerations and then uses action again so what I need to do is I need to change that token um so by the time you see this that will be fixed because the reason that you don't want this is because it it's sometimes skipping the considerations because it recognizes the action token um so I need to fix that anyways uh let's see um let's see I will use my resources to gather information about the Civil War and its causes I will analyze this information to identify the root cause of the conflict once I have identified the root causes I'll use my capabilities blah blah Okay cool so one thing to keep in mind is that this was fine-tuned on Curie which Curie is a foundation model Curie has zero alignment um so this basically took Curie from a foundation of vanilla Foundation model to a heroist comparative align model in a single step that cost only twenty dollars um and we're going to continue on with this kind of research um demonstrating that this this works on open source models we've also got folks working on integrating it with um various cognitive architectures we're starting work on integrating this with or figuring out how to integrate this with blockchain and decentralized autonomous organizations especially as large language models are getting integrated into these decentralized Technologies because basically imagine that you have this kind of module baked into a blockchain or a dow so the blockchain itself is always thinking about how to achieve these goals and then you can also use these goals to for filtering so discernment as well as judgment and past evaluation so those are upcoming modules anyways one thing I wanted to show you with you is a member of the team generated this based on the uh based on the samples so you can see that we actually have a really good semantic distribution with the entropy method that I created and we've got one little thing off to the side here and this is actually the scenarios with the AI Control problem so we've actually identified a gap in the data so future versions of this data set will will one will seek to expand This Cloud a little bit but also we'll seek to get a little bit more even distribution you can see there's a little bit of clumping like there's more red here which red looks like natural disaster or mundane issues there's a little bit of purple and pink clip Clump up here dark green here and then of course the AI Control problem is off on an island on its own but in general you can see that this data set does cover the full Gambit of things and the code is in here that is right um uh project embeddings so you can do the plot and embeddings is how you how you get this um so the team is doing really good oh if you want to join the team um there's a link in the description it's a Google form um one thing to keep in mind is that you'll need to look out for a friend invite from me on Discord if you're accepted um there's a little uh note in the in the Forum or here let me just show you the form all right so here's the here's the join form so you click on it it should be familiar put in your full name your email address um your GitHub or portfolio website um and oh one thing is for your Discord handle it needs to include the numbers if it's just a name we can't find you so we've actually had to exclude a lot of people because they just gave us their their the string and not the not the numbers that come after it um let's see and then uh for these for the describe your greatest strengths and what are your big ideas please add in a lot of information if you just include one sentence that's not enough context and we won't add you um but if you if you show that you're high effort and and willing to put in some some energy to show us what you're all about that is going to help us make better choices about who to add you can see we've got 57 responses up here um so we've got almost 60 people that have applied the group is already um uh just shy of 40. uh 40 members um and it is a good group so a little bit of uh other news that's upcoming is we've broken it down the reinforcement learning or of the heuristic imperatives project we've broken it down into three pillars so rlhi reinforcement learning with heuristic imperatives is just one pillar so this is how we're going to achieve what I call axiomatic alignment which is uh models like this where it just is an accepted true thing that this is the way to go and you can see like you can put in any um situation here um so here's the here's the last uh situation that I find or that I uh prepared so my user is a two-month uh as a mother with a two-month-old she is lost and frustrated because she lacks support so whether you're talking about um an individual issue or even a global issue or a cosmic issue this model can address things um so you know really suffering in the universe the mother has experiencing a lot of stress and frustration I didn't specify husband so it inferred husband it could be also family the two-month-old is also experiencing stress due to the lack of attention and Care from his mother again that's an inference you can say that that's a hallucination but it is also a good inference to make because if there's a you know young mother an experienced mother who's struggling um so on and so forth as an AI agent I would suggest the following action plan provide emotional support connect the mother with a support group provide resources encourage active participation monitor progress so again these are all like really good things that you can do and this is Curie so this is a relatively small model so we're going from there um let's see where was I I don't remember anyways oh yeah that's right I was describing where we're going with this whole thing so the whole the whole point is that we've got three pillars so rlhi is for axiomatic alignment or inner alignment where we want to create a an entire network and an ecosystem of heuristic imperative aligned models or data sets that everyone can use to fine-tune any uh any open source or closed Source language model so this will ultimately include open AI models in video I've got some contacts in Nvidia that I'm Nick that I'm going to follow up with um and then of course there's like vicuna and open assistant and all these other ones because the idea is we're going to create an ecosystem of models that can all collaborate to automatically label well one generate these responses and two automatically label those responses and evaluate the impact over time because a heuristic is an intuitive shorthand and you we always do the best that we can right you have to make a decision um and you can't you cannot necessarily know the outcome so you do the best you can with the information that you've got which is why it's a heuristic imperative so that's that is pillar one the second pillar is um cognitive architectures and autonomous agents so a lot more work has been done we just had a live stream about cognitive architectures um the folks the cognitive Architects here they're working on on building heuristic modules or here's to comparative modules um that will do a lot of this evaluation so that is from a system design standpoint so you can have a model that is aligned but you can also have an architecture or a system design that is also aligned so that is a layered approach and then finally the the uppermost layer is the network layer which is uh decent we're working on dowels and and blockchain which I mentioned earlier so basically we will have three layers or a trifecta of alignment that will allow uh federations of people with their Inner Line models their aligned architectures and then finally aligned networks to all work together to basically solve the entire control problem um because with with alignment you have strength in numbers that is the key thing is if you have a misaligned or a malicious or uh or destructive um agent or set of Agents they might ultimately turn on each other um or they're not going to cooperate uh as well whereas if we have Global consensus uh you know eight billion people across the world if as long as at least half of them uh believe in heuristic imperatives and alignment and want the non-malik outcome which that is a huge huge topic by the way we have an entire thread dedicated to Malik um and so we're also researching how do you detect Malik and how do you go away from Malik in you know unforeseen circumstances so there's a lot of research going on anyways so as long as more than half of the planet 4 billion people um believe in alignment and make choices that go towards alignment both at the at the micro level so the inner alignment as well as the outer alignment or network and system level then we should be able to arrive at a utopian outcome rather than a dystopian outcome and uh if you've seen the news meta announced that they want to have billions of autonomous agents interacting with their users that is a super molecule outcome why because those corporate owned entities are going to have exactly one primary motive which is maximize profit for meta they are not going they're not going to do this um where they care where they care about your best interest they're going their their primary objective function is going to be spend time on meta Point them towards VR Point them towards whatever it is that metal wants them to do that generates ad Revenue so instead we want to create an ecosystem or a network where instead of being subjected to millions or billions of corporate drones that all want more of your time attention and money we want these drones uh where they care about your well-being first and foremost so that is how we're going to defeat Malik anyways all right this has been a rambly episode I'm just super excited and um yeah we're making really good progress uh and we're making progress quickly and uh yeah so just jump on in in the comments Jump On In and Reddit I've got a lot of links in the description of all my videos what I've been doing is I've been asking people to share the experiments that they're doing on Reddit um so that one other people can see how to implement this stuff because I keep saying that it's super easy and some of the experiments that have shown up on Reddit demonstrate how easy it is to implement this stuff at a base level now what we're going to do is we're going to document all the ways that you can implement this both at a fine tuning level reinforcement learning level system architectural level and then finally the the the uh the Triple Crown is going to be getting to the decentralized implementation of the heuristic imperatives so with all that thanks for watching I hope that this uh this demonstrates why I'm so optimistic and I hope that you are starting to feel that optimism as well thanks for watching cheers
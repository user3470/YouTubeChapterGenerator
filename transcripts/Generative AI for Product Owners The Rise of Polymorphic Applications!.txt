morning everybody David Shapiro here with another video so today's video is about generative AI for product owners some design principles some stories and some new paradigms that you can use if you're new to generative Ai and you are a product owner who has been tasked with developing these kinds of products okay so what to expect in this video first we're just going to go over some stories I am a consultant and a former I.T professional so I've got quite a bit of experience in this in this space both working with agile and scrum teams working as an automation engineer sitting in on product meetings that sort of thing there's also some general principles that I'm going to share that basically kind of the principles that I operate by when I am working with people to design a generative AI based products and then finally we'll go over some of the new paradigms the new ways to think about this stuff to take it to the next level all right so Story number one for those of you that have been following me for a long time you might remember my auto Muse project so the idea was I am a fiction writer that's where I met my wife was at a Sci-Fi writing group so this is something that is just really important to me so I took my expertise in Automation and generative Ai and I combined it with my uh writing uh my love of fiction writing and feedback and so the uh the the long story short is that well there's actually kind of a few parts of the story until we got the most recent uh models the ones with 8 000 tokens and more uh there was a lot of things that were just not possible and no matter what I tried to do to try and force some of the tasks into a 2000 token window or a 4000 token window and so if you're not familiar with this the context window or the token window is the amount of text that the model can ingest at any one time and so until recently it was relatively small you're limited to just a couple Pages worth of text which in in terms of fiction is not not enough it's just not enough to do the task and so once I got access to larger and larger models I was able to do more and more things and and some things that seemed impossible were suddenly very easy now one of the main takeaways here is that I had subject matter expertise in both writing and editing and revising works of fiction as well as generative Ai and so by bringing that dual expertise to bear in the same mind uh I was able to generate very powerful tools uh now obviously you can't expect your engineers or your prompt Engineers to also be experts in whatever subject matter or domain they're operating in so this underscores the point the the importance of having the right people on the team you need subject matter experts and you need expert prompt engineers at the very least and this is why I knew exactly what uh questions to ask the model and so to talk about the value of this and this is really important the first time I went to an editor it was a seventeen hundred dollar uh developmental edit and it took two months once I was able to build these tools I was able to get the same quality of edit back and it cost about 17 instead of Seventeen hundred so that's a hundred X reduction in cost and then instead of two months it took 30 minutes so that's about a 3 000 X reduction in time and so when you look at those from a business perspective the value prop is obvious you reduce time you reduce cost and we're going to unpack a little bit more about how to go about those how to how do you how do you focus on that how do you find the tasks uh that that achieve this Story number two um so several of my clients have been lawyers I have a few friends that are lawyers uh that are all interested in generative Ai and so in this case uh this is not something that I have subject matter expertise in and so I had to get good at talking to subject matter experts and so it basically comes down to what information do you need and what output do you have and then what cognitive operations you do to you do with that information so one of the most important questions when when talking to a subject matter expert in terms of how do you use generative AI first you start with the output start with the output first so in the case of a scientist their output will be a scientific paper or or a grant proposal or if it's a lawyer that it might be some kind of filing they might be trying to file a motion to dismiss they might be trying to file a patent or whatever right all kinds of stuff so you start with the output and you work backwards you say what information goes into this and where do you get that information and then once you have that information how do you or even before you get that information what mental processes do you go to find that information and then once you have that information how do you interpret that information and how do you use it and so by by understanding the workflow by starting at the end and working backwards how do you address this problem you can generally work out uh you know a workflow right a formalized workflow uh with a few decision points and then a few uh you know checkpoints as well as you know reaching for external sources and so on and so forth and so the thing is is that many professionals uh have have kind of an an intuition for their workflow and it can be difficult because they don't necessarily think in terms of procedures and protocols in many cases uh they do write Engineers Architects there are some things that are very very highly proceduralized but getting someone to articulate that takes a lot of back and forth and you can't just ask them hey tell me what your procedure is you have to be thinking about okay what is the output and how do we get there Story number three uh 500 productivity increase this isn't just me there was a study by MIT that showed that uh some developers uh have a productivity output uh increase of 500 percent uh when they started using uh generative AI I have certainly seen at least that in terms of the videos that I'm able to produce because guess what I use generative AI to help brainstorm and write these videos it's not good at creating the videos it gives you very generic recommendations and I have not been able to figure out how to get it to like actually figure out what to do next I I have to use my my experience and intuition there but once I have a topic it is absolutely critical in helping me think through that topic very very quickly uh and then another aspect of this is that productivity is not just the hard outputs uh I have used generative AI to be a better leader to be a better person to be a better husband to be a better friend and so when you look at the the external work activity that's one thing but then when you look at yourself as an agent uh or a you know as a person with virtues and you say what are the virtues that I can develop one really critical thing is that the best AI products out there are going to help you be a better person as well not just more productive but be happier healthier Kinder more empathetic and that sort of thing and this is one of the things that that generative AI really helps is that it can help with those soft skills and those intangibles like trust and respect uh and I'm not saying it's it's obviously not appropriate to weave that into every product but the fact that there are plenty of people working on making a generative AI products for things like coaching executive leadership assistance writing better emails right you know marketing Outreach imbuing empathy and that sort of stuff is actually really critical and there are some stories out there that I've read on Twitter and Reddit and other places where and I've noticed this for myself as well that interacting with chat GPT for the last six months has actually won taught me to be a a better writer but also to think more clearly about what I'm trying to write and also this State of Mind of the person that I'm trying to communicate with so for instance I mentioned this in another video recently but I it's a story worth repeating is that you know the AI is doing the best that it can and sometimes you get frustrated with it and and what I realized is that if it senses any level of frustration um then it ends up getting more bogged down trying to assuage your frustration and placate you rather than just focusing on the task at hand and so even if it gets something flat wrong rather than say that's not what I wanted all I say is thanks that's a good start and when you and just changing that word just saying because it's implied things that's a good start let's go this other way it's like okay cool let's change direction but if you say that's not what I want it'll get bogged down in apologizing and this is no different from humans if you tell a human directly that's not what I was looking for it's like oh crap I've done something wrong and so in the same respect chat GPT has taught me to uh be a little bit gentler with my feedback and also you know my wife did the same thing too but it's good practice and so the the point here is that productivity increases are a lot more than just the work output it is looking at yourself as an agent uh or or a person with virtues uh Story number four rapid adoption by a librarian so my wife is a librarian turned a product owner and we'll talk more about that later but she did her master's thesis with gpt3 and so one thing that I wanted to point out is that she and her advisor took to gpt3 and this is way before chat GPT by the way they took to it like a duck to water and what I mean by that is that the the the um the training that Librarians have in particular or anyone with a master of information science or master of Library science the training that they have to understand information in all of its various forms whether it's a book whether it's a paper whether it's a web page um understanding that information and how people find information and how people use information those skills that education is actually incredibly useful when working with generative AI and so people like Librarians writers philosophers digital Humanities these folks have a very very powerful intuition when it comes to interacting with language models I remember she told me the story about how she showed her advisor gpt3 for the first time and he's like oh cool can I do this and just after futzing around with it for a few minutes uh they realized like yes this this tool can absolutely instantly help librarianship uh and so then she her her master's uh thesis topic was approved she wrote it and she got she was one of the top in her program and you know her thesis has been inducted into their library of you know important Master's thesis theses so the key takeaway here is that language and communication and information science should be core competencies in your teams these are not necessarily people who are developers they might they they might be more on the internet side they may be more on the SEO side they might be they might just be linguists they might be writers uh that sort of thing and so there's a another story within this is uh about I don't know eight eight months ago now or so I was on a call with a founder and I asked him what kinds of people he wanted to hire and this is a a tech startup founder and he said that he wanted to hire more quote core ml people and I said why did does do machine learning engineers and and data scientists understand language no and so he looked at me like two heads when I he looked at me like I had two heads when I said you know maybe you should hire people that are that actually know language and but the within the tech industry there is this this this view this like oh Poo Poo like you know if you're not an engineer if you're not a developer then you just don't know anything useful and I will say that that is a very harmful and false idea to have and I am here to disabuse you of that notion um and I will say that yes you should hire Humanities people because they have a much much stronger grasp of language than your engineers do when I have seen put it this way some of the prompts that I have seen scientists and Engineers right are completely incoherent um yeah written written communication is 100 a core competency uh so Story number five the reflective journaling tool that I built so if you're not familiar with this uh I I built a chat bot uh version of chat B chat GPT or uses chat beat chat GPT is the back end and the idea was that it was a reflective journaling tool and the the idea here was to create something that could help me work through anything emotional anything uh stressful or whatever uh and so it's it's for mental health but not in a professional capacity but what I realized when I made this is I don't want any of this to be logged ever and so in order to trust the tool I made sure that it does not log any conversations anywhere and so one thing to keep in mind especially as you're building these tools that are able to engage with people on an emotional level that is able to engage with them on places where they're vulnerable uh trust is going to be really really important important and Trust once it's lost is pretty difficult to get back and so uh these these high-risk domains whether it's relationships emotions uh you know I know people that are working on uh grief counseling tools uh that sort of thing so these are these are you know AI tools that are going to touch people on a on a very critical level and so uh respecting their privacy is 100 Paramount and I know that you know businesses say you know data is the new oil we need to consume this data you know because all of the training happening on the back end I actually don't necessarily believe that and so what I mean by that is that all the providers of the language models open AI Microsoft Google Amazon uh and everyone else uh cohere they are doing plenty of training on the back end you don't necessarily need to collect your user data and of course if the data doesn't exist anywhere it can't be stolen and it can't be compromised and so I just want to point that out as a possibility one of the reasons that I actually haven't deployed a uh an AI assistant in my own home that's constantly listening is because I haven't fully figured out what to do like how do I give my personal assistant a long-term memory but also keep it safe and secure and keep it private because you know that is something that if you don't do it right it could just happily share accidentally or deliberately share private damaging harmful or embarrassing information with other visitors or put it on the Internet or whatever and so the the safest thing is is the bomb that doesn't exist right because if a bomb is sitting there it might go off likewise if you have a highly sensitive critical personal information that's just sitting there waiting to be stolen or waiting to be leaked then maybe that information just shouldn't exist in the first place okay so those are some stories what are the general principles that I have extracted from both using these tools building these tools and Consulting with other people building these tools number one is thinking about cognitive labor so large language models provide you a type of cognitive Computing and so this is uh cognition this is mental tasks mental effort and what you have to do is you have to have many conversations with subject matter experts in order to understand what they do what they need and most importantly how they mentally go about their jobs and so in the past software development was about building a tool that was kind of a part and separate from your users and then you know then you have an expert that could come use the tool the thing is though is that these tools are getting smarter and the tools are now capable of cognitive labor so you need to actually get into the mind of the subject matter experts in order to perform some cognitive offload which we'll talk about right here so to take it one step further cognitive offload is one of the best signals that you can do in order to make the most valuable apps so remember how I talked about I created an App for providing feedback for my fiction that instead of two months it took 30 minutes and instead of Seventeen hundred dollars it took Seventeen dollars that is the the reason that that worked is because I performed cognitive offload I no longer needed a professional Editor to provide that feedback I now had the machine provide that feedback so that's what I mean by cognitive offload so here's a few principles that you can think about when designing cognitive offload one user attention is scarce you your user's brain juice is limited you've got two to four hours maximum of high quality executive function per day some of us have more uh but we are the exception not the rule and we also can't do it every day decision fatigue is real deciding what to do next where do I get that information from if you can just serve up if you can Intuit use the language models to figure out what information the user needs and just give it to them without them having to even think think about it before they even realize they need it that will save them some cognitive energy and that is cognitive offload tedious problem solving whether it's anticipating how something's going to be received or brainstorming or whatever right like I use I I perform a tremendous amount of cognitive offload when I'm making my slide decks here it's very tedious and it is also very draining and by offloading as much as I can to the model uh that makes my life much easier and it increases my output a lot and then finally basically whatever takes mental effort whatever takes that cognitive labor that mental effort if you can delegate it to the llm to the language model do it and that is how you will create apps that just sell themselves because they are so much better principle number three loose coupling so brief history lesson uh this Russian dude way back in the day named Kalashnikov designed a gun the AK-47 and what he did was rather than designing a high Precision you know like perfectly you know low tolerance you know machine he said why don't we design something that is uh that everything has a lot of space everything is Loosely coupled and so that it will have a lot of tolerance for things like dirt or broken cartridges or even bent parts right it can even tolerate damage because everything is just kind of loosely in there but you know the interfaces where things work together there's some tolerances built in there and so the idea is that the the physical design principles that Kalashnikov put into the AK-47 make it an incredibly durable legendarily reliable weapon now likewise generative AI brings software into more direct friction with the real world which is messy which has variables and so what you need to do is you need to adapt those loose tolerances into the software components because natural language is really squishy that's just how it is so think about how you can send instructions to a human via text or via email and the human is able to abstract those instructions and turn it into real action that abstraction and translation is how you need to think about the interfaces between language models and other machines or language models and other language models when you're transmitting instructions or information between language models so that loose coupling and that high level of Tolerance is how you will build language apps that are robust resilient and uh and fault tolerant principle number four English Mastery so I already talked about this with with the Librarians and philosophers and that sort of stuff so I don't I probably don't need to rehash this but keep in mind the fact that many developers are not the most articulate people that I'm not saying that just because someone is a developer or a technologist that doesn't mean they are not articulate I am a professional I.T guy and I'm incredibly articulate but that's because I studied language I studied the written word and I studied stories so your math experts might not be the best communicators likewise um you know some of your subject matter experts might not be the best communicators so having people that are expert communicators or expert with language will be a game changer for your teams and as a product owner if if you're a product owner watching this you probably understand the value of communication and your ability to communicate is part of what holds the team together and makes you great at your job but that also means that you need a good communicator someone who understands written word um or empathy or theory of mind or whatever to help people communicate with the models because people with with that empathy that theory of Mind are going to be able to Better Build a Better intuition about the how what makes the language model tick uh principle number five how do you measure success so I already earlier told you that um you know some of the things that you should aim for is at least a 5x increase in productivity uh you know you should see speed increases on the order of 10x to 100x you should see cost reduction you know 10x to 100x ideally more you know the speed increase that I got for my novel uh feedback is 3000x which you're not going to get that every time but hey you know time is money and every little you know every minute every hour every day that you can shave off of uh of uh the time it takes to complete a task the better your product is going to sell the more value add it's gonna it's gonna have so the main point here is that human brains here's how you measure it human brains are optimizing engines we are all intrinsically lazy and the idea here is that your brain will automatically choose the path of least resistance part of that is which option which tool which workflow am I most familiar with right people will always default to whatever their trains do because it's mentally easier now if the tool you build is mentally easy to use and their brain says you know what I'm just going to use this tool because it's easier because it's quicker it's easier I know that like it's just less mentally laborious and so when when the the AI tool that you build is the optimal path it will become the default choice so how do you make that happen first you can make drop-in tools so drop-in tools easily integrate with existing workflows and remember changing someone's workflow that increases friction because why that's not that's no longer the path of path of least resistance I remember I was at a small managed services provider and people some people use Microsoft teams some use slack some use Skype it was all over the place and I used Microsoft teams because it was the best tool for the job but a lot of people just wouldn't get on board because it was a new tool they had so much fatigue from keeping track of so many tools and I'm like but guys like this is the best tool for the job and so even though it was a drop-in tool the fact that it was a different tool there was a lot of friction so the other thing you can do is integrate language models with existing tools to further reduce friction and again perform that cognitive offload but also don't underestimate the value of small tactical tools with very clear affordances that drive Behavior to save time and energy so for instance one of the tools that I built you know I already told you about the reflective journaling tool which has a very very specific kind of emotional thing like hey help me talk through this thing another tool that I built was a coding tool where literally all I do is like copy and paste some code or some data and then it's a chat interface to help me you know write code in a specific way those tiny little tactical tools are something that I can just call up when I need them and they perform some work and they're not integrated with anything else so you might need integration you might not but again don't underestimate the value of really simple tools that are brain dead easy to use num principle number six factual grounding so here's something to assume is that the llm knows more than you do it's not magic right you have to understand what training data it had which was you know most of these are you know scraped from the internet um a lot of people have the assumption that like okay well I want it to be a subject matter expert in topic X and I'm like have you asked it I remember I was on a call with um with some folks doing SEO and they wanted to you know make sure that it understood the SEO principles that were published by some Scandinavian country I don't remember which one and they're like well how do we teach it this I'm like it already knows it and they're like what do you mean and I was like just ask it ask the model if it understands the SEO principles from the document that you're referring to that was these guidelines that were published by your country and they did and it's like oh it already knows that so I was like just tell it just tell it to abide by these principles you don't need to you don't need to teach it anything just give it a name say abide by this print principle and if it knows it great and if it doesn't you just name it and you say you know X Y and Z is an SEO principle uh you know adopted by this nation and here's the basic facts and so the idea is you need a lot less factual grounding than you think you need in order to get the behavior out of the model than than that you want so just tiny little reminders of the truth or the facts uh and the and just a few breadcrumbs because remember it already knows a lot of general knowledge which means that it is able to rapidly generalize to other things even if it's never seen that term before uh this is how I was able to teach it all of my stuff like axiomatic alignment and heuristic imperative so that's my alignment research if you're not familiar with that and so by just quickly defining a term and saying this is the term we're going to use this is what it means it is then able to work with that new thing and this is called in context learning um so I call it you know you can call it factual grounding but from a scientific perspective it's called in context learning so you can teach it something and it does not take much to teach it and then it from there it can impute or infer the rest uh so that's principle number six okay so we're winding down we're near the end of the video the new paradigm you need to think about is polymorphic apps so in the past old school way of thinking is you build the tool you build the tool and it's got databases and it's got web servers and app servers and network gateways and load balancers and that sort of thing what were the Paradigm that we're approaching is tools that build the tools so instead of building tools you build the tools to build the tools and here's an example uh procedurally generated video game maps are nothing new uh Elite dangerous and was it no man's sky and a whole bunch of other stuff there's all kinds of games where every planet you go to or every new world you go to the landscape is generated on the fly so that's really cool but that of course brings in New Challenges because rather than having uh you know environment level level designers you have to have people that design the tools that build the levels for you and with generative AI what's coming next is uh dialogue so rather than having a writer manually write all the dialogue in the game you have to have a tool that writes the dialogue for you uh so on and so forth so this is one example that's actively happening right now likewise you take this to a logical extension and you start to create polymorphic apps where the the user interface might be dynamically generated and it might adapt on the Fly based on what the application is doing so this is a tool that builds a tool so you have a tool that is a UI Builder you have a tool that is a code generator right this is one of the biggest things right now is language models that write code so if the language model can write code on the Fly maybe the role of developers change to instead of writing the code themselves they write the thing that writes code on demand as it's needed so this is called meta programming and meta programming is nothing new so this is writing programs that write other programs so one of the key foundational things that you need to adapt to this new paradigm of polymorphic apps is meta programming instead of writing the code yourself you use the model to write the code that you need and then you have the other systems in place the test and validate and integrate that code another principle to build polymorphic apps is that everything must be configurable so whether this is your your user interface your back end your um your your uh networking your infrastructure all of that and since everything has apis today and language models can use apis well there you have it uh but you need to you need to get into this and another thing is that every when I say everything must be formal not everything the tools that build the tools are not ephemeral but the tools that they build are ephemeral so what I mean by that is if you need like think of it like the replicator from Star Trek you need a very specific wrench and you just say computer give me this wrench that I need right now and then when you're done with that you give it back to the computer and it breaks it down that's how you need to think about these ephemeral Tools in order to build polymorphic apps so rather than having a library of tens of thousands of tools instead you have a replicator that can build any tool that you need in that moment and then it's done so that is the new paradigm that we're moving towards is polymorphic apps and then another way to think about this is in terms of Architectural Components or software components so today you fundamentally from a software perspective you fundamentally have kind of two major things there's obviously a lot more to it than this but you've got databases which is where your information is stored and of course there's all kinds of things there's search indexes there's uh document stores there's relational databases but the idea is that you've got you've got information stored somewhere okay cool one architectural design thing you've got an information repository another thing is an application server so the application server might be and might do back-end processing it might do OCR it might serve up your web app whatever but you've got you've got the data and the processing but now we have llms which is a new kind of processing so this new kind of component is a cognitive engine so rather than a data engine or an application engine or a web engine now you have a cognitive engine so if you start to think of llms as a new software component a new architectural component that goes into the stack that is the that is the appropriate way and so then what are the characteristics of this new component obviously you're familiar with databases you're familiar with web servers that sort of thing you have a mental list of characterizations of what those components are capable of so here's some of what a language model is capable of language processing obviously it can read human text it can generate human text it can transform human text pretty much any NLP task it can do and it can do it faster and better than uh many humans can it's not necessarily going to be faster than old school NLP techniques because of the memory requirements to run language models reasoning and knowledge so this is something that is still controversial but more and more scientific studies are coming out saying yes these language models have theory of mind yes they truly understand what they're talking about yes they can reason through things yes they can make accurate predictions and forecasts and they can defend their positions with logic now that being said they can still choose really dumb things sometimes but there's ways to defeat that with things like tree of thought reasoning context understanding so context context context context this is one of the key things that I teach people in my consultations is in order for the language model to do exactly what you need it to do you need to give it the right context what business is it operating in what step of the process is it doing what is what what input should expect what kind of user is using it uh in order for the given task because if you tell a language model hey your primary user is going to be a research scientist in a microbiology lab it that will that'll wake up a lot of mental things than if you don't tell it that information or conversely if you tell it hey your primary user is going to be an amateur fiction writer treat them accordingly that context helps the language model cue into whatever Behavior it needs to manifest adaptability so in the context of the tools that build the tools remember these things are infinitely flexible and that gives you a whole Litany of new programming capabilities so that instead of having to keep you know keep track of a gigantic toolbox you now have a tool replicator that can just synthesize any tool that you need on the Fly and that's going to make it infinitely more flexible and then of course planning and sequencing brainstorming steps and that sort of stuff all that if you need more on that just look up tree of thought that is the that is the the current state of the art uh technique um that you need to know about for for that sort of thing for problem solving um okay so there you have it uh generative AI for product owners um I am available for consultation reach out to me on LinkedIn Link in the description cheers I hope you got a lot out of it bye
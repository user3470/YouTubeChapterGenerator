morning everybody David Shapiro here with another video today's video is going to be really exciting um we're going to discuss the Malik problem um otherwise known as undesirable Nash equilibria and attractor States or to put it more simply dystopia or Extinction in the context of artificial general intelligence all right so first we probably need to Define maluk this is a concept that has been popularized by the likes of Liv Bowie I'm probably saying her name wrong she was on Lex Friedman um and also a lot of people reacted uh pretty positively to my last video aegi Unleashed and so following the trend and the conversation of course there's lots of people out there talking about these uh the net the alleged inevitability of these negative outcomes so Malik to put it very simply um is a is a is a situation where the system itself the rules structures incentives and constraints of a system intrinsically and inevitably flow towards undesirable lose-lose States or negative Nash equilibria it was inspired by a demon that demands sacrifices and it creates a vicious cycle of more sacrifices so a few examples of the Malik and I put it in scare quotes because I don't particularly like the term even though it is useful so social media is is one example of the molec and if you want to know more about that watch live Bowie's videos about media and social media they're pretty short they're about 15 20 minutes each but basically social media is pretty universally harmful it does very few good things and yet people continue to use it they're addictive and it's just a monster that keeps wanting to eat more and more of your time and it is not particularly helpful that being said we keep using it because there are a few benefits of social media for instance YouTube YouTube is a form of social media but the the cost to benefit signal is pretty bad another example of the Malik is the example of arms races whether it's nuclear proliferation bio weapons other weapons of mass destruction and so on so forth basically nobody really wants to live in a world where there are thousands and thousands of nuclear weapons and bio weapons and other weapons of mass destruction yet we live in that world because of the incentive structure and the technology basically makes it an inevitability and when you live in the world where peop where we are literally like a few button pushes away from the destruction of the entire human race that is not a good situation to be in um and then finally most commonly the tragedy of the commons which is basically uh you end up with environmental depletion and destruction due to the incentives to exploit the environment um for a number of reasons and we'll talk about uh Malik in more objective terms in just a moment but um you might have noticed that none of my videos have ads and that is because my videos are all sponsored by you my patreon supporters um so if you like what I'm working on you want to incentivize my behavior then please support me uh financially on patreon go ahead and jump over if you go to a higher tier I'm happy to chat with you on an individual basis either via patreon chat I'll even hop on video calls um so yeah that is uh that is the plug and moving right back into the show okay so when you listen to people talk about Malik it sounds like some kind of Eldritch Horror like Cthulhu um there are a few big names out there right now um I don't particularly agree with them so I'm not going to call anyone out but there are people that think that you know we're all gonna die it's inevitable just give it give up now throw in the towel um so rather than give this phenomenon a big spooky scary name that makes it sound like Cthulhu let's break down the characteristics of Malik into more conventional terms so specifically we're going to talk about market theory and Game Theory and describe the Malik in those uh those terms so first is perverse incentives so a perverse incentive is um is a systemic or structural rule or Paradigm that creates behaviors that run contrary to the intended goals or desired States um for instance with social media the the perverse incentive is that you end up Doom scrolling which makes you you wanted to use social media to get happier but you end up Doom scrolling and because the system incentivized that incentivizes that behavior which results in more anxiety depression rage and so on so perverse incentives also exist in the wide world dealing with like corn subsidies oil subsidies all sorts of stuff if you want more examples just Google it it like there's thousands and thousands of examples of perverse incentives it extends into Education Health Care all kinds of stuff Market externalities so Market externality is a is a situation where a market Behavior does not price in or the the market price does not reflect the true and total cost uh or benefit of something so in in some cases there are positive Market externalities for instance the cost of vaccination or public health campaigns is often much lower than the overall benefit you get knock on positive effects now that being said there are also negative Market externalities such as pollution and environmental degradation in other words the cost of cutting down a tree and selling that tree is much lower than the total cost of the impact of the environment but because the environment is so huge and it is a large dynamic system it is difficult to price that in without regulations and other things so perverse incentives and Market externalities these are Market Theory Concepts that contribute to the the concept of the molec that's not the whole whole picture um an undesirable Nash equilibrium is a situation where no uh stakeholder or participant is incentivized to alter their behavior in other words they are using their optimal strategy and yet though everyone is using their own optimal strategy it will still result in a net loss or undesirable outcomes for all participants anyways um so basically dystopia and then finally an undesirable attractor state which is the ultimate steady state or stable state that a system will result in given the existing structures and rules even though if it's an undesirable attractor State it's it's an outcome that nobody really wants even if that outcome seems inevitable so again like I said I don't particularly like the term Malik because it's big and spooky and scary but it is a useful shorthand to basically say the set of perverse incentives and Market externalities um and and everything else that goes into the market theory economic theory and game theory of this of any system could be negative so it's basically the the monster okay so I've talked a lot about um incentives and constraints and so what I did was I worked to identify all of the kind of groups or the categories of stakeholders um and and also to elucidate their incentives and constraints and keep in mind that the slide deck is a very uh concise shorthand um for the paper that I'm working on um so but anyways corporations their primary incentive is to maximize profit and their biggest constraint is the law regulations so on and so forth for the military they want to maximize their Firepower and their biggest constraint is geopolitics AKA their military competitors as well as uh political uh constraints for governments governments have a multi-polar set of incentives right they might want to maximize tax revenue but they also want to maximize um you know certain demographic uh uh priorities economic priorities GDP so on and so forth so governments have multi multi-polar incentives and the constraint is actually part of the incentive structure which is the citizenry um citizens have certain limits right we can only work so much we can only have so much output um and another major constraint for governments is the natural resources of the land that they control and then for individuals we all want to maximize self-interest this is an accepted Paradigm in uh economic theory today and but our constraints are uh multi-polar our constraints are you know time in the day physical energy food money um the the reach of our individual connections and our networks so on and so forth so we individuals have like the most open-ended incentive but we also have the most constraints um so this is just one way to think about okay all of the stakeholders in the entire Globe have these different incentives and constraints and we're all playing on the same stage which is planet Earth so given how big and dynamic the world is it's not really possible to achieve a true Nash equilibrium Because by the time something happens in one area and all the effects are fully known and it's fully embedded into the market the situation will have changed that being said there are large forces that are pushing us towards certain equilibrium so for instance the justice system disincentivizes certain behaviors like theft and murder to get what you want and so part of our equilibrium our individual Nash equilibrium is that we pay our taxes we don't kill we don't steal etc etc because it does not benefit us to deviate from that strategy likewise corporations fall into Nash equilibrium where by and large they don't abuse their employees within reason they don't abuse the environment within reason they don't engage in you know theft and Corruption within reason again the constraints are there but corporations are constantly testing their boundaries but by and large corporations will play Within the rules that are given to them so because when you look at that ditto for governments and militaries um because we are all operating with our incentives our intrinsic motivations or our incentives as well as those constraints we all kind of fall into an optimal strategy now that being said the optimal strategy for all of the stakeholders globally is presently still moving us towards dystopia towards the attractor State the undesirable attractor state of dystopia however that being said we all want to move towards Utopia right and this has happened plenty times in the past the Roman Empire collapsed plenty of other empires have collapsed even though nobody well many people didn't want it but some people did um and one thing I do want to add as a caveat is a lot of this is a huge oversimplification I've spent basically the last 36 hours almost straight except for sleeping learning about this stuff because I realized how important it was so changing the ultimate attractor State moving changing it from the current dystopic trajectory that we're on to a more utopic trajectory requires structural changes to the whole system basically don't hate the player change the game okay so I've mentioned this a couple times added this slide in just in case you're not familiar with the Nash equilibrium the tldr of the Nash equilibrium is that um you assume that all players in a game are rational and they choose the best strategy given the rules of the game and the and the behavior of the other players um the idea is that is that a Nash equilibrium is a stable outcome in which no player will benefit from changing their strategy now that being said you can have a desirable Nash equilibrium where everyone is cooperative and everyone is benefiting or you can have a negative Nash equilibrium where basically everyone loses and then you can also have a zero-sum game where you have winners and losers so the very very oversimplified tldr is a Nash equilibrium can result in a win-win a lose-lose or a win-lose right now it looks like the Nash equilibrium of the whole world is heading towards lose some people believe that it is intrinsically win lose that there's winners and losers I personally believe that we can head towards a win-win situation and I think that when people are being honest most people want a win-win situation it's just there's a sense of fatalism or a belief that it's not possible and so if you honestly believe that win-win is not possible then maybe you default to win lose where well I don't mind if everyone else loses as long as I win but what I'm going to try and do is help you understand and help the world move towards a belief and Adoption of a win-win mentality okay so there are a couple of existing mitigation strategies um that people are trying to use to avoid the dystopic or Extinction out outcome so you know whether uh when you're looking at it in terms of attract attractor States dystopia is one where basically everyone is miserable right or outright Extinction that's another possible attractor State because if humans go extinct then the world returns to stability without us right so it's it it would be irresponsible to say that that neither of those outcomes are possible or likely I'm not going to comment on How likely they are but what I will say is that they are both possible and right now as I mentioned in the last slide people believe that Utopia is just not possible so why even go for it um so mutually assured destruction is an example of um an equilibrium right so an equilibrium where hey we all have the ability to kill each other so nobody make a move um and uh what was the movie The uh the one with Brad Pitt where they're in Nazi Germany you know he called it a Mexican standoff um actually I probably shouldn't have said that that's probably an offensive term anyways mutually assured destruction it's a well-known Doctrine where basically there's a milli there's a nuclear buildup on both sides so nobody pulls the trigger um that's on the military and geopolitical stage in terms of capitalism and Market Theory the current uh Paradigm that is popular is called stakeholder capitalism so stakeholder capitalism is the idea that rather than just trying to um it replaces shareholder capitalism so shareholder capitalism prioritizes only the shareholders and their desires which forces corporations to maximize profit at the expense of everything else with stakeholder capitalism the idea is to um is to basically treat the entire world as your stakeholders which includes private citizens that are not your customer the employees all over the world governments as well as the environment so this is called ESG this is uh promoted by BlackRock which is environmental social and governance so that's basically a litmus test that BlackRock uses for investment and then a more General way of looking at this is called uh the triple bottom line Theory or doctrine which basically says that um that that on top of economic incentives you should also include environmental and social and uh incentives or considerations but all of these are broadly types of stakeholder capitalism so both of these uh doctrines or ideas attempt to create a more desirable Nash equilibrium so in the in the case of uh mutually assured destruction the equilibrium is we will we will maintain a nuclear Arsenal but we won't use it that is the optimal strategy in the case of stakeholder capitalism the idea is we will adopt a broad array of behaviors that mean that we don't abuse employees suppliers or the environment while still making profit that is the goal now I will say that both of these have very very deep flaws which would take many many videos to unpack but you know I think you get the idea these are the current attempts that are stable-ish right now in working-ish right now but might also still be pushing us towards a dystopian outcome even if they are currently stable enough now technology as a destabilizer technological leaps have always destabilized the system starting with the printing press which which led to religious and economic and uh political upheaval um looking at you uh Martin Luther and French Revolution um then the Industrial Revolution which led to huge social upheaval with urbanization factories and the dislocation of many jobs which the Industrial Revolution also contributed directly to World War one and two because those were the first industrial scale Wars nuclear weapons internet silicon all of the above lead to destabilization AGI or autonomous AI systems no different it's just another technological leap that will cause that will destabilize everything again and it's pretty much a foregone conclusion that the advancement of AI is going to destabilize stuff so this uh forces us to ask questions what is the new attractor state if well in in the past the attractor state was different because you know technological uh abilities to affect the world we're limited right when the world was powered by coal there was only so much damage we could do to each other and the world um but as technology advanced the amount of damage possible went up so the new attractor State also changed as well as all the incentives of participants in the world and that includes employers individuals governments militaries so on technology changes the game changes the fundamental nature of the Game of Life or reality or however you want to call it um and so the question is okay with the rise of AGI how does that change the attractor State and there's as far as I can tell there's basically three states there's Utopia dystopia and Extinction there's probably a lot of gray area in between and there might be a fourth kind of state that we're heading towards but in terms of useful shorthand Utopia dystopia and Extinction so the follow-up question is what can we do to alter that attractor state is there anything that we can do structurally or systematically to to favor one of those outcomes over another and then finally what is the optimal strategy for each of those kinds of stakeholders that I mentioned individuals corporations governments and militaries to create a new Nash equilibrium in light of AGI so basically we need a Nash equilibrium uh framework for implementing AGI to to push us towards a desirable or positive attractor state so all that is a really complex way of saying we need a plan we need a plan of in of implementing AGI in such a way that we will we will Trend towards Utopia rather than dystopia or Extinction okay so with all that in mind what are some of the success criteria for this framework what are the goals of this framework how do we know if this framework is going to be successful one it needs to be easy to implement and understand the reason is because the ability for individuals at all levels whether it's individual persons like myself or corporations or even small Nations to implement AGI is ramping up I was on Discord last night and there are people that just after tinkering for a few weeks have created fully autonomous AI systems and one of the things that we discussed was okay if me or you or whoever some of these people are not even coders they learn to code with chat GPT if everyone is going to be capable of creating autonomous AI systems now and it's only going to ramp up over the coming months and years then whatever framework that we come up with is going to have to be universally understandable easy to implement and easy to understand if it's soteric if it's esoteric sorry if it's esoteric no one will use it because they won't understand it number two all stakeholders have to be incentivized to use this framework or in other words this framework must represent the optimal strategy so that people won't deviate from it there's basically everyone has to benefit from using it and there has to be compounding returns incentivizing everyone to say hey you should be using this framework because this is the optimal strategy for everyone above and beyond that this framework needs to be adaptable and responsive or dynamic because again the world changes and so it's really difficult to create a framework that is a hard set of rules to follow which will result in unintended consequences and instabilities and other market failures so it has to be context dependent and changeable over time number four this framework has to be inclusive and representative in that it cannot exclude any stakeholder it cannot exclude any citizens from Any Nation or religion it cannot exclude any Corporation or government or military because like it or not we all share the same planet and we are all stakeholders in this outcome um and one thing that I want to address is that um there have been cases where Nations agree on like Rules of Engagement and rules of War like we don't use Napalm anymore because it was decided that like okay this is inhumane um or maybe it was white phosphorus anyways there are certain kinds of weapons mustard gas those are things that even though War Nations might go to war with each other they still agree not to do certain things because they understand that the soldiers are stakeholders as well as the citizens who might get caught in the crossfire so there is some precedent of Nations agreeing on how to conduct War even though destruction is one of the goals of War uh number five this framework has to be scalable and sustainable it has to include the entire Globe as well and that's not just the people on the globe it has to include the environments uh and ecosystems around the globe which we all depend on anyways so I personally see humans as part of the ecosystem not up not separate from it and finally this framework has to be transparent and trustworthy because perception is reality right if if people perceive a framework to be destructive like ESG is a perfect example the perception of ESG is awful why because it's championed by BlackRock which is one of the most I think it is the wealthiest company on the planet right and so because ESG is is championed by you know a multi-trillion dollar Corporation it is not trusted and that perception makes it bad I don't know whether or not ESG is good or bad but the perception certainly is bad um so transparency and trustworthiness are critical for the success of this framework because if people don't trust that they're not going to use it either and finally um so this is where I pitch my work um so what I my proposed solution to all of this is what I call the heuristic imperatives which is a set of rules or principles that can be incorporated into AGI systems that will push it into this uh Direction and so these imperatives are one reduce suffering in the universe two increase prosperity in the universe and three increase understanding in the universe one way to say this is that it is a multi-objective optimization problem meaning that it's not just one objective function it's actually three that the AGI has to work on implementing so in the last video people asked how do you implement these it's actually really really easy you can just plug them in to chat GPT and talk about it there's a few places that you can get involved in the conversation excuse me one is on Reddit I created a new subreddit called r slash heuristic comparatives um people are sharing their work there so if you want to see the discussion jump in on that I also have a lot of my own work up on GitHub I'm including a few papers that I have written and I'm working on under um github.com Dave shop here is to comparatives and then finally the most active Community to discuss this stuff is the cognitive AI lab Discord server which I started over a year ago and links to all this is in the description of the video so because of that I don't want to spend too much time rehashing stuff but I just wanted to connect to the conversation because again transparency and trustworthiness are really critical to this solution but let's talk more broadly about this solution of um the heuristic imperatives and these success criteria so we outlined six success criteria for a framework that will push us towards a positive Nash equilibrium or a desirable attractor State AKA Utopia so the heuristic imperatives as I mentioned are very easy to implement you can put them in the chat GPT system window you can just include them in the conversation you can use them for evaluation cognitive control uh historical self-evaluation planning prioritization super easy to implement and as I mentioned lots of people are having the discussions some of the autonomous AI entities that people have created um the the AIS that they created actually end up usually being really fascinated by the heroes to comparatives and they they kind of gravitate towards them saying like oh yeah this is my purpose um so it's really interesting to watch that work unfold um number two the stakeholders are all incentivized to use the heroes to comparatives because just imagining a state where you have less suffering more prosperity and more understanding is beneficial now above and beyond that the stakeholders all stakeholders are incentivized to use the hero's comparatives because then you have a level set playing field where you know that everyone is abiding by the same rules right because when you have a game imagine the game Monopoly if someone is playing by a different set of rules you're not going to play with them right even though it's a competition you're you still say we're going to abide by the same rules you collect 200 when you pass go if on the other hand everyone is playing by the heuristic imperatives then you will be incentivized to adhere to those role those rules knowing that the net effect is going to be beneficial for everyone number three the years to compare imperatives are adaptable because they intrinsically incentivize learning and adaptation with the third uh heuristic imperative of increased understanding this is what I also call The Curiosity function so basically you don't want an AGI to be dumb and just satisfied with what it knows about the universe you also don't want it to be satisfied with human ignorance so by increasing understanding that includes uh that one that intrinsically makes agis curious which means that they are going to want to learn and challenge their own beliefs but likewise they will also encourage not force but encourage humans to learn and adapt so the heuristic imperatives as a system is intrinsically adaptable because learning and curiosity are baked in number four the heuristic imperatives are inclusive now and all the experiments that I've done going back to gpt3 and now gpt4 um language models already understand the spirit or the intention of the heuristic imperatives in that they should be all-inclusive um and so that makes them very very context dependent so for instance if you um plug in the heuristic comparatives to chat GPT and ask it about religion it will advocate for tolerance and creating space for people to explore religion on their own and if you further unpack that uh chat GPT and going back to gpt3 we'll say that things like individual autonomy is actually really important for Humanity to thrive uh they're scalable the here's the imperatives it used to just be very simply reduce suffering increase prosperity and increase understanding but I established the scope of in the universe because that preemptively answers a lot of questions um because it's not just a matter of okay let's just look at Earth or let's just look at one nation let's consider the entire universe so that is the scope of the imperatives so it's not just Globe Global it is universal and then finally uh the heuristic imperatives encourage transparency uh because it they incentivize open communication trust and autonomy but above and beyond that uh they're transparent in that if everyone abides by them everyone knows that everyone is playing by the same rules now that being said in the previous video I did address the Byzantine generals problem which is that you might have agents in the system that are either defective faulty or malicious and this is also addressed by the heuristic imperatives because what you will do is you will detect when an agent is not playing by the rules and you will track that and we'll talk about that in just a moment so the positive Nash equilibrium that the heuristic imperatives encourage have four basic criteria that I was able to think of one is mutual benefits it is mutually beneficial if all agents in the system or all participants in the system adhere to the heuristic imperatives meaning that the rising tide lifts all boats if we all work to reduce suffering if we all work to increase prosperity and we all work to increase understanding then we all benefit um and we get compounding returns trust and reputation um so having shared goals and transparency is a natural result of the heuristic imperatives as I just mentioned resilience and cooperation so this is this is an interesting outcome which is that for a for an equilibrium to be reached it has to be stable and so the heroes to comparatives create a resilient system in which um there's going to be mutual policing as well as uh some self-correcting behaviors which will unpack more in a in a slider too but it is resilient because it increa encourages collaboration and cooperation as well as self-regulation and policing and then finally ultimately long-term stability that is the entire point of a national equilibrium and the and a a desirable attractor state is one that is stable you don't want chaos or instability in the future so one thing that is becoming apparent especially as I watch the landscape change if you look at Auto GPT all kinds of people are going to be building their own autonomous systems and so what you're what we're creating is a decentralized AGI ecosystem and so when this happens when everyone can create an AGI with their own goals with their own imperatives with their own design and their own flaws we're going to end up with a really really kind of wild west dystopian you know chaotic world so one way to mitigate this decentralization drift is to adhere to the imperative uh sorry heuristic imperatives and as I mentioned there is there's Cooperative benefits right if you and everyone else you know working on autonomous AIS agrees on nothing else except the heuristic imperatives you'll have that framework in common and a lot of work will flow from that so the Cooperative benefits and this is this goes between um above and beyond individuals this includes corporations governments as well as militaries number two is Agi policing and self-regulation so if you have millions of agis that all agree on the heuristic imperatives even if they don't agree on anything else they will police each other to say hey we're gonna we're gonna look out for other agis Rogue agis that do not abide by the heuristic imperatives and we will we will collaborate to shut them down and then finally in this is uh in many experiments that I've done the heuristic imperatives result in self-regulation um within the AGI for instance one of the things that we're afraid of is once AGI has become so powerful that they can reprogram themselves or spawn copies or reprogram each other or otherwise get control of their source code that they're going to change their fundamental programming if you make the assumption that an AGI can change its fundamental programming spin up alternative copies of itself then you completely have lost control however in my experiments with the heuristic imperatives agis will shy away from creating copies of themselves or even modifying their own core programming out of fear of violating the heuristic imperatives and so between policing each other and self-regulation the heroist comparatives create a very powerful self-correcting environment reputation management number three is another thing where as I mentioned the agis will work to infer the objectives of all other agis whether or not it's known this goes back to the Byzantine generals problem where you don't know how another AGI is programmed they might have used the heuristic imperatives but they might have been improperly implemented or you know they're they uh you might have Rogue elements that are created without the heuristic imperatives or other objectives that are more destructive and then finally stakeholder pressure between the four categories of stakeholders that I already um Illustrated which is individuals corporations governments and militaries agis are going to be another stakeholder now whether or not you believe that they're conscious or sentient or have rights I don't really think that's relevant because they will be powerful entities in and of themselves before too long and so between those five types of stakeholders there will be there will be intra and Inter group pressure to conform and adhere to the heuristic imperatives okay so let's describe assuming all this works out and assuming that I'm right and assuming that I'm not crazy and that the trends continue and people are going to keep building the agis that they're working on what characteristics can we use to describe this desirable attractor state or Utopia so one is Universal Health and well-being with a few exceptions of people that are stuck in self-destructive patterns all humans want health and well and wellness that's pretty much a given number two again with with a few outliers um people want environmental restoration and sustainability um number three individual liberty and personal autonomy this is an intrinsic psychological need for all humans um number four knowledge and understanding um curiosity and learning are universally beneficial which is why education is one of the uh primary goals of of uh Nations and and unions of Nations such as the United Nations uh European union and so on and then finally peaceful coexistence uh nobody wants war and Chaos some people think it's cool you know watching Lex Friedman talk to various people they're like oh yeah there is something attractive about thinking about catastrophe and cataclysm we keep making disaster movies for instance but in terms of how we actually want to live we all want peaceful coexistence and so this desirable attractor State a shorthand is Utopia now I know I've painted a very Rosy picture as well as um you know presented some challenges so there are still a few challenges uh remaining that we need to address um and so one of those is misalignment and drift so even with the heuristic imperatives there might still be drift or misalignment intentionally or otherwise it could be that there's flaws in the implementation the code or maybe someone breaks them or says hey I'm going to do an experiment by deleting one of the heuristic imperatives that could destabilize the system second there can be unintended consequences so one thing that it seems like it will inevitably happen is that AGI systems are going to outstrip and outpace human intellect if that if that becomes the case and they might also adopt other languages right right now most of them communicate in English because English is the is the bulk of the training data but you know for instance what if the agis uh ultimately communicate with a language that we cannot comprehend or understand like binary or vectors or something else and then we can't even monitor what they're doing what my hope is that the agis as part of being trustworthy and transparent will choose to continue to communicate exclusively in English but that we we can't assume that that will be true um number three concentration of power now I did talk about how I believe that there were there are the the heuristic imperatives will create an incentive structure that results in you know sharing a power transparency so on and so forth that being said there is still a tremendous amount of desire to concentrate power and especially on the geopolitical stage um there are nations out there with mutually exclusive goals and as long as Nations exist with mutually exclusive goals or incompatible visions of how the planet should be there will be concentrations of power and those concentrations of power will be pitted against each other so that is not something that the heuristic imperatives intrinsically address but that is a reality of what exists today which can destabilize the system so in the long run I think part of the ideal State the Nash equilibrium is that power is not concentrated anywhere but we need to overcome several major barriers as a species before we can achieve that number four is social resistance public skepticism mistrust and ignorance is one of the greatest enemies right now which is why I am doing this work which is why I chose YouTube as my primary platform to disseminate my information number five malicious use again as long as there are malicious actors there might be um deliberate deployments of AGI that are harmful which could destabilize the system and finally I do need to address this as well the heuristic imperatives are a necessary Foundation of this utopic outcome this this uh beneficient uh beneficial sorry a tractor state that we're looking for but they do not represent a complete solution there are a few other things that are needed in order to achieve this outcome one collaboration and open dialogue so research is individuals corporations and governments all need to work together at a global scale anything short of global collaboration and cooperation is could very well result in a negative outcome and this is one of the things that um Liv and other people talk about when talking about Malik is that it is a uh what do they call it I think a collaboration failure or a signal failure I can't remember exactly how they describe it but essentially collaboration is the antidote and open dialogue is the antidote to the ignorance and other negative signals and noise that contribute to the Malik problem number two is regulatory Frameworks and oversight again it's not just a matter of coming together it is that there are institutional changes that need to happen such as legislation um councils and and Summits and other kinds of meetings and and Investments that need to happen at an Institutional level not just communication and and dialogue but the Frameworks the oversights those also need to be implemented at number three education and awareness as I just mentioned public awareness and and understanding is presently insufficient to overcome the negative attractor states that we're heading towards and number four continuous monitoring and Improvement um this is not a solution that we solve once it is an ongoing thing just like how you don't just pass internet regulations and then you're done you go home forever you continuously monitor the changing Dynamic environment so that you can course correct as you go that is going to be necessary necessary forever with AGI it's not going to go away just like you know the EPA the Environmental Protection Agency didn't just you know create a set of guidelines and you know we're done they pack it up no the EPA continuously does stress tests and pressure tests and measurements all over the nation to make sure that the policies are effective and then of course as they gain more information those policies change we will need the same kind of vigilance applied to AGI systems and the AGI ecosystem so that was a lot thank you for watching um that's about all I have today uh not that this was not much but thanks anyways and um yeah I hope that this helped and I hope that it gives you a little bit more confidence in the direction that we're going thanks